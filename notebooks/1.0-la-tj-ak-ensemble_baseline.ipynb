{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ensemble_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevincong95/cs231n-emotiw/blob/master/notebooks/ensemble_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rWTS99OI8l-",
        "colab_type": "text"
      },
      "source": [
        "## Video Sentiment Analysis in the Wild\n",
        "### Ensembling Notebook | CS231n\n",
        "\n",
        "This notebook preprocesses input videos to extract faces, frames, poses, and audio before running pre-trained models for each modality to predict group sentiment (positive, negative, or neutral). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58avLN7UlDDA",
        "colab_type": "code",
        "outputId": "36bd0c09-ed91-44cb-c3c2-1462a1770541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Clone the code base\n",
        "!git clone 'https://github.com/kevincong95/cs231n-emotiw.git'\n",
        "\n",
        "\n",
        "# Install required packages \n",
        "!pip install -r  '/content/cs231n-emotiw/requirements.txt'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cs231n-emotiw'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 318 (delta 30), reused 51 (delta 22), pack-reused 254\u001b[K\n",
            "Receiving objects: 100% (318/318), 169.85 MiB | 28.64 MiB/s, done.\n",
            "Resolving deltas: 100% (163/163), done.\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/cs231n-emotiw/requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: opencv-python>=4.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/cs231n-emotiw/requirements.txt (line 2)) (4.1.2.30)\n",
            "Collecting pydub==0.24.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/f9/2cd255898c11179a57415937d601ab1e8a14a7c6a8331ff9c365e97e41f6/pydub-0.24.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r /content/cs231n-emotiw/requirements.txt (line 4)) (3.2.1)\n",
            "Collecting moviepy>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/54/01a8c4e35c75ca9724d19a7e4de9dc23f0ceb8769102c7de056113af61c3/moviepy-1.0.3.tar.gz (388kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: audioread in /usr/local/lib/python3.6/dist-packages (from -r /content/cs231n-emotiw/requirements.txt (line 6)) (2.1.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r /content/cs231n-emotiw/requirements.txt (line 7)) (1.0.3)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.6/dist-packages (from -r /content/cs231n-emotiw/requirements.txt (line 8)) (0.7)\n",
            "Collecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r /content/cs231n-emotiw/requirements.txt (line 11)) (1.18.4)\n",
            "Collecting openl3\n",
            "  Downloading https://files.pythonhosted.org/packages/e2/88/8536723b81c47ada614d008a75e71923932f22e35ab89d4bf5fe441b58fc/openl3-0.3.1.tar.gz\n",
            "Collecting SoundFile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 17.6MB/s \n",
            "\u001b[?25hCollecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.6/dist-packages (from -r /content/cs231n-emotiw/requirements.txt (line 16)) (19.18.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (2.2.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (0.34.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (2.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (1.29.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r /content/cs231n-emotiw/requirements.txt (line 4)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r /content/cs231n-emotiw/requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r /content/cs231n-emotiw/requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r /content/cs231n-emotiw/requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from moviepy>=1.0.0->-r /content/cs231n-emotiw/requirements.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy>=1.0.0->-r /content/cs231n-emotiw/requirements.txt (line 5)) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.6/dist-packages (from moviepy>=1.0.0->-r /content/cs231n-emotiw/requirements.txt (line 5)) (2.23.0)\n",
            "Collecting proglog<=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/fe/ab/4cb19b578e1364c0b2d6efd6521a8b4b4e5c4ae6528041d31a2a951dd991/proglog-0.1.9.tar.gz\n",
            "Collecting imageio<3.0,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/2b/9dd19644f871b10f7e32eb2dbd6b45149c350b4d5f2893e091b882e03ab7/imageio-2.8.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 30.6MB/s \n",
            "\u001b[?25hCollecting imageio_ffmpeg>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/c8/04c6b4a001b8ae7326fb83d6665af1ee58d6cc1acb421f8ea40d2678fe3c/imageio_ffmpeg-0.4.2-py3-none-manylinux2010_x86_64.whl (26.9MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9MB 113kB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r /content/cs231n-emotiw/requirements.txt (line 7)) (2018.9)\n",
            "Collecting keras<2.3.0,>=2.0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/ba/2d058dcf1b85b9c212cc58264c98a4a7dd92c989b798823cc5690d062bb2/Keras-2.2.5-py2.py3-none-any.whl (336kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 39.1MB/s \n",
            "\u001b[?25hCollecting kapre==0.1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/2e/f540d1d1f05c764686163fdb5bb1e5c703f1528076d2829bfc3900683f06/kapre-0.1.4-py3-none-any.whl\n",
            "Collecting PySoundFile>=0.9.0.post1\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/b3/0b871e5fd31b9a8e54b4ee359384e705a1ca1e2870706d2f081dc7cc1693/PySoundFile-0.9.0.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: resampy<0.3.0,>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from openl3->-r /content/cs231n-emotiw/requirements.txt (line 12)) (0.2.2)\n",
            "Collecting scikit-image<0.15.0,>=0.14.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/78/cfb15cdb3f63eea16946a42d0dbf7ef17be79d30858aa8efd5f6757bd106/scikit_image-0.14.5-cp36-cp36m-manylinux1_x86_64.whl (25.4MB)\n",
            "\u001b[K     |████████████████████████████████| 25.4MB 119kB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from SoundFile->-r /content/cs231n-emotiw/requirements.txt (line 13)) (1.14.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition->-r /content/cs231n-emotiw/requirements.txt (line 15)) (7.0.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition->-r /content/cs231n-emotiw/requirements.txt (line 15)) (7.1.2)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (46.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (1.6.0.post3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (1.7.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->-r /content/cs231n-emotiw/requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->-r /content/cs231n-emotiw/requirements.txt (line 5)) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->-r /content/cs231n-emotiw/requirements.txt (line 5)) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->-r /content/cs231n-emotiw/requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras<2.3.0,>=2.0.9->openl3->-r /content/cs231n-emotiw/requirements.txt (line 12)) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras<2.3.0,>=2.0.9->openl3->-r /content/cs231n-emotiw/requirements.txt (line 12)) (1.0.8)\n",
            "Requirement already satisfied: librosa>=0.5 in /usr/local/lib/python3.6/dist-packages (from kapre==0.1.4->openl3->-r /content/cs231n-emotiw/requirements.txt (line 12)) (0.6.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from kapre==0.1.4->openl3->-r /content/cs231n-emotiw/requirements.txt (line 12)) (0.16.0)\n",
            "Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.6/dist-packages (from resampy<0.3.0,>=0.2.1->openl3->-r /content/cs231n-emotiw/requirements.txt (line 12)) (0.48.0)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15.0,>=0.14.3->openl3->-r /content/cs231n-emotiw/requirements.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15.0,>=0.14.3->openl3->-r /content/cs231n-emotiw/requirements.txt (line 12)) (1.1.1)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15.0,>=0.14.3->openl3->-r /content/cs231n-emotiw/requirements.txt (line 12)) (2.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->SoundFile->-r /content/cs231n-emotiw/requirements.txt (line 13)) (2.20)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (1.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.5->kapre==0.1.4->openl3->-r /content/cs231n-emotiw/requirements.txt (line 12)) (0.15.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.5->kapre==0.1.4->openl3->-r /content/cs231n-emotiw/requirements.txt (line 12)) (0.22.2.post1)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.32->resampy<0.3.0,>=0.2.1->openl3->-r /content/cs231n-emotiw/requirements.txt (line 12)) (0.31.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.0->-r /content/cs231n-emotiw/requirements.txt (line 1)) (0.4.8)\n",
            "Building wheels for collected packages: moviepy, openl3, imgaug, proglog, face-recognition-models\n",
            "  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for moviepy: filename=moviepy-1.0.3-cp36-none-any.whl size=110728 sha256=dc406a4071ab8a335d920f756ac6bcb8c5ebe04e1af30ccafdfc208efe90b340\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/fe/1c/f4e6dca9e828d4b979c04e461d7fcc5b8e7bd35f947e665b65\n",
            "  Building wheel for openl3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openl3: filename=openl3-0.3.1-py2.py3-none-any.whl size=249323247 sha256=4af4ed7ce68246bec4975a008df388690c3044052f1ff221fd0aef74f7479777\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/63/c9/35868f3dd3b466909e73178db8566430da2d093cc055b932b1\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=6a5f622e637d837f53886e90df04b2cf4104032d45c6d7e30ce6871519c17c43\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "  Building wheel for proglog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for proglog: filename=proglog-0.1.9-cp36-none-any.whl size=6149 sha256=4a8a453fd305331a99e3704e313ba8f35151539445796757c9693b1bdb0362d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/56/60/1d0306a8d90b188af393c1812ddb502a8821b70917f82dcc00\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566172 sha256=f92d36df2b79f3428e3afa3c1d80e54502ec8a2031e93b20ce21044cea1bdb02\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built moviepy openl3 imgaug proglog face-recognition-models\n",
            "Installing collected packages: pydub, proglog, imageio, imageio-ffmpeg, moviepy, argparse, keras, kapre, PySoundFile, scikit-image, openl3, SoundFile, imgaug, face-recognition-models, face-recognition\n",
            "  Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "  Found existing installation: moviepy 0.2.3.5\n",
            "    Uninstalling moviepy-0.2.3.5:\n",
            "      Successfully uninstalled moviepy-0.2.3.5\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "  Found existing installation: kapre 0.1.3.1\n",
            "    Uninstalling kapre-0.1.3.1:\n",
            "      Successfully uninstalled kapre-0.1.3.1\n",
            "  Found existing installation: scikit-image 0.16.2\n",
            "    Uninstalling scikit-image-0.16.2:\n",
            "      Successfully uninstalled scikit-image-0.16.2\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "Successfully installed PySoundFile-0.9.0.post1 SoundFile-0.10.3.post1 argparse-1.4.0 face-recognition-1.3.0 face-recognition-models-0.3.0 imageio-2.8.0 imageio-ffmpeg-0.4.2 imgaug-0.2.6 kapre-0.1.4 keras-2.2.5 moviepy-1.0.3 openl3-0.3.1 proglog-0.1.9 pydub-0.24.0 scikit-image-0.14.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14TqM3dYQ2wk",
        "colab_type": "text"
      },
      "source": [
        "#### Navigate to the repo we downloaded\n",
        "We will run all our commands from this repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvkvgyMmQxxk",
        "colab_type": "code",
        "outputId": "a678f1cc-93bc-4d81-e1db-bf2cff19bf1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pwd\n",
        "import os\n",
        "os.chdir('/content/cs231n-emotiw')\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/cs231n-emotiw\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-M6Q-f4KNX4",
        "colab_type": "text"
      },
      "source": [
        "#### Pose Pre-Requisites\n",
        "Pose extraction uses the [CMU OpenPose library](https://github.com/CMU-Perceptual-Computing-Lab/openpose) to extract body keypoints. We have pre-compiled this library for use in Colab but some system files still need to be installed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ-wHgKSIgei",
        "colab_type": "code",
        "outputId": "9fb93f11-e65d-419e-f1db-8cb96ad753f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt-get -qq install -y libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler libgflags-dev libgoogle-glog-dev liblmdb-dev opencl-headers ocl-icd-opencl-dev libviennacl-dev\n",
        "!wget https://storage.googleapis.com/cs231n-emotiw/openpose/openpose.tar.gz\n",
        "!tar -xzf openpose.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package libgflags2.2.\n",
            "(Reading database ... 144439 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libgflags2.2_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags2.2 (2.2.1-1) ...\n",
            "Selecting previously unselected package libgflags-dev.\n",
            "Preparing to unpack .../01-libgflags-dev_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags-dev (2.2.1-1) ...\n",
            "Selecting previously unselected package libgoogle-glog0v5.\n",
            "Preparing to unpack .../02-libgoogle-glog0v5_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Selecting previously unselected package libgoogle-glog-dev.\n",
            "Preparing to unpack .../03-libgoogle-glog-dev_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog-dev (0.3.5-1) ...\n",
            "Selecting previously unselected package libhdf5-serial-dev.\n",
            "Preparing to unpack .../04-libhdf5-serial-dev_1.10.0-patch1+docs-4_all.deb ...\n",
            "Unpacking libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Selecting previously unselected package libleveldb1v5:amd64.\n",
            "Preparing to unpack .../05-libleveldb1v5_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb1v5:amd64 (1.20-2) ...\n",
            "Selecting previously unselected package libleveldb-dev:amd64.\n",
            "Preparing to unpack .../06-libleveldb-dev_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb-dev:amd64 (1.20-2) ...\n",
            "Selecting previously unselected package liblmdb0:amd64.\n",
            "Preparing to unpack .../07-liblmdb0_0.9.21-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package liblmdb-dev:amd64.\n",
            "Preparing to unpack .../08-liblmdb-dev_0.9.21-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblmdb-dev:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libprotobuf-lite10:amd64.\n",
            "Preparing to unpack .../09-libprotobuf-lite10_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package lmdb-doc.\n",
            "Preparing to unpack .../10-lmdb-doc_0.9.21-1ubuntu0.1_all.deb ...\n",
            "Unpacking lmdb-doc (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libprotobuf-dev:amd64.\n",
            "Preparing to unpack .../11-libprotobuf-dev_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package libsnappy-dev:amd64.\n",
            "Preparing to unpack .../12-libsnappy-dev_1.1.7-1_amd64.deb ...\n",
            "Unpacking libsnappy-dev:amd64 (1.1.7-1) ...\n",
            "Selecting previously unselected package libviennacl-dev.\n",
            "Preparing to unpack .../13-libviennacl-dev_1.7.1+dfsg1-2ubuntu1_all.deb ...\n",
            "Unpacking libviennacl-dev (1.7.1+dfsg1-2ubuntu1) ...\n",
            "Selecting previously unselected package opencl-clhpp-headers.\n",
            "Preparing to unpack .../14-opencl-clhpp-headers_2.0.10+git12-g5dd8bb9-1_all.deb ...\n",
            "Unpacking opencl-clhpp-headers (2.0.10+git12-g5dd8bb9-1) ...\n",
            "Selecting previously unselected package opencl-headers.\n",
            "Preparing to unpack .../15-opencl-headers_2.2~2018.02.21-gb5c3680-1_all.deb ...\n",
            "Unpacking opencl-headers (2.2~2018.02.21-gb5c3680-1) ...\n",
            "Setting up libviennacl-dev (1.7.1+dfsg1-2ubuntu1) ...\n",
            "Setting up libgflags2.2 (2.2.1-1) ...\n",
            "Setting up libgflags-dev (2.2.1-1) ...\n",
            "Setting up liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Setting up opencl-clhpp-headers (2.0.10+git12-g5dd8bb9-1) ...\n",
            "Setting up libleveldb1v5:amd64 (1.20-2) ...\n",
            "Setting up libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Setting up libsnappy-dev:amd64 (1.1.7-1) ...\n",
            "Setting up libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Setting up liblmdb-dev:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Setting up lmdb-doc (0.9.21-1ubuntu0.1) ...\n",
            "Setting up libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up opencl-headers (2.2~2018.02.21-gb5c3680-1) ...\n",
            "Setting up libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libleveldb-dev:amd64 (1.20-2) ...\n",
            "Setting up libgoogle-glog-dev (0.3.5-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "--2020-05-29 07:33:02--  https://storage.googleapis.com/cs231n-emotiw/openpose/openpose.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.15.128, 2a00:1450:400c:c09::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.15.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 598708936 (571M) [application/x-tar]\n",
            "Saving to: ‘openpose.tar.gz’\n",
            "\n",
            "openpose.tar.gz     100%[===================>] 570.97M   108MB/s    in 5.6s    \n",
            "\n",
            "2020-05-29 07:33:08 (102 MB/s) - ‘openpose.tar.gz’ saved [598708936/598708936]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af0HXGizRijr",
        "colab_type": "text"
      },
      "source": [
        "#### Set up Google Drive and GCS\n",
        "(if needed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjZXYypgRnVm",
        "colab_type": "code",
        "outputId": "8c4912e2-4baf-418e-b3c1-b2b6e99e927f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Updated property [core/project].\n",
            "gs://cs231n-emotiw/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6HQNWnJShB6",
        "colab_type": "text"
      },
      "source": [
        "#### Retrieve the files\n",
        "\n",
        "The code block below demonstrates how to retrieve the files from GCS. However, feel free to skip this step if the files are already on the local disk or you have Google Drive mounted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1083hIuSoJI",
        "colab_type": "code",
        "outputId": "15bf6dc3-48d2-45a4-f5e8-645ee7293a6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        }
      },
      "source": [
        "!wget https://storage.googleapis.com/cs231n-emotiw/data/train-tiny.zip\n",
        "!wget https://storage.googleapis.com/cs231n-emotiw/data/val-tiny.zip\n",
        "!wget https://storage.googleapis.com/cs231n-emotiw/data/test-tiny.zip\n",
        "!wget https://storage.googleapis.com/cs231n-emotiw/data/Train_labels.txt\n",
        "!wget https://storage.googleapis.com/cs231n-emotiw/data/Val_labels.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-29 07:34:57--  https://storage.googleapis.com/cs231n-emotiw/data/train-tiny.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.15.128, 2a00:1450:400c:c09::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.15.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 50131084 (48M) [application/zip]\n",
            "Saving to: ‘train-tiny.zip’\n",
            "\n",
            "train-tiny.zip      100%[===================>]  47.81M  13.2MB/s    in 3.6s    \n",
            "\n",
            "2020-05-29 07:35:01 (13.2 MB/s) - ‘train-tiny.zip’ saved [50131084/50131084]\n",
            "\n",
            "--2020-05-29 07:35:03--  https://storage.googleapis.com/cs231n-emotiw/data/val-tiny.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.184.128, 2a00:1450:400c:c0a::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.184.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 48020782 (46M) [application/zip]\n",
            "Saving to: ‘val-tiny.zip’\n",
            "\n",
            "val-tiny.zip        100%[===================>]  45.80M  27.1MB/s    in 1.7s    \n",
            "\n",
            "2020-05-29 07:35:06 (27.1 MB/s) - ‘val-tiny.zip’ saved [48020782/48020782]\n",
            "\n",
            "--2020-05-29 07:35:07--  https://storage.googleapis.com/cs231n-emotiw/data/test-tiny.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.15.128, 2a00:1450:400c:c0c::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.15.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 50596135 (48M) [application/zip]\n",
            "Saving to: ‘test-tiny.zip’\n",
            "\n",
            "test-tiny.zip       100%[===================>]  48.25M  60.2MB/s    in 0.8s    \n",
            "\n",
            "2020-05-29 07:35:09 (60.2 MB/s) - ‘test-tiny.zip’ saved [50596135/50596135]\n",
            "\n",
            "--2020-05-29 07:35:10--  https://storage.googleapis.com/cs231n-emotiw/data/Train_labels.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.15.128, 2a00:1450:400c:c09::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.15.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21653 (21K) [text/plain]\n",
            "Saving to: ‘Train_labels.txt’\n",
            "\n",
            "Train_labels.txt    100%[===================>]  21.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-29 07:35:10 (99.1 MB/s) - ‘Train_labels.txt’ saved [21653/21653]\n",
            "\n",
            "--2020-05-29 07:35:11--  https://storage.googleapis.com/cs231n-emotiw/data/Val_labels.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.184.128, 2a00:1450:400c:c0c::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.184.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6265 (6.1K) [text/plain]\n",
            "Saving to: ‘Val_labels.txt’\n",
            "\n",
            "Val_labels.txt      100%[===================>]   6.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-29 07:35:12 (49.7 MB/s) - ‘Val_labels.txt’ saved [6265/6265]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "776lNS68T4pH",
        "colab_type": "text"
      },
      "source": [
        "#### Pre-Processing\n",
        "\n",
        "Here, we will instantiate each of the preprocessors and process all of the input video files.\n",
        "\n",
        "NOTE: Change the input parameters as needed.\n",
        "\n",
        "WARNING: This may take several hours to complete, depending on the number of files.\n",
        "\n",
        "In general, pre-processing will extract the following:\n",
        "- Video frames\n",
        "- Pose keypoints\n",
        "- Faces from each video frame\n",
        "- Audio waveform and audio features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_n68gpZ2Zoz",
        "colab_type": "code",
        "outputId": "bbef95f2-03c7-4259-f440-5ddef274e9cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from src.preprocessors.scene_preprocessor import VideoPreprocessor\n",
        "from src.preprocessors.face_preprocessor import FacePreprocessor\n",
        "from src.preprocessors.pose_preprocessor import PosePreprocessor\n",
        "from src.preprocessors.audio_preprocessor import AudioPreprocessor\n",
        "\n",
        "video_preprocessor = VideoPreprocessor(\n",
        "    video_folder= \"train-tiny.zip\", \n",
        "    label_file= \"Train_labels.txt\", \n",
        "    output_folder=\"train-tiny-local\", \n",
        "    output_file= \"train-tiny-local.zip\"\n",
        ")\n",
        "\n",
        "face_preprocessor = FacePreprocessor(\n",
        "    video_folder=\"train-tiny.zip\",\n",
        "    output_folder=\"train-tiny-faces\", \n",
        "    output_file=\"train-tiny-faces.zip\"\n",
        ")\n",
        "\n",
        "pose_preprocessor = PosePreprocessor(\n",
        "    video_frame_folder=\"val-tiny.zip\",\n",
        "    output_folder=\"val-tiny-pose\", \n",
        "    output_file=\"val-tiny-pose.zip\"\n",
        ")\n",
        "\n",
        "audio_preprocessor = AudioPreprocessor(\n",
        "    output_folder=\"train-tiny-audio\", \n",
        "    output_file= \"train-tiny-audio.zip\" ,\n",
        "    video_folder= \"train-tiny.zip\",\n",
        "    label_path = \"Train_labels.txt\"\n",
        ")\n",
        "\n",
        "preprocessors_list = [video_preprocessor, face_preprocessor, pose_preprocessor, audio_preprocessor] \n",
        "\n",
        "for preprocessor in preprocessors_list:\n",
        "    preprocessor.preprocess()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Video Preprocessor created with is_zip = True, video_folder = train-tiny.zip , label_file = Train_labels.txt , output_folder = train-tiny-local, output_file = train-tiny-local.zip\n",
            "Frames will be created with height = 320 , width = 480 , sample_every = 10\n",
            "Video Preprocessor created with is_zip = True, video_folder = train-tiny.zip , output_folder = train-tiny-faces, output_file = train-tiny-faces.zip\n",
            "Frames will be created with height = 320 , width = 480 , sample_every = 10\n",
            "Pose Preprocessor created with is_zip = True, is_test = False, video_frame_folder = val-tiny.zip , output_folder = val-tiny-pose, output_file = val-tiny-pose.zip\n",
            "Video Preprocessor created with is_zip = True, video_folder = train-tiny.zip , output_folder = train-tiny-audio, output_file = train-tiny-audio.zip\n",
            "Frames will be created with hop_size = 0.5\n",
            "Unzipping files to temp dir train-tiny-local_tmp...\n",
            "Finished unzipping files\n",
            "Found 50 videos\n",
            "Processing video 6/50 with name 122_1.mp4 and class 1 \n",
            "\n",
            "Processing video 2/50 with name 101_30.mp4 and class 1 \n",
            "\n",
            "Processing video 4/50 with name 112_5.mp4 and class 2 \n",
            "\n",
            "Processing video 12/50 with name 188_22.mp4 and class 3 \n",
            "\n",
            "Processing video 7/50 with name 133_2.mp4 and class 1 \n",
            "\n",
            "Processing video 9/50 with name 148_4.mp4 and class 3 \n",
            "\n",
            "Processing video 15/50 with name 204_13.mp4 and class 3 \n",
            "\n",
            "Processing video 11/50 with name 188_15.mp4 and class 3 \n",
            "\n",
            "Processing video 17/50 with name 217_3.mp4 and class 1 \n",
            "\n",
            "Processing video 19/50 with name 258_2.mp4 and class 2 \n",
            "\n",
            "Processing video 23/50 with name 280_12.mp4 and class 1 \n",
            "\n",
            "Processing video 21/50 with name 276_8.mp4 and class 1 \n",
            "\n",
            "Processing video 25/50 with name 286_4.mp4 and class 2 \n",
            "\n",
            "Processing video 29/50 with name 312_1.mp4 and class 2 \n",
            "Processing video 31/50 with name 321_31.mp4 and class 1 \n",
            "\n",
            "\n",
            "Processing video 27/50 with name 300_56.mp4 and class 3 \n",
            "\n",
            "Processing video 1/50 with name 101_12.mp4 and class 3 \n",
            "\n",
            "Processing video 5/50 with name 119_8.mp4 and class 3 \n",
            "\n",
            "Processing video 8/50 with name 140_1.mp4 and class 1 \n",
            "\n",
            "Processing video 14/50 with name 198_5.mp4 and class 3 \n",
            "\n",
            "Processing video 18/50 with name 220_6.mp4 and class 3 \n",
            "\n",
            "Processing video 22/50 with name 277_3.mp4 and class 2 \n",
            "Processing video 26/50 with name 2_2.mp4 and class 3 \n",
            "Processing video 30/50 with name 321_15.mp4 and class 3 \n",
            "\n",
            "Processing video 3/50 with name 108_13.mp4 and class 3 \n",
            "\n",
            "\n",
            "\n",
            "Processing video 10/50 with name 16_14.mp4 and class 1 \n",
            "\n",
            "Processing video 20/50 with name 276_3.mp4 and class 2 \n",
            "\n",
            "Processing video 28/50 with name 303_41.mp4 and class 3 \n",
            "\n",
            "Processing video 13/50 with name 197_12.mp4 and class 1 \n",
            "\n",
            "Processing video 24/50 with name 281_2.mp4 and class 2 \n",
            "\n",
            "Processing video 16/50 with name 217_15.mp4 and class 1 \n",
            "\n",
            "Processing video 32/50 with name 324_34.mp4 and class 2 \n",
            "\n",
            "Processing video 33/50 with name 324_56.mp4 and class 3 \n",
            "\n",
            "Processing video 34/50 with name 324_96.mp4 and class 3 \n",
            "\n",
            "Processing video 35/50 with name 328_13.mp4 and class 3 \n",
            "\n",
            "Processing video 36/50 with name 334_21.mp4 and class 3 \n",
            "\n",
            "Processing video 37/50 with name 33_20.mp4 and class 1 \n",
            "\n",
            "Processing video 38/50 with name 34_9.mp4 and class 2 \n",
            "\n",
            "Processing video 39/50 with name 3_17.mp4 and class 3 \n",
            "\n",
            "Processing video 40/50 with name 3_29.mp4 and class 3 \n",
            "\n",
            "Processing video 41/50 with name 41_18.mp4 and class 1 \n",
            "\n",
            "Processing video 42/50 with name 43_12.mp4 and class 1 \n",
            "\n",
            "Processing video 43/50 with name 52_1.mp4 and class 2 \n",
            "\n",
            "Processing video 44/50 with name 61_15.mp4 and class 1 \n",
            "\n",
            "Processing video 45/50 with name 64_5.mp4 and class 1 \n",
            "\n",
            "Processing video 47/50 with name 69_30.mp4 and class 2 \n",
            "\n",
            "Processing video 46/50 with name 68_9.mp4 and class 1 \n",
            "\n",
            "Processing video 48/50 with name 7_6.mp4 and class 1 \n",
            "\n",
            "Processing video 49/50 with name 80_1.mp4 and class 1 \n",
            "\n",
            "Processing video 50/50 with name 97_22.mp4 and class 3 \n",
            "\n",
            "***** Submitted all tasks *****\n",
            "***** Completed *****\n",
            "Starting to zip files to train-tiny-local.zip\n",
            "Done zipping files to train-tiny-local.zip\n",
            "Done!\n",
            "Unzipping files to temp dir train-tiny-faces_tmp...\n",
            "Finished unzipping files\n",
            "Found 50 videos\n",
            "Processing video 1/50 with name 277_3.mp4 \n",
            "\n",
            "Processing video 2/50 with name 3_29.mp4 \n",
            "\n",
            "Processing video 4/50 with name 112_5.mp4 \n",
            "\n",
            "Processing video 6/50 with name 122_1.mp4 \n",
            "\n",
            "Processing video 10/50 with name 286_4.mp4 \n",
            "\n",
            "Processing video 12/50 with name 33_20.mp4 \n",
            "Processing video 22/50 with name 334_21.mp4 \n",
            "\n",
            "Processing video 24/50 with name 2_2.mp4 \n",
            "\n",
            "Processing video 13/50 with name 300_56.mp4 \n",
            "\n",
            "Processing video 8/50 with name 101_12.mp4 \n",
            "\n",
            "Processing video 26/50 with name 217_3.mp4 \n",
            "\n",
            "Processing video 9/50 with name 324_56.mp4 \n",
            "\n",
            "Processing video 20/50 with name 97_22.mp4 \n",
            "\n",
            "Processing video 5/50 with name 321_15.mp4 \n",
            "\n",
            "Processing video 30/50 with name 303_41.mp4 \n",
            "\n",
            "Processing video 32/50 with name 188_22.mp4 \n",
            "\n",
            "Processing video 18/50 with name 276_8.mp4 \n",
            "\n",
            "Processing video 28/50 with name 69_30.mp4 \n",
            "\n",
            "Processing video 17/50 with name 101_30.mp4 \n",
            "\n",
            "Processing video 16/50 with name 7_6.mp4 \n",
            "\n",
            "\n",
            "Processing video 14/50 with name 61_15.mp4 \n",
            "\n",
            "Processing video 21/50 with name 64_5.mp4 \n",
            "\n",
            "Processing video 7/50 with name 281_2.mp4 \n",
            "\n",
            "Processing video 19/50 with name 324_34.mp4 \n",
            "\n",
            "Processing video 27/50 with name 133_2.mp4 \n",
            "\n",
            "Processing video 23/50 with name 312_1.mp4 \n",
            "\n",
            "Processing video 29/50 with name 3_17.mp4 \n",
            "\n",
            "Processing video 11/50 with name 68_9.mp4 \n",
            "\n",
            "Processing video 25/50 with name 197_12.mp4 \n",
            "\n",
            "Processing video 15/50 with name 16_14.mp4 \n",
            "\n",
            "Processing video 31/50 with name 217_15.mp4 \n",
            "\n",
            "Processing video 3/50 with name 41_18.mp4 \n",
            "\n",
            "Processing video 33/50 with name 108_13.mp4 \n",
            "\n",
            "Processing video 34/50 with name 140_1.mp4 \n",
            "\n",
            "Processing video 35/50 with name 188_15.mp4 \n",
            "\n",
            "Processing video 36/50 with name 220_6.mp4 \n",
            "\n",
            "Processing video 37/50 with name 119_8.mp4 \n",
            "\n",
            "Processing video 38/50 with name 80_1.mp4 \n",
            "\n",
            "Processing video 39/50 with name 324_96.mp4 \n",
            "\n",
            "Processing video 42/50 with name 204_13.mp4 \n",
            "Processing video 41/50 with name 328_13.mp4 \n",
            "\n",
            "Processing video 40/50 with name 43_12.mp4 \n",
            "\n",
            "\n",
            "Processing video 43/50 with name 276_3.mp4 \n",
            "\n",
            "Processing video 44/50 with name 148_4.mp4 \n",
            "\n",
            "Processing video 45/50 with name 280_12.mp4 \n",
            "\n",
            "Processing video 46/50 with name 52_1.mp4 \n",
            "\n",
            "Processing video 47/50 with name 321_31.mp4 \n",
            "\n",
            "Processing video 48/50 with name 258_2.mp4 \n",
            "\n",
            "Processing video 49/50 with name 34_9.mp4 \n",
            "\n",
            "Processing video 50/50 with name 198_5.mp4 \n",
            "\n",
            "***** Submitted all tasks *****\n",
            "***** Completed *****\n",
            "Starting to zip files to train-tiny-faces.zip\n",
            "Done zipping files to train-tiny-faces.zip\n",
            "Done!\n",
            "Unzipping files to temp dir val-tiny-pose_tmp...\n",
            "Finished unzipping files\n",
            "Starting to zip files to val-tiny-pose.zip\n",
            "Done zipping files to val-tiny-pose.zip\n",
            "Done!\n",
            "Unzipping files to temp dir train-tiny-audio_tmp...\n",
            "Finished unzipping files\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 101_12.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 101_30.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 108_13.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 112_5.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 119_8.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 122_1.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 133_2.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 140_1.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 148_4.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 16_14.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 188_15.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 188_22.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 197_12.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 198_5.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 204_13.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 217_15.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 217_3.mp4extracted_audio.wav ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_graph'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8982828b694c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreprocessors_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/cs231n-emotiw/src/preprocessors/audio_preprocessor.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Reading file {output_wav_file} ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mX_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenl3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_audio_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_reads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhop_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/openl3/core.py\u001b[0m in \u001b[0;36mget_audio_embedding\u001b[0;34m(audio, sr, model, input_repr, content_type, embedding_size, center, hop_size, batch_size, verbose)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         model = load_audio_embedding_model(input_repr, content_type,\n\u001b[0;32m--> 199\u001b[0;31m                                            embedding_size)\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0membedding_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/openl3/models.py\u001b[0m in \u001b[0;36mload_audio_embedding_model\u001b[0;34m(input_repr, content_type, embedding_size)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAUDIO_MODELS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_repr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_audio_embedding_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_repr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/openl3/models.py\u001b[0m in \u001b[0;36m_construct_mel256_audio_network\u001b[0;34m()\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;31m# INPUT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mx_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maudio_window_dur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;31m# MELSPECTROGRAM PREPROCESSING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_shape, name, dtype, sparse, tensor)\u001b[0m\n\u001b[1;32m    176\u001b[0m                              \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                              \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                              input_tensor=tensor)\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0;31m# Return tensor including _keras_shape and _keras_history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# Note that in this case train_output and test_output are the same pointer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'input'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_uid\u001b[0;34m(prefix)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0m_GRAPH_UID_DICTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         raise RuntimeError(\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;34m'It looks like you are trying to use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;34m'a version of multi-backend Keras that '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;34m'does not support TensorFlow 2.0. We recommend '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: It looks like you are trying to use a version of multi-backend Keras that does not support TensorFlow 2.0. We recommend using `tf.keras`, or alternatively, downgrading to TensorFlow 1.14."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYFOnVElUVrh",
        "colab_type": "text"
      },
      "source": [
        "#### Predictions\n",
        "After performing pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xwIeRF_x40m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(mp4_dir , train_target_path , model_list= [model,] , model_paths=[\"\",] , num_models = 1 , mode=\"soft\" , complexFusion=False):\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Notes: \n",
        "\n",
        "  All file preprocessing will occur in this function.\n",
        "\n",
        "\n",
        "  Inputs\n",
        "  \n",
        "  * mp4_train_dir - The directory of .mp4 file paths that the model will make predictions from.\n",
        "  * train_target_path - The target path. Should be in .txt format.\n",
        "  * A list of pretrained models that will be used in the ensemble during prediction\n",
        "\n",
        "\n",
        "  Outputs \n",
        "\n",
        "  * An array of size (M) where M is the number of samples\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  assert len(model_list) == num_models\n",
        "  assert len(model_paths) == num_models\n",
        "\n",
        "  all_model_predictions = []\n",
        "  X_list = []\n",
        "\n",
        "  counter = 0\n",
        "\n",
        "  audio = AudioPreprocessor()\n",
        "  face = \n",
        "\n",
        "  # for model in models:\n",
        "  #    # Do preprocess here on a model basis.\n",
        "  #   X =  model.preprocess(\"video path/*.mp4\") # X Can either be a np array or None. Can either read from disk, work with raw files, or return None\n",
        "  #                                             # if using a data generator.\n",
        "  #   X_list.append(X)                             \n",
        "\n",
        "  for model in models:\n",
        "\n",
        "    model.load_model(model_paths[counter])\n",
        "\n",
        "\n",
        "    X = X_list[counter]\n",
        "    \n",
        "   \n",
        "\n",
        "    all_model_predictions.append(model.predict(dir=\"video path/*.mp4\" , X=X)) # Predict returns an (M , 3) array\n",
        "    \n",
        "    counter += 1\n",
        "\n",
        "  all_model_predictions = np.asarray(all_model_predictions , dtype='float32') # (num_models , M , 3)\n",
        "\n",
        "\n",
        "  assert mode in [\"soft\" , \"hard\"]\n",
        "\n",
        "  if mode == \"soft\":\n",
        "\n",
        "    \n",
        "    # Take the average of each \n",
        "\n",
        "    predictions = np.mean(all_model_predictions , axis=0)\n",
        "\n",
        "    predictions = np.argmax(predictions , axis = 1)\n",
        "\n",
        "    return predictions  # (M,) in the domain [0,1,2]\n",
        "\n",
        "  # TODO: Majority vote\n",
        "\n",
        "  positive_hard = np.argmax(positive_arr , axis=1) # ()\n",
        "\n",
        "\n",
        "\n",
        "  return predictions "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TJCeo420Zx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(predictions, targets):\n",
        "\n",
        "  # TO DO: Add evaluate code here\n",
        "\n",
        "  \"\"\"\n",
        "  Inputs\n",
        "  \n",
        "  * predictions np array of shape M where M is the number of samples\n",
        "  * target array of shape M where M is the number of samples\n",
        "\n",
        "\n",
        "  Outputs \n",
        "\n",
        "  * Model accuracy scalar \n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  assert len(targets) == len(predictions)\n",
        "\n",
        "  incorrect = np.count_nonzero(predictions - targets)\n",
        "\n",
        "  acc = (targets.shape[0] - incorrect) / targets.shape[0]\n",
        "\n",
        "  return acc\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}