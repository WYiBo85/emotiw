{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ensemble_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOYYeVh6mI2IS7wvQl+XrXI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevincong95/cs231n-emotiw/blob/master/ensemble_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58avLN7UlDDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone the code base\n",
        "!git clone 'https://github.com/kevincong95/cs231n-emotiw.git'\n",
        "\n",
        "\n",
        "# Install required packages \n",
        "\n",
        "!pip install -r  '/content/cs231n-emotiw/requirements.txt'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVP4etYysz0m",
        "colab_type": "code",
        "outputId": "582697d3-96ff-4e0e-ed27-1777b556dcd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Convert .ipynbs to .py\n",
        "!jupyter nbconvert '/content/cs231n-emotiw/audio/openl3_audio_api.ipynb' --to python\n",
        "\"\"\n",
        "\"\"\n",
        "\"\"\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NbConvertApp] Converting notebook /content/cs231n-emotiw/audio/openl3_audio_api.ipynb to python\n",
            "[NbConvertApp] Writing 12417 bytes to /content/cs231n-emotiw/audio/openl3_audio_api.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpXq8P8aqYrK",
        "colab_type": "code",
        "outputId": "f617201f-e9b4-4231-ed35-ddd227baad56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Import and instantiate all input models\n",
        "!cp '/content/cs231n-emotiw/audio/openl3_audio_api.py' '/content/'\n",
        "\"\"\n",
        "\"\"\n",
        "\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNXOwZ9ct5dm",
        "colab_type": "code",
        "outputId": "59cabdf8-1bf1-437d-afda-bb6857dec16a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from openl3_audio_api import audio_model\n",
        "\"\"\n",
        "\"\"\n",
        "\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_n68gpZ2Zoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate your models\n",
        "\n",
        "audio_model_test = audio_model()\n",
        "\n",
        "model_list = [audio_model_test] #TODO: Add your models here \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xwIeRF_x40m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(mp4_dir , train_target_path , model_list= [model,] , model_paths=[\"\",] , num_models = 1 , mode=\"soft\"):\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Notes: \n",
        "\n",
        "  All file preprocessing will occur in this function.\n",
        "\n",
        "\n",
        "  Inputs\n",
        "  \n",
        "  * mp4_train_dir - The directory of .mp4 file paths that the model will make predictions from.\n",
        "  * train_target_path - The target path. Should be in .txt format.\n",
        "  * A list of pretrained models that will be used in the ensemble during prediction\n",
        "\n",
        "\n",
        "  Outputs \n",
        "\n",
        "  * An array of size (M) where M is the number of samples\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  assert len(model_list) == num_models\n",
        "  assert len(model_paths) == num_models\n",
        "\n",
        "  all_model_predictions = []\n",
        "  \n",
        "  for model in models:\n",
        "\n",
        "    model.load_model(model_paths[counter]) \n",
        "\n",
        "    all_model_predictions.append(model.predict(mp4_dir)) # Predict returns an (M , 3) array\n",
        "\n",
        "   \n",
        "  all_model_predictions = np.asarray(all_model_predictions , dtype='float32') # (num_models , M , 3)\n",
        "\n",
        "\n",
        "  assert mode in [\"soft\" , \"hard\"]\n",
        "\n",
        "  if mode == \"soft\":\n",
        "\n",
        "    \n",
        "    # Take the average of each \n",
        "\n",
        "    predictions = np.mean(all_model_predictions , axis=0)\n",
        "\n",
        "    predictions = np.argmax(predictions , axis = 1)\n",
        "\n",
        "    return predictions  # (M , n classes)\n",
        "\n",
        "  # TODO: Majority vote\n",
        "\n",
        "  positive_hard = np.argmax(positive_arr , axis=1) # ()\n",
        "\n",
        "\n",
        "\n",
        "  return predictions "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TJCeo420Zx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(predictions, targets):\n",
        "\n",
        "  # TO DO: Add evaluate code here\n",
        "\n",
        "  \"\"\"\n",
        "  Inputs\n",
        "  \n",
        "  * predictions np array of shape M where M is the number of samples\n",
        "  * target array of shape M where M is the number of samples\n",
        "\n",
        "\n",
        "  Outputs \n",
        "\n",
        "  * Model accuracy scalar \n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  assert len(targets) == len(predictions)\n",
        "\n",
        "  incorrect = np.count_nonzero(predictions - targets)\n",
        "\n",
        "  acc = (targets.shape[0] - incorrect) / targets.shape[0]\n",
        "\n",
        "  return acc\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}