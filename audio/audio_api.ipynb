{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "audio-api.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevincong95/cs231n-emotiw/blob/master/audio/audio_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPKtwAdgQzil",
        "colab_type": "text"
      },
      "source": [
        "# Audio API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvmKxLO5ba44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_vggish():\n",
        "  pump = vgk.get_pump()\n",
        "  model = vgk.VGGish(pump)\n",
        "\n",
        "  #Create time-stamp for folder name\n",
        "  TIMESTR = time.strftime(\"%Y%m%d-%H%M%S\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aawWIMDLRkFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: add option for soft vs hard\n",
        "def predict(mp4_filepath, best_model_filepath):\n",
        "    \"\"\"\n",
        "    Outputs:\n",
        "    - A tuple with predictions for each class (positive, neutral, negative)\n",
        "    \"\"\"\n",
        "\n",
        "    model = fer_model()\n",
        "    model.load_model(best_model_filepath)\n",
        "    return model.predict(mp4_filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOSIfnb4PRuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class audio_model:\n",
        "    def __init__(self):\n",
        "        self.model = ()\n",
        "        return\n",
        "\n",
        "    def predict(self, mp4_filepath , target_filepath ):\n",
        "        X , y = self.get_feature_batch(mp4_filepath , target_filepath) #Preproccess \n",
        "        X = np.asarray(X) #You may get a bug TODO: trimming \n",
        "\n",
        "        soft_pred = self.model.predict(X)\n",
        "\n",
        "\n",
        "        return soft_pred # (0.1 ,0.2 , 0.7)\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "    def load_model(self, best_model_filepath):\n",
        "        self.model = load_model(best_model_filepath)\n",
        "        \n",
        "        return  \n",
        "\n",
        "    def train(self, X_train , y_train , epochs=500 , batch_size=32 , X_val=None , Y_val=None , val_split=0.1, save_path = None):\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        Train function with the model architecture\n",
        "\n",
        "        - Outputs\n",
        "          1. Trained model -- saves the model as a .h5 file to the specified path\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        #TODO: There are some bugs here \n",
        "        # Next Steps:\n",
        "        # 1. Transfer learning\n",
        "        # 2. Try CNN-LSTM approach \n",
        "        # 3. For deep networks, try residual blocks\n",
        "        # 4. Look for other model architecture to use with openSmile/VggISH/mel-spec features \n",
        "\n",
        "    \n",
        "        inputs = keras.Input(shape=[32,512])\n",
        "\n",
        "        cnn1 =  tf.keras.layers.Conv1D(\n",
        "        512, 3, activation='selu')\n",
        "\n",
        "        maxpool_1 = tf.keras.layers.MaxPooling1D(pool_size=2,\n",
        "   strides=1, padding='valid')\n",
        "        \n",
        "        dropout_1 = tf.keras.layers.Dropout(0.3)\n",
        "\n",
        "        cnn2 =  tf.keras.layers.Conv1D(\n",
        "        512, 3, activation='selu')\n",
        "\n",
        "        maxpool_2 = tf.keras.layers.MaxPooling1D(pool_size=2,\n",
        "   strides=1, padding='valid')\n",
        "        \n",
        "        dropout_2 = tf.keras.layers.Dropout(0.3)\n",
        "\n",
        "        cnn3 =  tf.keras.layers.Conv1D(\n",
        "        512, 3, activation='selu')\n",
        "         \n",
        "\n",
        "        maxpool_3 = tf.keras.layers.MaxPooling1D(pool_size=2,\n",
        "   strides=1, padding='valid')\n",
        "         \n",
        "        dropout_3 = tf.keras.layers.Dropout(0.3)\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "        recurrent_1 = keras.layers.Bidirectional(keras.layers.LSTM(10, return_sequences=True, input_shape=[None, 512] ,                                                                   dropout=0.2 , activation='selu')) #A sequence of any length with dimensions 512 (i.e. 512 columns\n",
        "        recurrent_2 = keras.layers.Bidirectional(keras.layers.LSTM(5))\n",
        "        dense_1 = keras.layers.Dense(32 , activation='selu')\n",
        "        dropout_1 = keras.layers.Dropout(0.5)\n",
        "        softmax = keras.layers.Dense(3 , activation='softmax')\n",
        "\n",
        "        # x = cnn1(inputs)\n",
        "        # x = maxpool_1(x)\n",
        "        # x = dropout_1(x)\n",
        "        # x = cnn2(x)\n",
        "        # x = maxpool_2(x)\n",
        "        # x = dropout_2(x)\n",
        "        # x = cnn3(x)\n",
        "        # x = maxpool_3(x)\n",
        "        # x = dropout_3(x)\n",
        "        # x = recurrent_1(x)\n",
        "        # x = recurrent_2(x)\n",
        "        # x = dense_1(x)\n",
        "        # x = dropout_1(x)\n",
        "        # outputs = softmax(x)\n",
        "\n",
        "        inputs = keras.Input(shape=[16,512])\n",
        "\n",
        "        recurrent_1 = keras.layers.Bidirectional(keras.layers.LSTM(10, return_sequences=True, input_shape=[None, 512] ,                                                                   dropout=0.2 , activation='selu')) #A sequence of any length with dimensions 512 (i.e. 512 columns\n",
        "        recurrent_2 = keras.layers.Bidirectional(keras.layers.LSTM(5))\n",
        "        dense_1 = keras.layers.Dense(32 , activation='selu')\n",
        "        dropout_1 = keras.layers.Dropout(0.5)\n",
        "        softmax = keras.layers.Dense(3 , activation='softmax')\n",
        "\n",
        "        x = recurrent_1(inputs)\n",
        "        x = recurrent_2(x)\n",
        "        x = dense_1(x)\n",
        "        x = dropout_1(x)\n",
        "        outputs = softmax(x)\n",
        "\n",
        "        rnn_ae = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate=1e-4,\n",
        "        decay_steps=10000,\n",
        "        decay_rate=0.9)\n",
        "        opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "        rnn_ae.compile(loss='sparse_categorical_crossentropy' , optimizer=opt , metrics=['accuracy'])\n",
        "\n",
        "        history = None \n",
        "\n",
        "        if X_val == None and Y_val == None:\n",
        "          history = rnn_ae.fit(X_train , y_train , epochs=epochs , batch_size=batch_size,  validation_split=val_split)\n",
        "\n",
        "        else:\n",
        "          history = rnn_ae.fit(X_train , y_train , epochs=epochs , batch_size=batch_size,  validation_data=(X_val, Y_val))\n",
        "\n",
        "\n",
        "        if save_path != None:\n",
        "          assert save_path[-3:] == '.h5'\n",
        "          rnn_ae.save(save_path)\n",
        "        return rnn_ae , history\n",
        "\n",
        "\n",
        "    #Function to slice up the audio.\n",
        "    def slice_audio(self, files, channels, outformat, width, rate, slice_length, slide):\n",
        "        out_files = []\n",
        "        \n",
        "        outformat = outformat.replace('.','').lower()\n",
        "        #Allow the user to see their x-bit selection with this dictionary.\n",
        "        width_translator = {1:'8-bit', 2:'16-bit', 4:'32-bit'}\n",
        "        #For every file in the input list do processing.\n",
        "        for file in files:\n",
        "            print(file)\n",
        "            fileName, fileExtension = os.path.splitext(file)\n",
        "            #Store the file in RAM.\n",
        "            sound = AudioSegment.from_file(file, fileExtension.replace('.','').lower())\n",
        "            #Print the 'x-bit' conversion parameters.\n",
        "            print (width_translator[sound.sample_width]+' to '+width_translator[int(width)]+'.\\n')\n",
        "            #Implement the user-selected or default (if nothing selected) parameters for processing.\n",
        "            sound = sound.set_frame_rate(int(rate))\n",
        "            sound = sound.set_sample_width(int(width))\n",
        "            sound = sound.set_channels(int(channels))\n",
        "            length_sound_ms = len(sound)\n",
        "            length_slice_ms = int(slice_length)\n",
        "            slice_start = 0\n",
        "            #create audiosegment object\n",
        "            notes_reversed = sound[0:1].reverse()\n",
        "            #Begin slicing at the start of the file.\n",
        "            while slice_start + length_slice_ms < length_sound_ms:\n",
        "                sound_slice = sound[slice_start:slice_start+length_slice_ms]\n",
        "                backwards = sound_slice.reverse()\n",
        "                notes_reversed += backwards\n",
        "                sound_slice.export('to_zip/'+ fileName+'.slice'+str(slice_start/1000)+'SecsTo'+str((slice_start+length_slice_ms)/1000)+'Secs.'+outformat, format=outformat)\n",
        "                \n",
        "                out_files.append('to_zip/'+ fileName+'.slice'+str(slice_start/1000)+'SecsTo'+str((slice_start+length_slice_ms)/1000)+'Secs.'+outformat)\n",
        "                \n",
        "                #backwards.export( fileName+'backwards_slice'+str(slice_start/1000)+'SecsTo'+str((slice_start+length_slice_ms)/1000)+'Secs.'+outformat, format=outformat)\n",
        "                slice_start += int(slide)\n",
        "            #When the slice is abutting the end of the file, output that slice too.'\n",
        "            if slice_start + length_slice_ms >= length_sound_ms:\n",
        "                sound_slice = sound[slice_start:length_sound_ms]\n",
        "                backwards = sound_slice.reverse()\n",
        "                notes_reversed += backwards\n",
        "                sound_slice.export('to_zip/'+fileName+'.slice'+str(slice_start/1000)+'SecsToEndFileAt'+str((length_sound_ms)/1000)+'Secs.'+outformat, format=outformat)\n",
        "                \n",
        "                out_files.append('to_zip/'+fileName+'.slice'+str(slice_start/1000)+'SecsToEndFileAt'+str((length_sound_ms)/1000)+'Secs.'+outformat)\n",
        "                \n",
        "                #backwards.export(fileName+'backwards_slice'+str(slice_start/1000)+'SecsToEndFileAt'+str((slice_start+length_slice_ms)/1000)+'Secs.'+outformat, format=outformat)\n",
        "            #Save the sewn together backwards bits to file\n",
        "            #notes_reversed.export(fileName+'notes_reversed_granular.'+outformat, format=outformat)\n",
        "\n",
        "        return out_files\n",
        "    def preprocess(self, mp4_filepath , target_label_path=None , hop_int=1):\n",
        "\n",
        "      \"\"\"\n",
        "      Outputs:\n",
        "      - A numpy array with dimensions (m,n). \n",
        "        - m is the units in time dependent on the audio splice rate.\n",
        "        - n is the number of features from the openSMILE library.\n",
        "      \"\"\"\n",
        "\n",
        "      print(f\"Processing file {mp4_filepath} ...\")\n",
        "\n",
        "\n",
        "      output_wav_file = mp4_filepath.split(\"/\")[-1] + 'extracted_audio.wav'\n",
        "      mp4_filename = os.path.basename(mp4_filepath)\n",
        "      audio_home_dir = os.path.dirname(mp4_filepath)\n",
        "\n",
        "      # Strip the audio from video and store as .wav file\n",
        "      ffmpeg_extract_audio(mp4_filepath, output_wav_file)\n",
        "\n",
        "      files_written = self.slice_audio([output_wav_file], 2, \"wav\", 2, 30000, 2000, 100)\n",
        "\n",
        "      X_arr = []\n",
        "\n",
        "      # VGGish feature extraction\n",
        "      #out_fn = os.path.join('/content/openSmile-features.arff')\n",
        "      counter = 0\n",
        "      for in_fn in files_written:\n",
        "        name = os.path.basename(in_fn)\n",
        "        if counter % hop_int == 0: # Choose every hop_int splice\n",
        "          X = pump.transform(in_fn)[vgk.params.PUMP_INPUT]\n",
        "          X_arr.append(X)        \n",
        "        counter += 1\n",
        "\n",
        "      for in_fn in files_written:\n",
        "        os.remove(in_fn)\n",
        "\n",
        "      # Get the Y values \n",
        "      target = None \n",
        "      if target_label_path is not None:\n",
        "          target_labels = np.genfromtxt(target_label_path , delimiter = ' ' , dtype='str')\n",
        "          target_index = np.where(target_labels[: , 0] == mp4_filename[:-4])[0]\n",
        "          target = int(target_labels[: , 1][target_index])\n",
        "\n",
        "      \n",
        "      return X_arr , target\n",
        "\n",
        "\n",
        "      # Read in each video file and add the (m,n) feature matrix to a 3D array\n",
        "\n",
        "    def get_feature_batch(self, input_files_dir , batch_size=3000 , target_label_path=None):\n",
        "        \"\"\"\n",
        "        Inputs: \n",
        "        - Path to the .mp4 files\n",
        "        Outputs:\n",
        "        - An ndarray with dims (s , m , n)\n",
        "          - s is the number of samples\n",
        "          - m is the number of slices for that sample (32)\n",
        "          - n is the number of features (512)\n",
        "        \"\"\"\n",
        "\n",
        "        output_x = []\n",
        "        output_y = None\n",
        "\n",
        "        if target_label_path is not None:\n",
        "          output_y = []\n",
        "\n",
        "\n",
        "        counter = 1\n",
        "\n",
        "        fileList = glob.glob(input_files_dir + '*.mp4')\n",
        "\n",
        "        MAX_WORKERS = 32\n",
        "\n",
        "        futures = []\n",
        "        with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "            for file_path in fileList:\n",
        "            \n",
        "                print(f\"Submitting {counter} - {file_path}\")\n",
        "\n",
        "                # one_sample_feat_matrix , y = self.preprocess(file_path , target_label_path=target_label_path)\n",
        "\n",
        "                future = executor.submit(self.preprocess, file_path, target_label_path)\n",
        "                futures.append(future)\n",
        "\n",
        "                if counter >= batch_size:\n",
        "                    break\n",
        "\n",
        "                counter += 1\n",
        "\n",
        "        print(\"***** Submitted all tasks *****\")\n",
        "\n",
        "        k = 0\n",
        "        for future in futures:\n",
        "            X_arr, y = future.result()\n",
        "\n",
        "            Z_arr = []\n",
        "            for X in X_arr:\n",
        "                # np.concatenate([X]*5)\n",
        "                Z = model.predict(X)\n",
        "                Z_arr += [Z]\n",
        "\n",
        "            Z_arr = np.asarray(Z_arr , dtype='float32')\n",
        "            Z_arr = Z_arr.squeeze()\n",
        "\n",
        "            # Standardize\n",
        "            scaler = StandardScaler()\n",
        "            last_index = min(Z_arr.shape[0], 32)\n",
        "            Z_arr = Z_arr[:last_index] #Trim \n",
        "            all_timepoints_feature_array = scaler.fit_transform(Z_arr)\n",
        "\n",
        "            print(all_timepoints_feature_array.shape)\n",
        "\n",
        "            print(f\"Finished future {k}\")\n",
        "            output_x.append(all_timepoints_feature_array)\n",
        "            if target_label_path is not None:        \n",
        "              output_y.append(y)\n",
        "            future.result()\n",
        "            k += 1\n",
        "        print(\"***** Completed *****\")\n",
        "\n",
        "        output_y = np.asarray(output_y)\n",
        "        output_y -= 1\n",
        "        output_x = np.asarray(output_x)\n",
        "        output_np_x = np.zeros((len(output_x) , 32 , 512))\n",
        "\n",
        "\n",
        "\n",
        "        for i in range(len(output_x)):\n",
        "          for j in range(output_x[i].shape[0]):\n",
        "            for k in range(512):\n",
        "              output_np_x[i][j][k] = output_x[i][j][k]\n",
        "\n",
        "       \n",
        "\n",
        "        return output_np_x , output_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5lfxK8Nb5A8",
        "colab_type": "text"
      },
      "source": [
        "# Main Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBAbNurmQFAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "  import subprocess\n",
        "\n",
        "  subprocess.check_output(\"pip install pydub\", shell=True)\n",
        "  subprocess.check_output(\"pip install vggish-keras==0.0.18\", shell=True)\n",
        "  subprocess.check_output(\"pip install git+https://github.com/beasteers/pumpp@tf_keras\", shell=True) #Update the path base.py file\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive' , force_remount=True)\n",
        "  #Patch\n",
        "  subprocess.check_output(\"cp -f '/content/gdrive/My Drive/Machine-Learning-Projects/cs231n-project/notebooks/base.py' '/usr/local/lib/python3.6/dist-packages/pumpp/feature/base.py'\", shell=True)\n",
        "\n",
        "\n",
        "  from tensorflow.keras.models import load_model\n",
        "  from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_audio\n",
        "  import glob\n",
        "  import time\n",
        "  import importlib\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  from subprocess import Popen, PIPE, STDOUT\n",
        "  import librosa\n",
        "  import os\n",
        "  import pickle\n",
        "\n",
        "\n",
        "\n",
        "  from pydub import AudioSegment\n",
        "  import argparse\n",
        "  import audioread\n",
        "  import time\n",
        "  import numpy as np\n",
        "  import subprocess\n",
        "  from tensorflow import keras\n",
        "  import tensorflow as tf\n",
        "\n",
        "  from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
        "  from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
        "  import vggish_keras as vgk\n",
        "  importlib.reload(vgk)\n",
        "  pump = vgk.get_pump()\n",
        "  model = vgk.VGGish(pump) \n",
        "\n",
        "  # Instantiate audio_model object\n",
        "  model_test = audio_model()\n",
        "\n",
        "  # Extract and preprocess X_train and Y_train from .mp4 file paths\n",
        "\n",
        "  subprocess.check_output(\"cp '/content/gdrive/My Drive/Machine-Learning-Projects/cs231n-project/datasets/emotiw/Train.zip' '/content/'\", shell=True)\n",
        "  subprocess.check_output(\"unzip Train.zip\", shell=True)\n",
        "  subprocess.check_output(\"mkdir to_zip\", shell = True)\n",
        "\n",
        "  subprocess.check_output(\"cp '/content/gdrive/My Drive/Machine-Learning-Projects/cs231n-project/datasets/emotiw/Train_labels.txt' '/content/'\", shell=True)\n",
        "  X_train, Y_train = model_test.get_feature_batch('Train/' , batch_size=3000 , target_label_path='Train_labels.txt')\n",
        "  with open('/content/gdrive/My Drive/Machine-Learning-Projects/cs231n-project/notebooks/audio-new/arrays/np_arrays/100ms-32-unit-seq-vggish.x_train.pickle', 'wb') as f:\n",
        "    pickle.dump(X_train, f) \n",
        "  with open('/content/gdrive/My Drive/Machine-Learning-Projects/cs231n-project/notebooks/audio-new/arrays/np_arrays/100ms-32-unit-seq-vggish.y_train.pickle', 'wb') as f:\n",
        "    pickle.dump(Y_train, f)   \n",
        "  # Train the model\n",
        "\n",
        "  model_test = audio_model()\n",
        "  model, history = model_test.train(X_train, Y_train , save_path='/content/gdrive/My Drive/Machine-Learning-Projects/cs231n-project/notebooks/audio-new/models/api_train_test-1.h5' )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtgHGMFzJqcq",
        "colab_type": "code",
        "outputId": "5e51e394-9092-4ae2-9b87-19f0c6d30cc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_test = audio_model()\n",
        "X_train = np.load('/content/gdrive/My Drive/Machine-Learning-Projects/cs231n-project/notebooks/audio-new/arrays/audio.train-vggish-standardized_X-test.all-2-np.pickle'\n",
        ", allow_pickle=True)\n",
        "Y_train = np.load('/content/gdrive/My Drive/Machine-Learning-Projects/cs231n-project/notebooks/audio-new/arrays/audio.train-vggish-standardized_y-test.all-2-np.pickle'\n",
        ", allow_pickle=True)\n",
        "model, history = model_test.train(X_train, Y_train , val_split=0.25 ,  save_path='/content/gdrive/My Drive/Machine-Learning-Projects/cs231n-project/notebooks/audio-new/models/api_train_test-2-500-epochs-200ms-stride.h5' )\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/500\n",
            "63/63 [==============================] - 6s 93ms/step - loss: 1.1671 - accuracy: 0.3338 - val_loss: 1.1377 - val_accuracy: 0.3143\n",
            "Epoch 2/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 1.1440 - accuracy: 0.3434 - val_loss: 1.1308 - val_accuracy: 0.3233\n",
            "Epoch 3/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 1.1264 - accuracy: 0.3579 - val_loss: 1.1256 - val_accuracy: 0.3308\n",
            "Epoch 4/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 1.1243 - accuracy: 0.3514 - val_loss: 1.1225 - val_accuracy: 0.3338\n",
            "Epoch 5/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 1.1193 - accuracy: 0.3645 - val_loss: 1.1214 - val_accuracy: 0.3263\n",
            "Epoch 6/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 1.1092 - accuracy: 0.3574 - val_loss: 1.1163 - val_accuracy: 0.3263\n",
            "Epoch 7/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 1.0998 - accuracy: 0.3845 - val_loss: 1.1123 - val_accuracy: 0.3278\n",
            "Epoch 8/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 1.0995 - accuracy: 0.3911 - val_loss: 1.1101 - val_accuracy: 0.3323\n",
            "Epoch 9/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 1.1028 - accuracy: 0.3750 - val_loss: 1.1086 - val_accuracy: 0.3504\n",
            "Epoch 10/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 1.0965 - accuracy: 0.3891 - val_loss: 1.1104 - val_accuracy: 0.3414\n",
            "Epoch 11/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 1.0907 - accuracy: 0.3835 - val_loss: 1.1111 - val_accuracy: 0.3429\n",
            "Epoch 12/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 1.0785 - accuracy: 0.4041 - val_loss: 1.1117 - val_accuracy: 0.3353\n",
            "Epoch 13/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 1.0738 - accuracy: 0.4177 - val_loss: 1.1089 - val_accuracy: 0.3398\n",
            "Epoch 14/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 1.0683 - accuracy: 0.4347 - val_loss: 1.1073 - val_accuracy: 0.3414\n",
            "Epoch 15/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 1.0780 - accuracy: 0.4021 - val_loss: 1.1073 - val_accuracy: 0.3534\n",
            "Epoch 16/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 1.0671 - accuracy: 0.4307 - val_loss: 1.1067 - val_accuracy: 0.3444\n",
            "Epoch 17/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 1.0652 - accuracy: 0.4272 - val_loss: 1.1041 - val_accuracy: 0.3564\n",
            "Epoch 18/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 1.0538 - accuracy: 0.4463 - val_loss: 1.1033 - val_accuracy: 0.3669\n",
            "Epoch 19/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 1.0519 - accuracy: 0.4443 - val_loss: 1.1038 - val_accuracy: 0.3684\n",
            "Epoch 20/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 1.0573 - accuracy: 0.4388 - val_loss: 1.1055 - val_accuracy: 0.3714\n",
            "Epoch 21/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 1.0447 - accuracy: 0.4588 - val_loss: 1.1092 - val_accuracy: 0.3669\n",
            "Epoch 22/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 1.0384 - accuracy: 0.4568 - val_loss: 1.1089 - val_accuracy: 0.3654\n",
            "Epoch 23/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 1.0397 - accuracy: 0.4608 - val_loss: 1.1061 - val_accuracy: 0.3759\n",
            "Epoch 24/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 1.0198 - accuracy: 0.4915 - val_loss: 1.1061 - val_accuracy: 0.3729\n",
            "Epoch 25/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 1.0237 - accuracy: 0.4910 - val_loss: 1.1029 - val_accuracy: 0.3820\n",
            "Epoch 26/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 1.0121 - accuracy: 0.4880 - val_loss: 1.1055 - val_accuracy: 0.3789\n",
            "Epoch 27/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 1.0170 - accuracy: 0.4940 - val_loss: 1.1037 - val_accuracy: 0.3774\n",
            "Epoch 28/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 1.0023 - accuracy: 0.5090 - val_loss: 1.1054 - val_accuracy: 0.3865\n",
            "Epoch 29/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 1.0034 - accuracy: 0.4995 - val_loss: 1.1048 - val_accuracy: 0.3850\n",
            "Epoch 30/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 1.0000 - accuracy: 0.5045 - val_loss: 1.1034 - val_accuracy: 0.3744\n",
            "Epoch 31/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.9883 - accuracy: 0.5226 - val_loss: 1.1013 - val_accuracy: 0.3895\n",
            "Epoch 32/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.9729 - accuracy: 0.5256 - val_loss: 1.1094 - val_accuracy: 0.3940\n",
            "Epoch 33/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.9671 - accuracy: 0.5377 - val_loss: 1.1051 - val_accuracy: 0.3985\n",
            "Epoch 34/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.9637 - accuracy: 0.5377 - val_loss: 1.1058 - val_accuracy: 0.3940\n",
            "Epoch 35/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.9494 - accuracy: 0.5557 - val_loss: 1.1113 - val_accuracy: 0.3940\n",
            "Epoch 36/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.9550 - accuracy: 0.5457 - val_loss: 1.1100 - val_accuracy: 0.4000\n",
            "Epoch 37/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.9457 - accuracy: 0.5512 - val_loss: 1.1110 - val_accuracy: 0.3910\n",
            "Epoch 38/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.9401 - accuracy: 0.5703 - val_loss: 1.1159 - val_accuracy: 0.4030\n",
            "Epoch 39/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.9258 - accuracy: 0.5788 - val_loss: 1.1146 - val_accuracy: 0.4045\n",
            "Epoch 40/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.9091 - accuracy: 0.5889 - val_loss: 1.1224 - val_accuracy: 0.4000\n",
            "Epoch 41/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.9090 - accuracy: 0.5889 - val_loss: 1.1195 - val_accuracy: 0.3940\n",
            "Epoch 42/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.8995 - accuracy: 0.5863 - val_loss: 1.1220 - val_accuracy: 0.4090\n",
            "Epoch 43/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.9052 - accuracy: 0.5868 - val_loss: 1.1173 - val_accuracy: 0.4015\n",
            "Epoch 44/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.8770 - accuracy: 0.6024 - val_loss: 1.1305 - val_accuracy: 0.4000\n",
            "Epoch 45/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.8713 - accuracy: 0.6049 - val_loss: 1.1290 - val_accuracy: 0.4120\n",
            "Epoch 46/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.8641 - accuracy: 0.6079 - val_loss: 1.1332 - val_accuracy: 0.4211\n",
            "Epoch 47/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.8692 - accuracy: 0.6165 - val_loss: 1.1332 - val_accuracy: 0.4000\n",
            "Epoch 48/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.8509 - accuracy: 0.6310 - val_loss: 1.1394 - val_accuracy: 0.4120\n",
            "Epoch 49/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.8375 - accuracy: 0.6350 - val_loss: 1.1466 - val_accuracy: 0.4060\n",
            "Epoch 50/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.8285 - accuracy: 0.6391 - val_loss: 1.1529 - val_accuracy: 0.3955\n",
            "Epoch 51/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.8239 - accuracy: 0.6446 - val_loss: 1.1563 - val_accuracy: 0.4030\n",
            "Epoch 52/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.7921 - accuracy: 0.6632 - val_loss: 1.1553 - val_accuracy: 0.4030\n",
            "Epoch 53/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.8031 - accuracy: 0.6531 - val_loss: 1.1599 - val_accuracy: 0.4120\n",
            "Epoch 54/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.7816 - accuracy: 0.6692 - val_loss: 1.1677 - val_accuracy: 0.4165\n",
            "Epoch 55/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.7770 - accuracy: 0.6571 - val_loss: 1.1706 - val_accuracy: 0.4030\n",
            "Epoch 56/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.7580 - accuracy: 0.6872 - val_loss: 1.1728 - val_accuracy: 0.4135\n",
            "Epoch 57/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.7408 - accuracy: 0.6978 - val_loss: 1.1828 - val_accuracy: 0.4165\n",
            "Epoch 58/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.7470 - accuracy: 0.6772 - val_loss: 1.1866 - val_accuracy: 0.4090\n",
            "Epoch 59/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.7334 - accuracy: 0.6913 - val_loss: 1.1869 - val_accuracy: 0.4180\n",
            "Epoch 60/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.7239 - accuracy: 0.7033 - val_loss: 1.1973 - val_accuracy: 0.4241\n",
            "Epoch 61/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.7138 - accuracy: 0.7134 - val_loss: 1.2037 - val_accuracy: 0.4226\n",
            "Epoch 62/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.7059 - accuracy: 0.7038 - val_loss: 1.2169 - val_accuracy: 0.4180\n",
            "Epoch 63/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.7067 - accuracy: 0.7113 - val_loss: 1.2181 - val_accuracy: 0.4120\n",
            "Epoch 64/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.6976 - accuracy: 0.7174 - val_loss: 1.2194 - val_accuracy: 0.4256\n",
            "Epoch 65/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.6805 - accuracy: 0.7344 - val_loss: 1.2420 - val_accuracy: 0.4180\n",
            "Epoch 66/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.6752 - accuracy: 0.7189 - val_loss: 1.2332 - val_accuracy: 0.4226\n",
            "Epoch 67/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.6381 - accuracy: 0.7450 - val_loss: 1.2586 - val_accuracy: 0.4135\n",
            "Epoch 68/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.6698 - accuracy: 0.7339 - val_loss: 1.2555 - val_accuracy: 0.4331\n",
            "Epoch 69/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.6680 - accuracy: 0.7374 - val_loss: 1.2462 - val_accuracy: 0.4241\n",
            "Epoch 70/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.6595 - accuracy: 0.7219 - val_loss: 1.2566 - val_accuracy: 0.4195\n",
            "Epoch 71/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.6396 - accuracy: 0.7400 - val_loss: 1.2624 - val_accuracy: 0.4271\n",
            "Epoch 72/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.6381 - accuracy: 0.7500 - val_loss: 1.2540 - val_accuracy: 0.4301\n",
            "Epoch 73/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.6028 - accuracy: 0.7615 - val_loss: 1.2757 - val_accuracy: 0.4256\n",
            "Epoch 74/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.6137 - accuracy: 0.7560 - val_loss: 1.2914 - val_accuracy: 0.4211\n",
            "Epoch 75/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.6251 - accuracy: 0.7575 - val_loss: 1.3263 - val_accuracy: 0.4135\n",
            "Epoch 76/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.6079 - accuracy: 0.7525 - val_loss: 1.3227 - val_accuracy: 0.4226\n",
            "Epoch 77/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.5982 - accuracy: 0.7731 - val_loss: 1.3132 - val_accuracy: 0.4105\n",
            "Epoch 78/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.5841 - accuracy: 0.7761 - val_loss: 1.3174 - val_accuracy: 0.4241\n",
            "Epoch 79/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.5762 - accuracy: 0.7771 - val_loss: 1.3376 - val_accuracy: 0.4331\n",
            "Epoch 80/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.5487 - accuracy: 0.7882 - val_loss: 1.3373 - val_accuracy: 0.4241\n",
            "Epoch 81/500\n",
            "63/63 [==============================] - 5s 80ms/step - loss: 0.5593 - accuracy: 0.7726 - val_loss: 1.3566 - val_accuracy: 0.4120\n",
            "Epoch 82/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.5658 - accuracy: 0.7806 - val_loss: 1.3524 - val_accuracy: 0.4075\n",
            "Epoch 83/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.5529 - accuracy: 0.7851 - val_loss: 1.3615 - val_accuracy: 0.4135\n",
            "Epoch 84/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.5394 - accuracy: 0.7846 - val_loss: 1.3579 - val_accuracy: 0.4226\n",
            "Epoch 85/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.5244 - accuracy: 0.8042 - val_loss: 1.3791 - val_accuracy: 0.4150\n",
            "Epoch 86/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.5050 - accuracy: 0.8077 - val_loss: 1.3732 - val_accuracy: 0.4195\n",
            "Epoch 87/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.5057 - accuracy: 0.7987 - val_loss: 1.3977 - val_accuracy: 0.4150\n",
            "Epoch 88/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.5071 - accuracy: 0.8077 - val_loss: 1.3856 - val_accuracy: 0.4180\n",
            "Epoch 89/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.4988 - accuracy: 0.8092 - val_loss: 1.4122 - val_accuracy: 0.4226\n",
            "Epoch 90/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.4999 - accuracy: 0.8102 - val_loss: 1.4235 - val_accuracy: 0.4211\n",
            "Epoch 91/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.4737 - accuracy: 0.8288 - val_loss: 1.4264 - val_accuracy: 0.4256\n",
            "Epoch 92/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.4540 - accuracy: 0.8318 - val_loss: 1.4368 - val_accuracy: 0.4120\n",
            "Epoch 93/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.4895 - accuracy: 0.8163 - val_loss: 1.4680 - val_accuracy: 0.4045\n",
            "Epoch 94/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.4760 - accuracy: 0.8163 - val_loss: 1.4455 - val_accuracy: 0.4195\n",
            "Epoch 95/500\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.4757 - accuracy: 0.8208 - val_loss: 1.4542 - val_accuracy: 0.4286\n",
            "Epoch 96/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.4347 - accuracy: 0.8379 - val_loss: 1.4607 - val_accuracy: 0.4241\n",
            "Epoch 97/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.4477 - accuracy: 0.8288 - val_loss: 1.4816 - val_accuracy: 0.4286\n",
            "Epoch 98/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.4329 - accuracy: 0.8409 - val_loss: 1.4924 - val_accuracy: 0.4451\n",
            "Epoch 99/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.4324 - accuracy: 0.8514 - val_loss: 1.5083 - val_accuracy: 0.4271\n",
            "Epoch 100/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.4323 - accuracy: 0.8343 - val_loss: 1.4950 - val_accuracy: 0.4316\n",
            "Epoch 101/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.4142 - accuracy: 0.8454 - val_loss: 1.5212 - val_accuracy: 0.4406\n",
            "Epoch 102/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.4055 - accuracy: 0.8484 - val_loss: 1.5395 - val_accuracy: 0.4256\n",
            "Epoch 103/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.4130 - accuracy: 0.8404 - val_loss: 1.5411 - val_accuracy: 0.4286\n",
            "Epoch 104/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.4148 - accuracy: 0.8404 - val_loss: 1.5496 - val_accuracy: 0.4226\n",
            "Epoch 105/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.4167 - accuracy: 0.8429 - val_loss: 1.5629 - val_accuracy: 0.4211\n",
            "Epoch 106/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.3994 - accuracy: 0.8529 - val_loss: 1.5612 - val_accuracy: 0.4256\n",
            "Epoch 107/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.3740 - accuracy: 0.8690 - val_loss: 1.5828 - val_accuracy: 0.4271\n",
            "Epoch 108/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.3977 - accuracy: 0.8549 - val_loss: 1.5852 - val_accuracy: 0.4241\n",
            "Epoch 109/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.3801 - accuracy: 0.8690 - val_loss: 1.6074 - val_accuracy: 0.4286\n",
            "Epoch 110/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.3794 - accuracy: 0.8549 - val_loss: 1.6153 - val_accuracy: 0.4301\n",
            "Epoch 111/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.3724 - accuracy: 0.8624 - val_loss: 1.6041 - val_accuracy: 0.4301\n",
            "Epoch 112/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.3603 - accuracy: 0.8765 - val_loss: 1.6276 - val_accuracy: 0.4241\n",
            "Epoch 113/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.3474 - accuracy: 0.8770 - val_loss: 1.6464 - val_accuracy: 0.4241\n",
            "Epoch 114/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.3566 - accuracy: 0.8690 - val_loss: 1.6434 - val_accuracy: 0.4316\n",
            "Epoch 115/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.3599 - accuracy: 0.8720 - val_loss: 1.6307 - val_accuracy: 0.4271\n",
            "Epoch 116/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.3645 - accuracy: 0.8700 - val_loss: 1.6620 - val_accuracy: 0.4195\n",
            "Epoch 117/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.3381 - accuracy: 0.8775 - val_loss: 1.6784 - val_accuracy: 0.4241\n",
            "Epoch 118/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.3326 - accuracy: 0.8820 - val_loss: 1.6907 - val_accuracy: 0.4301\n",
            "Epoch 119/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.3374 - accuracy: 0.8825 - val_loss: 1.6921 - val_accuracy: 0.4180\n",
            "Epoch 120/500\n",
            "63/63 [==============================] - 5s 80ms/step - loss: 0.3325 - accuracy: 0.8825 - val_loss: 1.7062 - val_accuracy: 0.4195\n",
            "Epoch 121/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.3306 - accuracy: 0.8830 - val_loss: 1.6975 - val_accuracy: 0.4256\n",
            "Epoch 122/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.3289 - accuracy: 0.8835 - val_loss: 1.7084 - val_accuracy: 0.4090\n",
            "Epoch 123/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.3367 - accuracy: 0.8725 - val_loss: 1.7365 - val_accuracy: 0.4045\n",
            "Epoch 124/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.3160 - accuracy: 0.8860 - val_loss: 1.7653 - val_accuracy: 0.4120\n",
            "Epoch 125/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.3037 - accuracy: 0.8921 - val_loss: 1.7659 - val_accuracy: 0.4286\n",
            "Epoch 126/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.3160 - accuracy: 0.8891 - val_loss: 1.7530 - val_accuracy: 0.4316\n",
            "Epoch 127/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.2971 - accuracy: 0.8936 - val_loss: 1.7866 - val_accuracy: 0.4271\n",
            "Epoch 128/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.2896 - accuracy: 0.8956 - val_loss: 1.7592 - val_accuracy: 0.4271\n",
            "Epoch 129/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.3052 - accuracy: 0.8956 - val_loss: 1.7735 - val_accuracy: 0.4331\n",
            "Epoch 130/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.2938 - accuracy: 0.8951 - val_loss: 1.7797 - val_accuracy: 0.4286\n",
            "Epoch 131/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.2922 - accuracy: 0.8961 - val_loss: 1.7728 - val_accuracy: 0.4391\n",
            "Epoch 132/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.2864 - accuracy: 0.8991 - val_loss: 1.8203 - val_accuracy: 0.4271\n",
            "Epoch 133/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.2870 - accuracy: 0.8941 - val_loss: 1.8448 - val_accuracy: 0.4211\n",
            "Epoch 134/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.2690 - accuracy: 0.9061 - val_loss: 1.8344 - val_accuracy: 0.4180\n",
            "Epoch 135/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.2745 - accuracy: 0.9056 - val_loss: 1.8480 - val_accuracy: 0.4301\n",
            "Epoch 136/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.2829 - accuracy: 0.9006 - val_loss: 1.8437 - val_accuracy: 0.4226\n",
            "Epoch 137/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.2544 - accuracy: 0.9157 - val_loss: 1.8930 - val_accuracy: 0.4195\n",
            "Epoch 138/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.2710 - accuracy: 0.9051 - val_loss: 1.8346 - val_accuracy: 0.4301\n",
            "Epoch 139/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.2844 - accuracy: 0.9006 - val_loss: 1.9080 - val_accuracy: 0.4301\n",
            "Epoch 140/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.2520 - accuracy: 0.9111 - val_loss: 1.8818 - val_accuracy: 0.4316\n",
            "Epoch 141/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.2515 - accuracy: 0.9157 - val_loss: 1.8718 - val_accuracy: 0.4195\n",
            "Epoch 142/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.2567 - accuracy: 0.9076 - val_loss: 1.8723 - val_accuracy: 0.4135\n",
            "Epoch 143/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.2637 - accuracy: 0.9036 - val_loss: 1.8909 - val_accuracy: 0.4195\n",
            "Epoch 144/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.2634 - accuracy: 0.9036 - val_loss: 1.9137 - val_accuracy: 0.4195\n",
            "Epoch 145/500\n",
            "63/63 [==============================] - 5s 80ms/step - loss: 0.2404 - accuracy: 0.9207 - val_loss: 1.9380 - val_accuracy: 0.4286\n",
            "Epoch 146/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.2465 - accuracy: 0.9217 - val_loss: 1.9262 - val_accuracy: 0.4286\n",
            "Epoch 147/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.2452 - accuracy: 0.9116 - val_loss: 1.9472 - val_accuracy: 0.4271\n",
            "Epoch 148/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.2491 - accuracy: 0.9111 - val_loss: 1.9455 - val_accuracy: 0.4226\n",
            "Epoch 149/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.2245 - accuracy: 0.9212 - val_loss: 1.9588 - val_accuracy: 0.4211\n",
            "Epoch 150/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.2340 - accuracy: 0.9202 - val_loss: 1.9718 - val_accuracy: 0.4211\n",
            "Epoch 151/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.2388 - accuracy: 0.9247 - val_loss: 1.9775 - val_accuracy: 0.4376\n",
            "Epoch 152/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.2306 - accuracy: 0.9187 - val_loss: 1.9700 - val_accuracy: 0.4376\n",
            "Epoch 153/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.2392 - accuracy: 0.9101 - val_loss: 1.9913 - val_accuracy: 0.4376\n",
            "Epoch 154/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.2204 - accuracy: 0.9222 - val_loss: 2.0112 - val_accuracy: 0.4180\n",
            "Epoch 155/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.2248 - accuracy: 0.9232 - val_loss: 2.0161 - val_accuracy: 0.4286\n",
            "Epoch 156/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.2300 - accuracy: 0.9167 - val_loss: 2.0041 - val_accuracy: 0.4286\n",
            "Epoch 157/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.2252 - accuracy: 0.9197 - val_loss: 2.0349 - val_accuracy: 0.4256\n",
            "Epoch 158/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.2295 - accuracy: 0.9157 - val_loss: 2.0192 - val_accuracy: 0.4331\n",
            "Epoch 159/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.2106 - accuracy: 0.9282 - val_loss: 2.0564 - val_accuracy: 0.4346\n",
            "Epoch 160/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.2119 - accuracy: 0.9287 - val_loss: 2.0670 - val_accuracy: 0.4180\n",
            "Epoch 161/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.2080 - accuracy: 0.9332 - val_loss: 2.0633 - val_accuracy: 0.4241\n",
            "Epoch 162/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.2077 - accuracy: 0.9317 - val_loss: 2.0897 - val_accuracy: 0.4346\n",
            "Epoch 163/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.2083 - accuracy: 0.9257 - val_loss: 2.0952 - val_accuracy: 0.4361\n",
            "Epoch 164/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.2051 - accuracy: 0.9292 - val_loss: 2.1150 - val_accuracy: 0.4241\n",
            "Epoch 165/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.2001 - accuracy: 0.9267 - val_loss: 2.1068 - val_accuracy: 0.4271\n",
            "Epoch 166/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1916 - accuracy: 0.9362 - val_loss: 2.1149 - val_accuracy: 0.4406\n",
            "Epoch 167/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.1924 - accuracy: 0.9342 - val_loss: 2.1275 - val_accuracy: 0.4241\n",
            "Epoch 168/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1993 - accuracy: 0.9332 - val_loss: 2.1093 - val_accuracy: 0.4316\n",
            "Epoch 169/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1889 - accuracy: 0.9362 - val_loss: 2.1285 - val_accuracy: 0.4271\n",
            "Epoch 170/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1900 - accuracy: 0.9393 - val_loss: 2.1312 - val_accuracy: 0.4376\n",
            "Epoch 171/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1970 - accuracy: 0.9327 - val_loss: 2.1472 - val_accuracy: 0.4211\n",
            "Epoch 172/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1822 - accuracy: 0.9403 - val_loss: 2.1737 - val_accuracy: 0.4150\n",
            "Epoch 173/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1907 - accuracy: 0.9297 - val_loss: 2.1832 - val_accuracy: 0.4135\n",
            "Epoch 174/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1885 - accuracy: 0.9297 - val_loss: 2.1854 - val_accuracy: 0.4226\n",
            "Epoch 175/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1920 - accuracy: 0.9332 - val_loss: 2.2085 - val_accuracy: 0.4271\n",
            "Epoch 176/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1798 - accuracy: 0.9352 - val_loss: 2.1782 - val_accuracy: 0.4376\n",
            "Epoch 177/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1878 - accuracy: 0.9342 - val_loss: 2.2597 - val_accuracy: 0.4286\n",
            "Epoch 178/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1910 - accuracy: 0.9292 - val_loss: 2.2292 - val_accuracy: 0.4271\n",
            "Epoch 179/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1932 - accuracy: 0.9337 - val_loss: 2.2164 - val_accuracy: 0.4331\n",
            "Epoch 180/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1591 - accuracy: 0.9518 - val_loss: 2.2357 - val_accuracy: 0.4271\n",
            "Epoch 181/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1717 - accuracy: 0.9398 - val_loss: 2.2343 - val_accuracy: 0.4316\n",
            "Epoch 182/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1519 - accuracy: 0.9503 - val_loss: 2.2859 - val_accuracy: 0.4105\n",
            "Epoch 183/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1686 - accuracy: 0.9468 - val_loss: 2.2791 - val_accuracy: 0.4180\n",
            "Epoch 184/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1740 - accuracy: 0.9393 - val_loss: 2.2644 - val_accuracy: 0.4286\n",
            "Epoch 185/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1651 - accuracy: 0.9448 - val_loss: 2.3070 - val_accuracy: 0.4150\n",
            "Epoch 186/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1653 - accuracy: 0.9443 - val_loss: 2.2894 - val_accuracy: 0.4211\n",
            "Epoch 187/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1558 - accuracy: 0.9463 - val_loss: 2.3092 - val_accuracy: 0.4195\n",
            "Epoch 188/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1680 - accuracy: 0.9393 - val_loss: 2.3055 - val_accuracy: 0.4165\n",
            "Epoch 189/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1427 - accuracy: 0.9533 - val_loss: 2.3224 - val_accuracy: 0.4120\n",
            "Epoch 190/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1635 - accuracy: 0.9478 - val_loss: 2.3399 - val_accuracy: 0.4060\n",
            "Epoch 191/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1596 - accuracy: 0.9478 - val_loss: 2.3034 - val_accuracy: 0.4195\n",
            "Epoch 192/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1685 - accuracy: 0.9418 - val_loss: 2.2846 - val_accuracy: 0.4391\n",
            "Epoch 193/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.1586 - accuracy: 0.9458 - val_loss: 2.3210 - val_accuracy: 0.4226\n",
            "Epoch 194/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.1532 - accuracy: 0.9458 - val_loss: 2.3322 - val_accuracy: 0.4211\n",
            "Epoch 195/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1518 - accuracy: 0.9508 - val_loss: 2.3164 - val_accuracy: 0.4271\n",
            "Epoch 196/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1779 - accuracy: 0.9393 - val_loss: 2.3234 - val_accuracy: 0.4301\n",
            "Epoch 197/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1742 - accuracy: 0.9398 - val_loss: 2.3425 - val_accuracy: 0.4346\n",
            "Epoch 198/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1674 - accuracy: 0.9458 - val_loss: 2.3789 - val_accuracy: 0.4226\n",
            "Epoch 199/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1689 - accuracy: 0.9458 - val_loss: 2.3428 - val_accuracy: 0.4271\n",
            "Epoch 200/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.1556 - accuracy: 0.9468 - val_loss: 2.3634 - val_accuracy: 0.4165\n",
            "Epoch 201/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1484 - accuracy: 0.9533 - val_loss: 2.4037 - val_accuracy: 0.4331\n",
            "Epoch 202/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1486 - accuracy: 0.9528 - val_loss: 2.4009 - val_accuracy: 0.4165\n",
            "Epoch 203/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1482 - accuracy: 0.9488 - val_loss: 2.4039 - val_accuracy: 0.4286\n",
            "Epoch 204/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1582 - accuracy: 0.9458 - val_loss: 2.4019 - val_accuracy: 0.4165\n",
            "Epoch 205/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1458 - accuracy: 0.9538 - val_loss: 2.3991 - val_accuracy: 0.4256\n",
            "Epoch 206/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1503 - accuracy: 0.9458 - val_loss: 2.4488 - val_accuracy: 0.4120\n",
            "Epoch 207/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1388 - accuracy: 0.9493 - val_loss: 2.4110 - val_accuracy: 0.4120\n",
            "Epoch 208/500\n",
            "63/63 [==============================] - 5s 82ms/step - loss: 0.1534 - accuracy: 0.9498 - val_loss: 2.4661 - val_accuracy: 0.4150\n",
            "Epoch 209/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1435 - accuracy: 0.9463 - val_loss: 2.4485 - val_accuracy: 0.4361\n",
            "Epoch 210/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1385 - accuracy: 0.9573 - val_loss: 2.4192 - val_accuracy: 0.4376\n",
            "Epoch 211/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1278 - accuracy: 0.9538 - val_loss: 2.4152 - val_accuracy: 0.4241\n",
            "Epoch 212/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1406 - accuracy: 0.9568 - val_loss: 2.4467 - val_accuracy: 0.4165\n",
            "Epoch 213/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1242 - accuracy: 0.9608 - val_loss: 2.4569 - val_accuracy: 0.4271\n",
            "Epoch 214/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1296 - accuracy: 0.9558 - val_loss: 2.4857 - val_accuracy: 0.4120\n",
            "Epoch 215/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1442 - accuracy: 0.9458 - val_loss: 2.5036 - val_accuracy: 0.4301\n",
            "Epoch 216/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1140 - accuracy: 0.9618 - val_loss: 2.4874 - val_accuracy: 0.4361\n",
            "Epoch 217/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1191 - accuracy: 0.9613 - val_loss: 2.4735 - val_accuracy: 0.4271\n",
            "Epoch 218/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1301 - accuracy: 0.9613 - val_loss: 2.5427 - val_accuracy: 0.4271\n",
            "Epoch 219/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1401 - accuracy: 0.9503 - val_loss: 2.4940 - val_accuracy: 0.4180\n",
            "Epoch 220/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1380 - accuracy: 0.9528 - val_loss: 2.5131 - val_accuracy: 0.4271\n",
            "Epoch 221/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1338 - accuracy: 0.9543 - val_loss: 2.4876 - val_accuracy: 0.4361\n",
            "Epoch 222/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.1236 - accuracy: 0.9578 - val_loss: 2.5017 - val_accuracy: 0.4466\n",
            "Epoch 223/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1274 - accuracy: 0.9583 - val_loss: 2.5317 - val_accuracy: 0.4271\n",
            "Epoch 224/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1221 - accuracy: 0.9629 - val_loss: 2.5330 - val_accuracy: 0.4301\n",
            "Epoch 225/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1285 - accuracy: 0.9583 - val_loss: 2.5442 - val_accuracy: 0.4376\n",
            "Epoch 226/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1267 - accuracy: 0.9608 - val_loss: 2.5236 - val_accuracy: 0.4331\n",
            "Epoch 227/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1167 - accuracy: 0.9629 - val_loss: 2.5351 - val_accuracy: 0.4226\n",
            "Epoch 228/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1178 - accuracy: 0.9603 - val_loss: 2.5676 - val_accuracy: 0.4271\n",
            "Epoch 229/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1292 - accuracy: 0.9593 - val_loss: 2.5718 - val_accuracy: 0.4301\n",
            "Epoch 230/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1304 - accuracy: 0.9553 - val_loss: 2.5912 - val_accuracy: 0.4301\n",
            "Epoch 231/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1134 - accuracy: 0.9568 - val_loss: 2.6641 - val_accuracy: 0.4150\n",
            "Epoch 232/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.1061 - accuracy: 0.9644 - val_loss: 2.6181 - val_accuracy: 0.4361\n",
            "Epoch 233/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1092 - accuracy: 0.9629 - val_loss: 2.5868 - val_accuracy: 0.4256\n",
            "Epoch 234/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1147 - accuracy: 0.9598 - val_loss: 2.6404 - val_accuracy: 0.4286\n",
            "Epoch 235/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.1254 - accuracy: 0.9568 - val_loss: 2.5932 - val_accuracy: 0.4346\n",
            "Epoch 236/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1170 - accuracy: 0.9613 - val_loss: 2.5641 - val_accuracy: 0.4361\n",
            "Epoch 237/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1029 - accuracy: 0.9618 - val_loss: 2.6076 - val_accuracy: 0.4195\n",
            "Epoch 238/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1104 - accuracy: 0.9639 - val_loss: 2.5930 - val_accuracy: 0.4331\n",
            "Epoch 239/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1091 - accuracy: 0.9608 - val_loss: 2.6251 - val_accuracy: 0.4241\n",
            "Epoch 240/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1107 - accuracy: 0.9618 - val_loss: 2.6318 - val_accuracy: 0.4331\n",
            "Epoch 241/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1198 - accuracy: 0.9588 - val_loss: 2.6614 - val_accuracy: 0.4226\n",
            "Epoch 242/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1082 - accuracy: 0.9618 - val_loss: 2.6505 - val_accuracy: 0.4376\n",
            "Epoch 243/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1166 - accuracy: 0.9573 - val_loss: 2.6677 - val_accuracy: 0.4226\n",
            "Epoch 244/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1092 - accuracy: 0.9649 - val_loss: 2.6272 - val_accuracy: 0.4316\n",
            "Epoch 245/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0987 - accuracy: 0.9674 - val_loss: 2.6693 - val_accuracy: 0.4195\n",
            "Epoch 246/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.1162 - accuracy: 0.9603 - val_loss: 2.6998 - val_accuracy: 0.4226\n",
            "Epoch 247/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1034 - accuracy: 0.9709 - val_loss: 2.6734 - val_accuracy: 0.4481\n",
            "Epoch 248/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1146 - accuracy: 0.9629 - val_loss: 2.6660 - val_accuracy: 0.4301\n",
            "Epoch 249/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1095 - accuracy: 0.9659 - val_loss: 2.6901 - val_accuracy: 0.4331\n",
            "Epoch 250/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0993 - accuracy: 0.9659 - val_loss: 2.7039 - val_accuracy: 0.4226\n",
            "Epoch 251/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1012 - accuracy: 0.9613 - val_loss: 2.6929 - val_accuracy: 0.4391\n",
            "Epoch 252/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1018 - accuracy: 0.9634 - val_loss: 2.7326 - val_accuracy: 0.4241\n",
            "Epoch 253/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0985 - accuracy: 0.9634 - val_loss: 2.7510 - val_accuracy: 0.4256\n",
            "Epoch 254/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0963 - accuracy: 0.9689 - val_loss: 2.7447 - val_accuracy: 0.4286\n",
            "Epoch 255/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0956 - accuracy: 0.9664 - val_loss: 2.8021 - val_accuracy: 0.4376\n",
            "Epoch 256/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1084 - accuracy: 0.9659 - val_loss: 2.7777 - val_accuracy: 0.4301\n",
            "Epoch 257/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1085 - accuracy: 0.9608 - val_loss: 2.7650 - val_accuracy: 0.4361\n",
            "Epoch 258/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0951 - accuracy: 0.9674 - val_loss: 2.7747 - val_accuracy: 0.4286\n",
            "Epoch 259/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0997 - accuracy: 0.9699 - val_loss: 2.7848 - val_accuracy: 0.4346\n",
            "Epoch 260/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1160 - accuracy: 0.9618 - val_loss: 2.7842 - val_accuracy: 0.4376\n",
            "Epoch 261/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0984 - accuracy: 0.9659 - val_loss: 2.8147 - val_accuracy: 0.4331\n",
            "Epoch 262/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1077 - accuracy: 0.9623 - val_loss: 2.8060 - val_accuracy: 0.4316\n",
            "Epoch 263/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0762 - accuracy: 0.9779 - val_loss: 2.7927 - val_accuracy: 0.4286\n",
            "Epoch 264/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0999 - accuracy: 0.9664 - val_loss: 2.8422 - val_accuracy: 0.4135\n",
            "Epoch 265/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1007 - accuracy: 0.9664 - val_loss: 2.8291 - val_accuracy: 0.4180\n",
            "Epoch 266/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1004 - accuracy: 0.9634 - val_loss: 2.8262 - val_accuracy: 0.4211\n",
            "Epoch 267/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0826 - accuracy: 0.9714 - val_loss: 2.8328 - val_accuracy: 0.4211\n",
            "Epoch 268/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0822 - accuracy: 0.9694 - val_loss: 2.8135 - val_accuracy: 0.4361\n",
            "Epoch 269/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0979 - accuracy: 0.9684 - val_loss: 2.8220 - val_accuracy: 0.4271\n",
            "Epoch 270/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0922 - accuracy: 0.9704 - val_loss: 2.8040 - val_accuracy: 0.4361\n",
            "Epoch 271/500\n",
            "63/63 [==============================] - 5s 83ms/step - loss: 0.0925 - accuracy: 0.9674 - val_loss: 2.8626 - val_accuracy: 0.4180\n",
            "Epoch 272/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.1036 - accuracy: 0.9644 - val_loss: 2.8235 - val_accuracy: 0.4211\n",
            "Epoch 273/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0778 - accuracy: 0.9744 - val_loss: 2.8574 - val_accuracy: 0.4271\n",
            "Epoch 274/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0978 - accuracy: 0.9684 - val_loss: 2.8055 - val_accuracy: 0.4301\n",
            "Epoch 275/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.0853 - accuracy: 0.9679 - val_loss: 2.8315 - val_accuracy: 0.4226\n",
            "Epoch 276/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0841 - accuracy: 0.9729 - val_loss: 2.7880 - val_accuracy: 0.4376\n",
            "Epoch 277/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0837 - accuracy: 0.9714 - val_loss: 2.8656 - val_accuracy: 0.4165\n",
            "Epoch 278/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0836 - accuracy: 0.9724 - val_loss: 2.8827 - val_accuracy: 0.4226\n",
            "Epoch 279/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.1008 - accuracy: 0.9664 - val_loss: 2.8845 - val_accuracy: 0.4286\n",
            "Epoch 280/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0852 - accuracy: 0.9674 - val_loss: 2.8930 - val_accuracy: 0.4256\n",
            "Epoch 281/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0755 - accuracy: 0.9739 - val_loss: 2.9126 - val_accuracy: 0.4135\n",
            "Epoch 282/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.1005 - accuracy: 0.9618 - val_loss: 2.8671 - val_accuracy: 0.4331\n",
            "Epoch 283/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.0919 - accuracy: 0.9679 - val_loss: 2.8955 - val_accuracy: 0.4105\n",
            "Epoch 284/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0961 - accuracy: 0.9659 - val_loss: 2.9085 - val_accuracy: 0.4286\n",
            "Epoch 285/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0853 - accuracy: 0.9684 - val_loss: 2.9068 - val_accuracy: 0.4226\n",
            "Epoch 286/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.1003 - accuracy: 0.9654 - val_loss: 2.9218 - val_accuracy: 0.4256\n",
            "Epoch 287/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0801 - accuracy: 0.9739 - val_loss: 2.9395 - val_accuracy: 0.4271\n",
            "Epoch 288/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0784 - accuracy: 0.9744 - val_loss: 2.9163 - val_accuracy: 0.4195\n",
            "Epoch 289/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0904 - accuracy: 0.9704 - val_loss: 2.9258 - val_accuracy: 0.4316\n",
            "Epoch 290/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0809 - accuracy: 0.9754 - val_loss: 2.9089 - val_accuracy: 0.4211\n",
            "Epoch 291/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0819 - accuracy: 0.9724 - val_loss: 2.9889 - val_accuracy: 0.4135\n",
            "Epoch 292/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0796 - accuracy: 0.9739 - val_loss: 2.8917 - val_accuracy: 0.4376\n",
            "Epoch 293/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0900 - accuracy: 0.9649 - val_loss: 2.9238 - val_accuracy: 0.4301\n",
            "Epoch 294/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0767 - accuracy: 0.9724 - val_loss: 2.9354 - val_accuracy: 0.4256\n",
            "Epoch 295/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0695 - accuracy: 0.9739 - val_loss: 2.9095 - val_accuracy: 0.4241\n",
            "Epoch 296/500\n",
            "63/63 [==============================] - 5s 80ms/step - loss: 0.0894 - accuracy: 0.9674 - val_loss: 2.9309 - val_accuracy: 0.4391\n",
            "Epoch 297/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0818 - accuracy: 0.9769 - val_loss: 2.9599 - val_accuracy: 0.4316\n",
            "Epoch 298/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0827 - accuracy: 0.9704 - val_loss: 2.9634 - val_accuracy: 0.4361\n",
            "Epoch 299/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0919 - accuracy: 0.9674 - val_loss: 2.9820 - val_accuracy: 0.4226\n",
            "Epoch 300/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0651 - accuracy: 0.9789 - val_loss: 2.9996 - val_accuracy: 0.4301\n",
            "Epoch 301/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0762 - accuracy: 0.9779 - val_loss: 2.9917 - val_accuracy: 0.4451\n",
            "Epoch 302/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0844 - accuracy: 0.9714 - val_loss: 3.0132 - val_accuracy: 0.4256\n",
            "Epoch 303/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0721 - accuracy: 0.9734 - val_loss: 3.0040 - val_accuracy: 0.4331\n",
            "Epoch 304/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0733 - accuracy: 0.9749 - val_loss: 3.0831 - val_accuracy: 0.4241\n",
            "Epoch 305/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0896 - accuracy: 0.9714 - val_loss: 3.0661 - val_accuracy: 0.4241\n",
            "Epoch 306/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0672 - accuracy: 0.9769 - val_loss: 3.0549 - val_accuracy: 0.4346\n",
            "Epoch 307/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0750 - accuracy: 0.9719 - val_loss: 3.0510 - val_accuracy: 0.4286\n",
            "Epoch 308/500\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.0731 - accuracy: 0.9764 - val_loss: 3.1216 - val_accuracy: 0.4090\n",
            "Epoch 309/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0942 - accuracy: 0.9649 - val_loss: 3.1435 - val_accuracy: 0.4361\n",
            "Epoch 310/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0734 - accuracy: 0.9729 - val_loss: 3.0357 - val_accuracy: 0.4316\n",
            "Epoch 311/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0857 - accuracy: 0.9719 - val_loss: 3.0114 - val_accuracy: 0.4256\n",
            "Epoch 312/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0796 - accuracy: 0.9719 - val_loss: 3.0496 - val_accuracy: 0.4331\n",
            "Epoch 313/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0810 - accuracy: 0.9724 - val_loss: 3.0576 - val_accuracy: 0.4391\n",
            "Epoch 314/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0865 - accuracy: 0.9714 - val_loss: 3.0713 - val_accuracy: 0.4361\n",
            "Epoch 315/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0798 - accuracy: 0.9729 - val_loss: 3.0301 - val_accuracy: 0.4361\n",
            "Epoch 316/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0811 - accuracy: 0.9709 - val_loss: 3.0756 - val_accuracy: 0.4211\n",
            "Epoch 317/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0752 - accuracy: 0.9769 - val_loss: 3.0816 - val_accuracy: 0.4256\n",
            "Epoch 318/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0794 - accuracy: 0.9709 - val_loss: 3.0696 - val_accuracy: 0.4286\n",
            "Epoch 319/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0718 - accuracy: 0.9734 - val_loss: 3.0709 - val_accuracy: 0.4346\n",
            "Epoch 320/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0691 - accuracy: 0.9749 - val_loss: 3.0542 - val_accuracy: 0.4241\n",
            "Epoch 321/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0693 - accuracy: 0.9769 - val_loss: 3.0447 - val_accuracy: 0.4271\n",
            "Epoch 322/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0631 - accuracy: 0.9804 - val_loss: 3.0372 - val_accuracy: 0.4286\n",
            "Epoch 323/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0716 - accuracy: 0.9734 - val_loss: 3.0544 - val_accuracy: 0.4256\n",
            "Epoch 324/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0674 - accuracy: 0.9764 - val_loss: 3.0933 - val_accuracy: 0.4376\n",
            "Epoch 325/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.0846 - accuracy: 0.9719 - val_loss: 3.0897 - val_accuracy: 0.4391\n",
            "Epoch 326/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0719 - accuracy: 0.9739 - val_loss: 3.1063 - val_accuracy: 0.4346\n",
            "Epoch 327/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0694 - accuracy: 0.9774 - val_loss: 3.1313 - val_accuracy: 0.4331\n",
            "Epoch 328/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0699 - accuracy: 0.9734 - val_loss: 3.1568 - val_accuracy: 0.4211\n",
            "Epoch 329/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0702 - accuracy: 0.9734 - val_loss: 3.1057 - val_accuracy: 0.4316\n",
            "Epoch 330/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0757 - accuracy: 0.9774 - val_loss: 3.1076 - val_accuracy: 0.4211\n",
            "Epoch 331/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0588 - accuracy: 0.9779 - val_loss: 3.1488 - val_accuracy: 0.4286\n",
            "Epoch 332/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0635 - accuracy: 0.9809 - val_loss: 3.1476 - val_accuracy: 0.4331\n",
            "Epoch 333/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0647 - accuracy: 0.9789 - val_loss: 3.1464 - val_accuracy: 0.4271\n",
            "Epoch 334/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0648 - accuracy: 0.9769 - val_loss: 3.2085 - val_accuracy: 0.4165\n",
            "Epoch 335/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.0765 - accuracy: 0.9739 - val_loss: 3.1155 - val_accuracy: 0.4346\n",
            "Epoch 336/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0615 - accuracy: 0.9819 - val_loss: 3.1642 - val_accuracy: 0.4271\n",
            "Epoch 337/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0733 - accuracy: 0.9759 - val_loss: 3.2052 - val_accuracy: 0.4226\n",
            "Epoch 338/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0675 - accuracy: 0.9734 - val_loss: 3.1786 - val_accuracy: 0.4241\n",
            "Epoch 339/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0659 - accuracy: 0.9764 - val_loss: 3.1462 - val_accuracy: 0.4211\n",
            "Epoch 340/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0698 - accuracy: 0.9784 - val_loss: 3.1817 - val_accuracy: 0.4361\n",
            "Epoch 341/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0562 - accuracy: 0.9799 - val_loss: 3.2183 - val_accuracy: 0.4256\n",
            "Epoch 342/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0650 - accuracy: 0.9744 - val_loss: 3.2033 - val_accuracy: 0.4406\n",
            "Epoch 343/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0605 - accuracy: 0.9799 - val_loss: 3.2114 - val_accuracy: 0.4226\n",
            "Epoch 344/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0755 - accuracy: 0.9724 - val_loss: 3.1565 - val_accuracy: 0.4301\n",
            "Epoch 345/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0549 - accuracy: 0.9804 - val_loss: 3.1472 - val_accuracy: 0.4466\n",
            "Epoch 346/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0655 - accuracy: 0.9794 - val_loss: 3.2869 - val_accuracy: 0.4150\n",
            "Epoch 347/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0698 - accuracy: 0.9744 - val_loss: 3.2228 - val_accuracy: 0.4256\n",
            "Epoch 348/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0731 - accuracy: 0.9739 - val_loss: 3.2055 - val_accuracy: 0.4331\n",
            "Epoch 349/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0660 - accuracy: 0.9769 - val_loss: 3.2119 - val_accuracy: 0.4256\n",
            "Epoch 350/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0683 - accuracy: 0.9759 - val_loss: 3.2200 - val_accuracy: 0.4361\n",
            "Epoch 351/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0629 - accuracy: 0.9769 - val_loss: 3.2096 - val_accuracy: 0.4331\n",
            "Epoch 352/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0711 - accuracy: 0.9754 - val_loss: 3.2568 - val_accuracy: 0.4241\n",
            "Epoch 353/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0705 - accuracy: 0.9734 - val_loss: 3.2200 - val_accuracy: 0.4316\n",
            "Epoch 354/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0621 - accuracy: 0.9769 - val_loss: 3.2815 - val_accuracy: 0.4256\n",
            "Epoch 355/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0590 - accuracy: 0.9814 - val_loss: 3.2679 - val_accuracy: 0.4271\n",
            "Epoch 356/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0567 - accuracy: 0.9759 - val_loss: 3.2988 - val_accuracy: 0.4256\n",
            "Epoch 357/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0619 - accuracy: 0.9794 - val_loss: 3.2675 - val_accuracy: 0.4226\n",
            "Epoch 358/500\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.0679 - accuracy: 0.9769 - val_loss: 3.2998 - val_accuracy: 0.4346\n",
            "Epoch 359/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0724 - accuracy: 0.9759 - val_loss: 3.2642 - val_accuracy: 0.4406\n",
            "Epoch 360/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0618 - accuracy: 0.9779 - val_loss: 3.2277 - val_accuracy: 0.4361\n",
            "Epoch 361/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0577 - accuracy: 0.9804 - val_loss: 3.2799 - val_accuracy: 0.4226\n",
            "Epoch 362/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0600 - accuracy: 0.9799 - val_loss: 3.2450 - val_accuracy: 0.4346\n",
            "Epoch 363/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0552 - accuracy: 0.9794 - val_loss: 3.2428 - val_accuracy: 0.4316\n",
            "Epoch 364/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0539 - accuracy: 0.9829 - val_loss: 3.2748 - val_accuracy: 0.4256\n",
            "Epoch 365/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0617 - accuracy: 0.9809 - val_loss: 3.2946 - val_accuracy: 0.4316\n",
            "Epoch 366/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0659 - accuracy: 0.9764 - val_loss: 3.2663 - val_accuracy: 0.4511\n",
            "Epoch 367/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0683 - accuracy: 0.9779 - val_loss: 3.3438 - val_accuracy: 0.4376\n",
            "Epoch 368/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0590 - accuracy: 0.9779 - val_loss: 3.3288 - val_accuracy: 0.4286\n",
            "Epoch 369/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0704 - accuracy: 0.9799 - val_loss: 3.2897 - val_accuracy: 0.4391\n",
            "Epoch 370/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0626 - accuracy: 0.9779 - val_loss: 3.2763 - val_accuracy: 0.4346\n",
            "Epoch 371/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.0541 - accuracy: 0.9814 - val_loss: 3.2869 - val_accuracy: 0.4271\n",
            "Epoch 372/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0603 - accuracy: 0.9814 - val_loss: 3.2999 - val_accuracy: 0.4331\n",
            "Epoch 373/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0680 - accuracy: 0.9774 - val_loss: 3.3106 - val_accuracy: 0.4301\n",
            "Epoch 374/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0518 - accuracy: 0.9799 - val_loss: 3.3585 - val_accuracy: 0.4256\n",
            "Epoch 375/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0619 - accuracy: 0.9804 - val_loss: 3.3245 - val_accuracy: 0.4301\n",
            "Epoch 376/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0466 - accuracy: 0.9864 - val_loss: 3.3069 - val_accuracy: 0.4301\n",
            "Epoch 377/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0647 - accuracy: 0.9794 - val_loss: 3.3016 - val_accuracy: 0.4346\n",
            "Epoch 378/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0527 - accuracy: 0.9804 - val_loss: 3.3370 - val_accuracy: 0.4346\n",
            "Epoch 379/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0602 - accuracy: 0.9774 - val_loss: 3.3617 - val_accuracy: 0.4421\n",
            "Epoch 380/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0430 - accuracy: 0.9859 - val_loss: 3.3306 - val_accuracy: 0.4391\n",
            "Epoch 381/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0666 - accuracy: 0.9794 - val_loss: 3.3624 - val_accuracy: 0.4346\n",
            "Epoch 382/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0774 - accuracy: 0.9709 - val_loss: 3.3662 - val_accuracy: 0.4241\n",
            "Epoch 383/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0675 - accuracy: 0.9774 - val_loss: 3.3423 - val_accuracy: 0.4436\n",
            "Epoch 384/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0702 - accuracy: 0.9749 - val_loss: 3.3275 - val_accuracy: 0.4406\n",
            "Epoch 385/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0629 - accuracy: 0.9789 - val_loss: 3.3075 - val_accuracy: 0.4451\n",
            "Epoch 386/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0586 - accuracy: 0.9824 - val_loss: 3.3804 - val_accuracy: 0.4286\n",
            "Epoch 387/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.0529 - accuracy: 0.9819 - val_loss: 3.3807 - val_accuracy: 0.4346\n",
            "Epoch 388/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0781 - accuracy: 0.9764 - val_loss: 3.3030 - val_accuracy: 0.4436\n",
            "Epoch 389/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0609 - accuracy: 0.9769 - val_loss: 3.2999 - val_accuracy: 0.4421\n",
            "Epoch 390/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0533 - accuracy: 0.9809 - val_loss: 3.3027 - val_accuracy: 0.4331\n",
            "Epoch 391/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0600 - accuracy: 0.9819 - val_loss: 3.3332 - val_accuracy: 0.4376\n",
            "Epoch 392/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0530 - accuracy: 0.9804 - val_loss: 3.3401 - val_accuracy: 0.4316\n",
            "Epoch 393/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0504 - accuracy: 0.9829 - val_loss: 3.3168 - val_accuracy: 0.4421\n",
            "Epoch 394/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0486 - accuracy: 0.9844 - val_loss: 3.3424 - val_accuracy: 0.4286\n",
            "Epoch 395/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0667 - accuracy: 0.9779 - val_loss: 3.3046 - val_accuracy: 0.4286\n",
            "Epoch 396/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0457 - accuracy: 0.9849 - val_loss: 3.3287 - val_accuracy: 0.4361\n",
            "Epoch 397/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0503 - accuracy: 0.9814 - val_loss: 3.3641 - val_accuracy: 0.4256\n",
            "Epoch 398/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.0516 - accuracy: 0.9809 - val_loss: 3.3612 - val_accuracy: 0.4271\n",
            "Epoch 399/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0519 - accuracy: 0.9814 - val_loss: 3.3549 - val_accuracy: 0.4391\n",
            "Epoch 400/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0488 - accuracy: 0.9849 - val_loss: 3.3539 - val_accuracy: 0.4481\n",
            "Epoch 401/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0446 - accuracy: 0.9824 - val_loss: 3.3148 - val_accuracy: 0.4421\n",
            "Epoch 402/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0494 - accuracy: 0.9839 - val_loss: 3.3414 - val_accuracy: 0.4421\n",
            "Epoch 403/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.0473 - accuracy: 0.9844 - val_loss: 3.3925 - val_accuracy: 0.4316\n",
            "Epoch 404/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0585 - accuracy: 0.9769 - val_loss: 3.3804 - val_accuracy: 0.4226\n",
            "Epoch 405/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.0493 - accuracy: 0.9819 - val_loss: 3.3702 - val_accuracy: 0.4195\n",
            "Epoch 406/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.0624 - accuracy: 0.9794 - val_loss: 3.3375 - val_accuracy: 0.4301\n",
            "Epoch 407/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.0524 - accuracy: 0.9794 - val_loss: 3.3601 - val_accuracy: 0.4361\n",
            "Epoch 408/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0644 - accuracy: 0.9789 - val_loss: 3.4046 - val_accuracy: 0.4301\n",
            "Epoch 409/500\n",
            "63/63 [==============================] - 6s 88ms/step - loss: 0.0472 - accuracy: 0.9834 - val_loss: 3.4029 - val_accuracy: 0.4346\n",
            "Epoch 410/500\n",
            "63/63 [==============================] - 5s 84ms/step - loss: 0.0555 - accuracy: 0.9804 - val_loss: 3.3843 - val_accuracy: 0.4316\n",
            "Epoch 411/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0534 - accuracy: 0.9804 - val_loss: 3.4265 - val_accuracy: 0.4301\n",
            "Epoch 412/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0564 - accuracy: 0.9804 - val_loss: 3.4044 - val_accuracy: 0.4286\n",
            "Epoch 413/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0409 - accuracy: 0.9880 - val_loss: 3.4089 - val_accuracy: 0.4301\n",
            "Epoch 414/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0619 - accuracy: 0.9784 - val_loss: 3.4230 - val_accuracy: 0.4346\n",
            "Epoch 415/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0541 - accuracy: 0.9794 - val_loss: 3.4042 - val_accuracy: 0.4481\n",
            "Epoch 416/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0514 - accuracy: 0.9829 - val_loss: 3.3958 - val_accuracy: 0.4226\n",
            "Epoch 417/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0506 - accuracy: 0.9829 - val_loss: 3.4491 - val_accuracy: 0.4346\n",
            "Epoch 418/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0437 - accuracy: 0.9874 - val_loss: 3.4998 - val_accuracy: 0.4165\n",
            "Epoch 419/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0456 - accuracy: 0.9849 - val_loss: 3.4911 - val_accuracy: 0.4241\n",
            "Epoch 420/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0431 - accuracy: 0.9839 - val_loss: 3.4831 - val_accuracy: 0.4316\n",
            "Epoch 421/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0507 - accuracy: 0.9849 - val_loss: 3.4924 - val_accuracy: 0.4301\n",
            "Epoch 422/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0561 - accuracy: 0.9809 - val_loss: 3.5490 - val_accuracy: 0.4286\n",
            "Epoch 423/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0538 - accuracy: 0.9799 - val_loss: 3.5225 - val_accuracy: 0.4361\n",
            "Epoch 424/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0447 - accuracy: 0.9804 - val_loss: 3.4862 - val_accuracy: 0.4436\n",
            "Epoch 425/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0549 - accuracy: 0.9829 - val_loss: 3.4604 - val_accuracy: 0.4406\n",
            "Epoch 426/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0612 - accuracy: 0.9789 - val_loss: 3.4528 - val_accuracy: 0.4406\n",
            "Epoch 427/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0615 - accuracy: 0.9784 - val_loss: 3.4217 - val_accuracy: 0.4511\n",
            "Epoch 428/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0603 - accuracy: 0.9779 - val_loss: 3.4057 - val_accuracy: 0.4316\n",
            "Epoch 429/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0560 - accuracy: 0.9809 - val_loss: 3.3944 - val_accuracy: 0.4421\n",
            "Epoch 430/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0499 - accuracy: 0.9849 - val_loss: 3.4221 - val_accuracy: 0.4286\n",
            "Epoch 431/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0524 - accuracy: 0.9824 - val_loss: 3.4298 - val_accuracy: 0.4391\n",
            "Epoch 432/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0404 - accuracy: 0.9874 - val_loss: 3.4961 - val_accuracy: 0.4211\n",
            "Epoch 433/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0443 - accuracy: 0.9844 - val_loss: 3.5257 - val_accuracy: 0.4286\n",
            "Epoch 434/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0597 - accuracy: 0.9804 - val_loss: 3.5438 - val_accuracy: 0.4241\n",
            "Epoch 435/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0595 - accuracy: 0.9789 - val_loss: 3.5563 - val_accuracy: 0.4316\n",
            "Epoch 436/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0429 - accuracy: 0.9844 - val_loss: 3.5281 - val_accuracy: 0.4346\n",
            "Epoch 437/500\n",
            "63/63 [==============================] - 5s 84ms/step - loss: 0.0596 - accuracy: 0.9799 - val_loss: 3.5026 - val_accuracy: 0.4316\n",
            "Epoch 438/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0505 - accuracy: 0.9829 - val_loss: 3.4962 - val_accuracy: 0.4391\n",
            "Epoch 439/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0450 - accuracy: 0.9849 - val_loss: 3.4900 - val_accuracy: 0.4301\n",
            "Epoch 440/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0493 - accuracy: 0.9819 - val_loss: 3.5530 - val_accuracy: 0.4271\n",
            "Epoch 441/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0491 - accuracy: 0.9844 - val_loss: 3.5064 - val_accuracy: 0.4180\n",
            "Epoch 442/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0502 - accuracy: 0.9849 - val_loss: 3.5599 - val_accuracy: 0.4226\n",
            "Epoch 443/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0611 - accuracy: 0.9769 - val_loss: 3.5681 - val_accuracy: 0.4180\n",
            "Epoch 444/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0508 - accuracy: 0.9834 - val_loss: 3.5837 - val_accuracy: 0.4226\n",
            "Epoch 445/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.0449 - accuracy: 0.9844 - val_loss: 3.5893 - val_accuracy: 0.4286\n",
            "Epoch 446/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0406 - accuracy: 0.9859 - val_loss: 3.5716 - val_accuracy: 0.4286\n",
            "Epoch 447/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0398 - accuracy: 0.9859 - val_loss: 3.5691 - val_accuracy: 0.4406\n",
            "Epoch 448/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0463 - accuracy: 0.9839 - val_loss: 3.6142 - val_accuracy: 0.4256\n",
            "Epoch 449/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0464 - accuracy: 0.9829 - val_loss: 3.5785 - val_accuracy: 0.4301\n",
            "Epoch 450/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.0424 - accuracy: 0.9844 - val_loss: 3.6071 - val_accuracy: 0.4195\n",
            "Epoch 451/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0512 - accuracy: 0.9809 - val_loss: 3.5881 - val_accuracy: 0.4301\n",
            "Epoch 452/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0505 - accuracy: 0.9799 - val_loss: 3.5672 - val_accuracy: 0.4286\n",
            "Epoch 453/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0486 - accuracy: 0.9814 - val_loss: 3.5905 - val_accuracy: 0.4376\n",
            "Epoch 454/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0463 - accuracy: 0.9834 - val_loss: 3.5898 - val_accuracy: 0.4256\n",
            "Epoch 455/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0419 - accuracy: 0.9829 - val_loss: 3.5831 - val_accuracy: 0.4286\n",
            "Epoch 456/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0431 - accuracy: 0.9874 - val_loss: 3.5495 - val_accuracy: 0.4301\n",
            "Epoch 457/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0489 - accuracy: 0.9834 - val_loss: 3.5816 - val_accuracy: 0.4316\n",
            "Epoch 458/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0421 - accuracy: 0.9849 - val_loss: 3.5925 - val_accuracy: 0.4346\n",
            "Epoch 459/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0403 - accuracy: 0.9829 - val_loss: 3.6232 - val_accuracy: 0.4271\n",
            "Epoch 460/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0346 - accuracy: 0.9869 - val_loss: 3.5635 - val_accuracy: 0.4391\n",
            "Epoch 461/500\n",
            "63/63 [==============================] - 5s 81ms/step - loss: 0.0397 - accuracy: 0.9854 - val_loss: 3.6165 - val_accuracy: 0.4301\n",
            "Epoch 462/500\n",
            "63/63 [==============================] - 5s 79ms/step - loss: 0.0460 - accuracy: 0.9849 - val_loss: 3.6199 - val_accuracy: 0.4316\n",
            "Epoch 463/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0475 - accuracy: 0.9844 - val_loss: 3.6218 - val_accuracy: 0.4331\n",
            "Epoch 464/500\n",
            "63/63 [==============================] - 5s 78ms/step - loss: 0.0487 - accuracy: 0.9834 - val_loss: 3.6919 - val_accuracy: 0.4256\n",
            "Epoch 465/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0569 - accuracy: 0.9799 - val_loss: 3.6094 - val_accuracy: 0.4301\n",
            "Epoch 466/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0482 - accuracy: 0.9809 - val_loss: 3.6240 - val_accuracy: 0.4361\n",
            "Epoch 467/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0555 - accuracy: 0.9819 - val_loss: 3.6355 - val_accuracy: 0.4256\n",
            "Epoch 468/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0464 - accuracy: 0.9869 - val_loss: 3.6074 - val_accuracy: 0.4466\n",
            "Epoch 469/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0495 - accuracy: 0.9844 - val_loss: 3.6475 - val_accuracy: 0.4256\n",
            "Epoch 470/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0491 - accuracy: 0.9804 - val_loss: 3.6236 - val_accuracy: 0.4436\n",
            "Epoch 471/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0480 - accuracy: 0.9839 - val_loss: 3.6290 - val_accuracy: 0.4271\n",
            "Epoch 472/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0447 - accuracy: 0.9839 - val_loss: 3.5874 - val_accuracy: 0.4331\n",
            "Epoch 473/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0385 - accuracy: 0.9869 - val_loss: 3.6066 - val_accuracy: 0.4211\n",
            "Epoch 474/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0435 - accuracy: 0.9854 - val_loss: 3.5901 - val_accuracy: 0.4256\n",
            "Epoch 475/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0424 - accuracy: 0.9874 - val_loss: 3.5732 - val_accuracy: 0.4361\n",
            "Epoch 476/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0529 - accuracy: 0.9814 - val_loss: 3.6228 - val_accuracy: 0.4256\n",
            "Epoch 477/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0374 - accuracy: 0.9880 - val_loss: 3.6258 - val_accuracy: 0.4331\n",
            "Epoch 478/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.0515 - accuracy: 0.9809 - val_loss: 3.6235 - val_accuracy: 0.4421\n",
            "Epoch 479/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0409 - accuracy: 0.9869 - val_loss: 3.5871 - val_accuracy: 0.4466\n",
            "Epoch 480/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0363 - accuracy: 0.9880 - val_loss: 3.6132 - val_accuracy: 0.4346\n",
            "Epoch 481/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0383 - accuracy: 0.9864 - val_loss: 3.6287 - val_accuracy: 0.4316\n",
            "Epoch 482/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0505 - accuracy: 0.9849 - val_loss: 3.6096 - val_accuracy: 0.4331\n",
            "Epoch 483/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.0409 - accuracy: 0.9839 - val_loss: 3.6316 - val_accuracy: 0.4211\n",
            "Epoch 484/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0370 - accuracy: 0.9874 - val_loss: 3.6193 - val_accuracy: 0.4271\n",
            "Epoch 485/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0321 - accuracy: 0.9890 - val_loss: 3.6552 - val_accuracy: 0.4256\n",
            "Epoch 486/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0343 - accuracy: 0.9905 - val_loss: 3.6560 - val_accuracy: 0.4226\n",
            "Epoch 487/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0466 - accuracy: 0.9864 - val_loss: 3.6410 - val_accuracy: 0.4376\n",
            "Epoch 488/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0442 - accuracy: 0.9844 - val_loss: 3.6552 - val_accuracy: 0.4256\n",
            "Epoch 489/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0457 - accuracy: 0.9834 - val_loss: 3.6720 - val_accuracy: 0.4301\n",
            "Epoch 490/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0410 - accuracy: 0.9854 - val_loss: 3.7041 - val_accuracy: 0.4316\n",
            "Epoch 491/500\n",
            "63/63 [==============================] - 5s 74ms/step - loss: 0.0540 - accuracy: 0.9839 - val_loss: 3.6649 - val_accuracy: 0.4286\n",
            "Epoch 492/500\n",
            "63/63 [==============================] - 5s 75ms/step - loss: 0.0502 - accuracy: 0.9829 - val_loss: 3.6328 - val_accuracy: 0.4301\n",
            "Epoch 493/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0567 - accuracy: 0.9829 - val_loss: 3.6212 - val_accuracy: 0.4286\n",
            "Epoch 494/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0360 - accuracy: 0.9864 - val_loss: 3.5924 - val_accuracy: 0.4466\n",
            "Epoch 495/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0443 - accuracy: 0.9834 - val_loss: 3.6282 - val_accuracy: 0.4391\n",
            "Epoch 496/500\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 0.0409 - accuracy: 0.9885 - val_loss: 3.6837 - val_accuracy: 0.4331\n",
            "Epoch 497/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0452 - accuracy: 0.9834 - val_loss: 3.6930 - val_accuracy: 0.4556\n",
            "Epoch 498/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0446 - accuracy: 0.9839 - val_loss: 3.6675 - val_accuracy: 0.4331\n",
            "Epoch 499/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0445 - accuracy: 0.9854 - val_loss: 3.6955 - val_accuracy: 0.4391\n",
            "Epoch 500/500\n",
            "63/63 [==============================] - 5s 76ms/step - loss: 0.0409 - accuracy: 0.9859 - val_loss: 3.6607 - val_accuracy: 0.4361\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}