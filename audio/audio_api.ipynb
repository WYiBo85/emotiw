{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "audio-api.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yvesrm-Q44G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def install_dependencies():\n",
        "  import subprocess\n",
        "\n",
        "  subprocess.check_output(\"pip install pydub\", shell=True)\n",
        "  subprocess.check_output(\"pip install vggish-keras\", shell=True)\n",
        "  subprocess.check_output(\"pip install git+https://github.com/beasteers/pumpp@tf_keras\", shell=True) #Update the path base.py file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpVDgVNoTgms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "outputId": "f88365fa-e5b1-4638-84e5-464262dff344"
      },
      "source": [
        "!pip install git+https://github.com/beasteers/pumpp@tf_keras"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/beasteers/pumpp@tf_keras\n",
            "  Cloning https://github.com/beasteers/pumpp (to revision tf_keras) to /tmp/pip-req-build-r2npnhks\n",
            "  Running command git clone -q https://github.com/beasteers/pumpp /tmp/pip-req-build-r2npnhks\n",
            "  Running command git checkout -b tf_keras --track origin/tf_keras\n",
            "  Switched to a new branch 'tf_keras'\n",
            "  Branch 'tf_keras' set up to track remote branch 'tf_keras' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): pumpp==0.5.0 from git+https://github.com/beasteers/pumpp@tf_keras in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: librosa>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from pumpp==0.5.0) (0.6.3)\n",
            "Requirement already satisfied: jams>=0.3 in /usr/local/lib/python3.6/dist-packages (from pumpp==0.5.0) (0.3.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from pumpp==0.5.0) (0.22.2.post1)\n",
            "Requirement already satisfied: mir_eval>=0.5 in /usr/local/lib/python3.6/dist-packages (from pumpp==0.5.0) (0.6)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.6.2->pumpp==0.5.0) (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.6.2->pumpp==0.5.0) (1.18.4)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.6.2->pumpp==0.5.0) (0.15.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.6.2->pumpp==0.5.0) (2.1.8)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.6.2->pumpp==0.5.0) (4.4.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.6.2->pumpp==0.5.0) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.6.2->pumpp==0.5.0) (0.48.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.6.2->pumpp==0.5.0) (1.12.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from jams>=0.3->pumpp==0.5.0) (2.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from jams>=0.3->pumpp==0.5.0) (1.0.3)\n",
            "Requirement already satisfied: jsonschema>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from jams>=0.3->pumpp==0.5.0) (3.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from mir_eval>=0.5->pumpp==0.5.0) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa>=0.6.2->pumpp==0.5.0) (46.3.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa>=0.6.2->pumpp==0.5.0) (0.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->jams>=0.3->pumpp==0.5.0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->jams>=0.3->pumpp==0.5.0) (2018.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.0->jams>=0.3->pumpp==0.5.0) (1.6.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.0->jams>=0.3->pumpp==0.5.0) (19.3.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.0->jams>=0.3->pumpp==0.5.0) (0.16.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.0->jams>=0.3->pumpp==0.5.0) (3.1.0)\n",
            "Building wheels for collected packages: pumpp\n",
            "  Building wheel for pumpp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pumpp: filename=pumpp-0.5.0-cp36-none-any.whl size=46971 sha256=e7055c1c6e76f26023bc74385c121d903eb50683dd1f2d729b2a232086b3fe2d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6b79h0r2/wheels/c6/1a/da/cc46314603be89fe6373c1159af0147d92c1ff8d52563d97f1\n",
            "Successfully built pumpp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdjKfwTntt5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def import_dependencies():\n",
        "  from tensorflow.keras.models import load_model\n",
        "  from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_audio\n",
        "  import glob\n",
        "  import time\n",
        "  import importlib\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  from subprocess import Popen, PIPE, STDOUT\n",
        "  import librosa\n",
        "  import vggish_keras as vgk\n",
        "  importlib.reload(vgk)\n",
        "  from pydub import AudioSegment\n",
        "  import argparse\n",
        "  import audioread\n",
        "  import time\n",
        "  import numpy as np\n",
        "  import subprocess\n",
        "\n",
        "  from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
        "  from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otS204f_TEpP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "06617082-4ef6-4749-e405-76e046f7c079"
      },
      "source": [
        "import vggish_keras as vgk\n",
        "importlib.reload(vgk)\n",
        "vgk.VGGish(pump)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParameterError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParameterError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-48f39ab4e7c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvggish_keras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvgk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvgk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGGish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpump\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/vggish_keras/vggish.py\u001b[0m in \u001b[0;36mVGGish\u001b[0;34m(pump, input_shape, include_top, pooling, weights, name, compress)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpump\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpump\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tf.keras'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUMP_INPUT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pumpp/core.py\u001b[0m in \u001b[0;36mlayers\u001b[0;34m(self, api)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0moperator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'layers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mlayermap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayermap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pumpp/feature/base.py\u001b[0m in \u001b[0;36mlayers\u001b[0;34m(self, api)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mParameterError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported layer api={}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlayers_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mParameterError\u001b[0m: Unsupported layer api=tf.keras"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPKtwAdgQzil",
        "colab_type": "text"
      },
      "source": [
        "# Audio API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvmKxLO5ba44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_vggish():\n",
        "  pump = vgk.get_pump()\n",
        "  model = vgk.VGGish(pump)\n",
        "\n",
        "  #Create time-stamp for folder name\n",
        "  TIMESTR = time.strftime(\"%Y%m%d-%H%M%S\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aawWIMDLRkFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: add option for soft vs hard\n",
        "def predict(mp4_filepath, best_model_filepath):\n",
        "    \"\"\"\n",
        "    Outputs:\n",
        "    - A tuple with predictions for each class (positive, neutral, negative)\n",
        "    \"\"\"\n",
        "\n",
        "    model = fer_model()\n",
        "    model.load_model(best_model_filepath)\n",
        "    return model.predict(mp4_filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOSIfnb4PRuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class audio_model:\n",
        "    def __init__(self):\n",
        "        self.model = ()\n",
        "        return\n",
        "\n",
        "    def predict(self, mp4_filepath ):\n",
        "        X , y = self.get_feature_batch(mp4_filepath) #Preproccess \n",
        "        X = np.asarray(X) #You may get a bug TODO: trimming \n",
        "\n",
        "        soft_pred = self.model.predict(X)\n",
        "\n",
        "\n",
        "        return soft_pred # (0.1 ,0.2 , 0.7)\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "    def load_model(self, best_model_filepath):\n",
        "        self.model = load_model(best_model_filepath)\n",
        "        \n",
        "        return  \n",
        "\n",
        "    def train(self, X_train , y_train , epochs=50 , batch_size=32 , X_val=None , Y_val=None , val_split=0.1):\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        Train function with the model architecture\n",
        "\n",
        "        - Outputs\n",
        "          1. Trained model\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        #TODO: There are some bugs here \n",
        "        # Next Steps:\n",
        "        # 1. Transfer learning\n",
        "        # 2. Try CNN-LSTM approach \n",
        "        # 3. For deep networks, try residual blocks\n",
        "        # 4. Look for other model architecture to use with openSmile/VggISH/mel-spec features \n",
        "\n",
        "    \n",
        "        inputs = keras.Input(shape=[16,512])\n",
        "\n",
        "        recurrent_1 = keras.layers.Bidirectional(keras.layers.LSTM(10, return_sequences=True, input_shape=[None, 512] ,                                                                   dropout=0.2 , activation='selu')) #A sequence of any length with dimensions 512 (i.e. 512 columns\n",
        "        recurrent_2 = keras.layers.Bidirectional(keras.layers.LSTM(5))\n",
        "        dense_1 = keras.layers.Dense(32 , activation='selu')\n",
        "        dropout_1 = keras.layers.Dropout(0.5)\n",
        "        softmax = keras.layers.Dense(3 , activation='softmax')\n",
        "\n",
        "        x = recurrent_1(inputs)\n",
        "        x = recurrent_2(x)\n",
        "        x = dense_1(x)\n",
        "        x = dropout_1(x)\n",
        "        outputs = softmax(x)\n",
        "\n",
        "        rnn_ae = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate=1e-4,\n",
        "        decay_steps=10000,\n",
        "        decay_rate=0.9)\n",
        "        opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "        rnn_ae.compile(loss='sparse_categorical_crossentropy' , optimizer=opt , metrics=['accuracy'])\n",
        "\n",
        "        history = None \n",
        "\n",
        "        if X_val.all() != None and Y_val.all() != None:\n",
        "          history = rnn_ae.fit(X_train , y_train , epochs=epochs , batch_size=batch_size,  validation_split=val_split)\n",
        "\n",
        "        else:\n",
        "          history = rnn_ae.fit(X_train , y_train , epochs=epochs , batch_size=batch_size,  validation_data=(X_val, Y_val))\n",
        "\n",
        "        return rnn_ae , history\n",
        "\n",
        "\n",
        "    #Function to slice up the audio.\n",
        "    def slice_audio(self, files, channels, outformat, width, rate, slice_length, slide):\n",
        "        out_files = []\n",
        "        \n",
        "        outformat = outformat.replace('.','').lower()\n",
        "        #Allow the user to see their x-bit selection with this dictionary.\n",
        "        width_translator = {1:'8-bit', 2:'16-bit', 4:'32-bit'}\n",
        "        #For every file in the input list do processing.\n",
        "        for file in files:\n",
        "            print(file)\n",
        "            fileName, fileExtension = os.path.splitext(file)\n",
        "            #Store the file in RAM.\n",
        "            sound = AudioSegment.from_file(file, fileExtension.replace('.','').lower())\n",
        "            #Print the 'x-bit' conversion parameters.\n",
        "            print (width_translator[sound.sample_width]+' to '+width_translator[int(width)]+'.\\n')\n",
        "            #Implement the user-selected or default (if nothing selected) parameters for processing.\n",
        "            sound = sound.set_frame_rate(int(rate))\n",
        "            sound = sound.set_sample_width(int(width))\n",
        "            sound = sound.set_channels(int(channels))\n",
        "            length_sound_ms = len(sound)\n",
        "            length_slice_ms = int(slice_length)\n",
        "            slice_start = 0\n",
        "            #create audiosegment object\n",
        "            notes_reversed = sound[0:1].reverse()\n",
        "            #Begin slicing at the start of the file.\n",
        "            while slice_start + length_slice_ms < length_sound_ms:\n",
        "                sound_slice = sound[slice_start:slice_start+length_slice_ms]\n",
        "                backwards = sound_slice.reverse()\n",
        "                notes_reversed += backwards\n",
        "                sound_slice.export('to_zip/'+ fileName+'.slice'+str(slice_start/1000)+'SecsTo'+str((slice_start+length_slice_ms)/1000)+'Secs.'+outformat, format=outformat)\n",
        "                \n",
        "                out_files.append('to_zip/'+ fileName+'.slice'+str(slice_start/1000)+'SecsTo'+str((slice_start+length_slice_ms)/1000)+'Secs.'+outformat)\n",
        "                \n",
        "                #backwards.export( fileName+'backwards_slice'+str(slice_start/1000)+'SecsTo'+str((slice_start+length_slice_ms)/1000)+'Secs.'+outformat, format=outformat)\n",
        "                slice_start += int(slide)\n",
        "            #When the slice is abutting the end of the file, output that slice too.'\n",
        "            if slice_start + length_slice_ms >= length_sound_ms:\n",
        "                sound_slice = sound[slice_start:length_sound_ms]\n",
        "                backwards = sound_slice.reverse()\n",
        "                notes_reversed += backwards\n",
        "                sound_slice.export('to_zip/'+fileName+'.slice'+str(slice_start/1000)+'SecsToEndFileAt'+str((length_sound_ms)/1000)+'Secs.'+outformat, format=outformat)\n",
        "                \n",
        "                out_files.append('to_zip/'+fileName+'.slice'+str(slice_start/1000)+'SecsToEndFileAt'+str((length_sound_ms)/1000)+'Secs.'+outformat)\n",
        "                \n",
        "                #backwards.export(fileName+'backwards_slice'+str(slice_start/1000)+'SecsToEndFileAt'+str((slice_start+length_slice_ms)/1000)+'Secs.'+outformat, format=outformat)\n",
        "            #Save the sewn together backwards bits to file\n",
        "            #notes_reversed.export(fileName+'notes_reversed_granular.'+outformat, format=outformat)\n",
        "\n",
        "        return out_files\n",
        "\n",
        "    def preprocess(self, mp4_filepath , target_label_path=None , hop_int=2):\n",
        "\n",
        "      \"\"\"\n",
        "      Outputs:\n",
        "      - A numpy array with dimensions (m,n). \n",
        "        - m is the units in time dependent on the audio splice rate.\n",
        "        - n is the number of features from the openSMILE library.\n",
        "      \"\"\"\n",
        "\n",
        "      print(f\"Processing file {mp4_filepath} ...\")\n",
        "\n",
        "\n",
        "      output_wav_file = mp4_filepath.split(\"/\")[-1] + 'extracted_audio.wav'\n",
        "      mp4_filename = os.path.basename(mp4_filepath)\n",
        "      audio_home_dir = os.path.dirname(mp4_filepath)\n",
        "\n",
        "      # Strip the audio from video and store as .wav file\n",
        "      ffmpeg_extract_audio(mp4_filepath, output_wav_file)\n",
        "\n",
        "      files_written = self.slice_audio([output_wav_file], 2, \"wav\", 2, 30000, 2000, 100)\n",
        "\n",
        "      X_arr = []\n",
        "\n",
        "      # VGGish feature extraction\n",
        "      #out_fn = os.path.join('/content/openSmile-features.arff')\n",
        "      counter = 0\n",
        "      for in_fn in files_written:\n",
        "        name = os.path.basename(in_fn)\n",
        "        if counter % hop_int == 0: # Choose every hop_int splice\n",
        "          X = pump.transform(in_fn)[vgk.params.PUMP_INPUT]\n",
        "          X_arr.append(X)        \n",
        "        counter += 1\n",
        "\n",
        "      for in_fn in files_written:\n",
        "        os.remove(in_fn)\n",
        "\n",
        "      # Get the Y values \n",
        "      target = None \n",
        "      if target_label_path is not None:\n",
        "          target_labels = np.genfromtxt(target_label_path , delimiter = ' ' , dtype='str')\n",
        "          target_index = np.where(target_labels[: , 0] == mp4_filename[:-4])[0]\n",
        "          target = int(target_labels[: , 1][target_index])\n",
        "      return X_arr , target\n",
        "\n",
        "\n",
        "      # Read in each video file and add the (m,n) feature matrix to a 3D array\n",
        "\n",
        "    def get_feature_batch(self, input_files_dir , batch_size=3000 , target_label_path=None):\n",
        "        \"\"\"\n",
        "        Inputs: \n",
        "        - Path to the .mp4 files\n",
        "        Outputs:\n",
        "        - An ndarray with dims (s , m , n)\n",
        "          - s is the number of samples\n",
        "          - m is the number of slices for that sample (32)\n",
        "          - n is the number of features (512)\n",
        "        \"\"\"\n",
        "\n",
        "        output_x = []\n",
        "        output_y = None\n",
        "\n",
        "        if target_label_path is not None:\n",
        "          output_y = []\n",
        "\n",
        "\n",
        "        counter = 1\n",
        "\n",
        "        fileList = glob.glob(input_files_dir + '*.mp4')\n",
        "\n",
        "        MAX_WORKERS = 32\n",
        "\n",
        "        futures = []\n",
        "        with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "            for file_path in fileList:\n",
        "            \n",
        "                print(f\"Submitting {counter} - {file_path}\")\n",
        "\n",
        "                # one_sample_feat_matrix , y = self.preprocess(file_path , target_label_path=target_label_path)\n",
        "\n",
        "                future = executor.submit(self.preprocess, file_path, target_label_path)\n",
        "                futures.append(future)\n",
        "\n",
        "                if counter >= batch_size:\n",
        "                    break\n",
        "\n",
        "                counter += 1\n",
        "\n",
        "        print(\"***** Submitted all tasks *****\")\n",
        "\n",
        "        k = 0\n",
        "        for future in futures:\n",
        "            X_arr, y = future.result()\n",
        "\n",
        "            Z_arr = []\n",
        "            for X in X_arr:\n",
        "                # np.concatenate([X]*5)\n",
        "                Z = model.predict(X)\n",
        "                Z_arr += [Z]\n",
        "\n",
        "            Z_arr = np.asarray(Z_arr , dtype='float32')\n",
        "            Z_arr = Z_arr.squeeze()\n",
        "\n",
        "            # Standardize\n",
        "            scaler = StandardScaler()\n",
        "            all_timepoints_feature_array = scaler.fit_transform(Z_arr)\n",
        "\n",
        "            print(all_timepoints_feature_array.shape)\n",
        "\n",
        "            print(f\"Finished future {k}\")\n",
        "            output_x.append(all_timepoints_feature_array)\n",
        "            if target_label_path is not None:        \n",
        "              output_y.append(y)\n",
        "            future.result()\n",
        "            k += 1\n",
        "        print(\"***** Completed *****\")\n",
        "\n",
        "        output_y = np.asarray(output_y)\n",
        "        output_y -= 1\n",
        "\n",
        "        return output_x , output_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5lfxK8Nb5A8",
        "colab_type": "text"
      },
      "source": [
        "# Main Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBAbNurmQFAv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "ab66a00c-e6dc-4a24-a1a2-64fcaf08e77d"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  install_dependencies()\n",
        "  import_dependencies()\n",
        "  load_vggish()\n",
        "\n",
        "  #from google.colab import drive\n",
        "  #drive.mount('/content/gdrive' , force_remount=True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-1daaf7044574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0minstall_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mimport_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mload_vggish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m#from google.colab import drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-b2884adff453>\u001b[0m in \u001b[0;36mload_vggish\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_vggish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mpump\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGGish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpump\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m#Create time-stamp for folder name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vgk' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZkqolLCQVUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}