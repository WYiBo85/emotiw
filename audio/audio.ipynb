{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "audio.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtMIoO7CwrPW",
        "colab_type": "code",
        "outputId": "069994fc-41dd-417a-b1bf-92af46c46d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C2i_RzuxKXn",
        "colab_type": "code",
        "outputId": "a528609b-39ab-45e2-fb06-131ab86c0ff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install pydub"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.6/dist-packages (0.24.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdjKfwTntt5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports \n",
        "from tensorflow.keras.models import load_model\n",
        "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_audio\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import importlib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "os.system(\"pip install pydub\")\n",
        "\n",
        "os.chdir('/content/gdrive/My Drive/Machine-Learning-Projects/cs231n/notebooks/audio-new')\n",
        "\n",
        "\n",
        "import arffToNp\n",
        "importlib.reload(arffToNp)\n",
        "import subprocess\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPKtwAdgQzil",
        "colab_type": "text"
      },
      "source": [
        "# Audio API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOSIfnb4PRuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# TODO: add option for soft vs hard\n",
        "def predict(mp4_filepath, best_model_filepath):\n",
        "    \"\"\"\n",
        "    Outputs:\n",
        "    - A tuple with predictions for each class (positive, neutral, negative)\n",
        "    \"\"\"\n",
        "\n",
        "    model = fer_model()\n",
        "    model.load_model(best_model_filepath)\n",
        "    return model.predict(mp4_filepath)\n",
        "\n",
        "class audio_model:\n",
        "    def __init__(self):\n",
        "        self.model = ()\n",
        "        return\n",
        "\n",
        "    def predict(self, mp4_filepath):\n",
        "        self.preprocess(mp4_filepath)\n",
        "        X = cv2.imload(\"test/happy.jpg\")\n",
        "        X = cv2.resize(X, (48,48))\n",
        "        X = cv2.cvtColor(X, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        return self.model.predict(img)\n",
        "        #return (0.1,0.2,0.7)\n",
        "\n",
        "    def load_model(self, best_model_filepath):\n",
        "        self.model = load_model(best_model_filepath)\n",
        "        return\n",
        "\n",
        "    def train(self, mp4_filepaths):\n",
        "        # train the model\n",
        "        # self.model = ....\n",
        "        return\n",
        "\n",
        "    def preprocess(self, mp4_filepath):\n",
        "\n",
        "      \"\"\"\n",
        "      Outputs:\n",
        "      - A numpy array with dimensions (m,n). \n",
        "        - m is the units in time dependent on the audio splice rate.\n",
        "        - n is the number of features from the openSMILE library.\n",
        "      \"\"\"\n",
        "\n",
        "\n",
        "      output_wav_file = mp4_filepath[-5] + 'extracted_audio.wav'\n",
        "      mp4_filename = os.path.basename(mp4_filepath)\n",
        "      audio_home_dir = os.path.dirname(mp4_filepath)\n",
        "      os.chdir(audio_home_dir)\n",
        "\n",
        "      # Strip the audio from video and store as .wav file\n",
        "      ffmpeg_extract_audio(mp4_filepath, output_wav_file)\n",
        "      !cd '$audio_home_dir' ; mkdir to_zip\n",
        "\n",
        "      # splice the audio files into 2 seconds with 100 ms sliding window.\n",
        "      # 30 kHz sampling rate\n",
        "      !cd '$audio_home_dir' ; python SliceAudio.py -i *.wav -o wav -c 2  -b 2 -s 30000 -w 100 -l 2000\n",
        "    \n",
        "      # Zip and move files from drive to vm\n",
        "      !cd '$audio_home_dir'  ; zip -r -qq to_zip.zip  to_zip ; cd '$audio_home_dir' ; mv 'to_zip.zip' '/content/' \n",
        "\n",
        "      # Remove the old zip folder in vm\n",
        "      !cd '$audio_home_dir' ; cd to_zip ; rm *.wav  ; cd - ; rm -d to_zip\n",
        "\n",
        "      # Inflate the zip folder in vm\n",
        "      !cd '/content/' ; unzip -qq to_zip.zip \n",
        "\n",
        "\n",
        "      # OpenSMILE feature extraction\n",
        "      out_fn = os.path.join(audio_home_dir, mp4_filename + 'openSmile-features.arff')\n",
        "      os.chdir('/content/to_zip/')\n",
        "      aligned_files = glob.glob('*.wav')\n",
        "      os.chdir('/content/')\n",
        "      for in_fn in aligned_files:\n",
        "        in_fn = os.path.join('/content/to_zip/' , in_fn)\n",
        "        name = os.path.basename(in_fn)\n",
        "        !cd 'opensmile-2.3.0' ; inst/bin/SMILExtract -C config/IS13_ComParE.conf -I '$in_fn' -O '$out_fn' -N $name\n",
        "\n",
        "      # Convert .arff to .csv\n",
        "      all_timepoints_feature_array = arffToNp.convert(out_fn)\n",
        "      print(\"The shape of the feature matrix for one \\n video is: \" , all_timepoints_feature_array.shape)\n",
        "\n",
        "      # Clean up            \n",
        "      !cd to_zip ; rm *.wav ; cd - ; rm -d to_zip      \n",
        "      os.remove(out_fn)\n",
        "      !cd '$audio_home_dir' ; rm *.wav ; rm *.csv\n",
        "      !rm to_zip.zip\n",
        "\n",
        "\n",
        "      # Standardize\n",
        "      scaler = StandardScaler()\n",
        "      all_timepoints_feature_array = scaler.fit_transform(all_timepoints_feature_array)\n",
        "\n",
        "      return all_timepoints_feature_array\n",
        "\n",
        "\n",
        "      # Read in each video file and add the (m,n) feature matrix to a 3D array\n",
        "\n",
        "    def get_feature_batch(self, input_file_path , batch_size=3000):\n",
        "        \"\"\"\n",
        "        Inputs: \n",
        "        - Path to the .mp4 files\n",
        "        Outputs:\n",
        "        - An ndarray with dims (s , m , n)\n",
        "          - s is the number of samples\n",
        "          - m is the number of slices for that sample (32)\n",
        "          - n is the number of features (6373)\n",
        "        \"\"\"\n",
        "\n",
        "        output_arr = []\n",
        "\n",
        "        counter = 0\n",
        "\n",
        "        for root, dir, files in os.walk(input_file_path):\n",
        "          for name in files:\n",
        "            if '.mp4' in name:\n",
        "\n",
        "              file_path = os.path.join(input_file_path , name)\n",
        "              print(file_path)\n",
        "\n",
        "              one_sample_feat_matrix = self.preprocess(file_path)\n",
        "\n",
        "              output_arr.append(one_sample_feat_matrix)\n",
        "\n",
        "              if counter >= batch_size:\n",
        "                break\n",
        "\n",
        "              counter += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        return output_arr\n",
        "\n",
        "def installOpenSMILE():\n",
        "    \"\"\"\n",
        "    You must upload your downloaded version of openSMILE from the site to \n",
        "    cloud.\n",
        "\n",
        "    \"\"\"\n",
        "    os.chdir('/content/')\n",
        "    !tar -zxvf 'opensmile-2.3.0.tar.gz'\n",
        "    !sed -i '117s/(char)/(unsigned char)/g' opensmile-2.3.0/src/include/core/vectorTransform.hpp\n",
        "    !sudo apt-get update\n",
        "    !sudo apt-get install autoconf automake libtool m4 gcc\n",
        "    !cd 'opensmile-2.3.0' ; bash buildStandalone.sh\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCmJo14bwJPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "installOpenSMILE()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuQ7ZKNaErLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd 'opensmile-2.3.0' ; inst/bin/SMILExtract -h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz4-Eq7s1b8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "audio_model_1 = audio_model()\n",
        "output_arr = audio_model_1.preprocess(mp4_filepath='/content/gdrive/My Drive/Machine-Learning-Projects/cs231n/notebooks/audio-new/1_1.mp4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uvfF-vBuWFx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "d1ef2e35-70ff-4320-cc93-deba92b56a3e"
      },
      "source": [
        "!cd '/content/gdrive/My Drive/Machine-Learning-Projects/cs231n/notebooks/audio-new/'; ls "
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1_1.mp4\t\t\t\t  audio.ipynb\t\t  openSMILEShell.sh\n",
            "1extracted_audio.wav\t\t  audio.py\t\t  __pycache__\n",
            "arffToNp.py\t\t\t  opensmile-2.3.0\t  SliceAudio.py\n",
            "audio-deep-learning-models.ipynb  opensmile-2.3.0.tar.gz  to_zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpSBR3iwqBCu",
        "colab_type": "code",
        "outputId": "cd136dda-a8e4-4ad5-dc2b-c341413338fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output_arr.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 6373)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qclXsD0rQurr",
        "colab_type": "text"
      },
      "source": [
        "# Set up Processing Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO6kw5xPczMj",
        "colab_type": "code",
        "outputId": "8095ca28-acd9-43b0-e161-1cdd42c959d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Imports\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: cd: to_zip: No such file or directory\n",
            "rm: cannot remove 'to_zip': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XjbNuXMRCYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing Pipeling\n",
        "!cd '$home_dir'; mkdir train_vids ; mkdir val_vids\n",
        "train_path = '/content/gdrive/My Drive/Machine-Learning-Projects/cs231n/datasets/emotiw/Train.zip'\n",
        "val_path = '/content/gdrive/My Drive/Machine-Learning-Projects/cs231n/datasets/emotiw/Val.zip'\n",
        "vm_train_path = '/content/train_vids'\n",
        "vm_val_path = '/content/val_vids'\n",
        "slice_audio_path = '/content/gdrive/My Drive/Machine-Learning-Projects/cs231n/notebooks/audio-new/SliceAudio.py'\n",
        "\n",
        "# Copy files to vm and inflate\n",
        "!cp '$train_path' '$vm_train_path' ; cd '$vm_train_path' ; unzip -qq 'Train.zip'\n",
        "!cp '$val_path' '$vm_val_path' ; cd '$vm_val_path' ; unzip -qq 'Val.zip'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd8RXFbQX__G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inflated_train_path = '/content/train_vids/Train'\n",
        "inflated_val_path = '/content/train_vids/Val'\n",
        "\n",
        "# Copy SliceAudio to dirs\n",
        "!cp '$slice_audio_path' '$inflated_train_path' ; cp '$slice_audio_path' '$inflated_val_path'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WsvMPqQbh5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfhZzwnkh3pJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "audio_model_test = audio_model()\n",
        "      \n",
        "batched_array = audio_model_test.get_feature_batch(inflated_train_path , batch_size=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiBhbVOuqCSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df986068-60c0-4028-edd0-765ca19908f1"
      },
      "source": [
        "final_array_1 = np.asarray(batched_array , dtype='float')\n",
        "print(final_array_1.shape)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 32, 6373)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q__yJA75bhS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "586b71f9-1c50-49e0-9b4f-b4e05bc77a59"
      },
      "source": [
        ""
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}