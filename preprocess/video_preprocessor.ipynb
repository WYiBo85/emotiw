{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video_preprocessor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAfS_VQphFOI",
        "colab_type": "text"
      },
      "source": [
        "### Video Pre-processor\n",
        "\n",
        "Consumes the videos from a file and produces files that can be used by downstream models and/or downstream preprocessors. \n",
        "\n",
        "This is the first step in the video preprocessing pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNI9YJehDOYd",
        "colab_type": "code",
        "outputId": "2162dade-b66e-4b9e-9f9d-53a4d520ef37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxhjkzmem8dK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import cv2\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from pathlib import Path\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "\n",
        "class VideoPreprocessor:\n",
        "    \"\"\"\n",
        "    Preprocesses raw videos into frames so that further downstream extraction and\n",
        "    preprocessing can occur\n",
        "\n",
        "    Example usage:\n",
        "\n",
        "    video_preprocessor = VideoPreprocessor(\n",
        "        video_folder=\"drive/My Drive/cs231n-project/datasets/emotiw/train-tiny.zip\", \n",
        "        label_file=\"drive/My Drive/cs231n-project/datasets/emotiw/Train_labels.txt\", \n",
        "        output_folder=\"train-tiny-local\", \n",
        "        output_file=\"drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-local.zip\"\n",
        "    )\n",
        "    video_preprocessor.preprocess()\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, video_folder, label_file, output_folder, output_file=None, is_zip=True, height=320, width=480, sample_every=10, max_workers=32):\n",
        "        \"\"\"\n",
        "        @param video_folder   The folder where the list of videos are stored. If \n",
        "                              `is_zip` is set to True, this should be a single zip \n",
        "                              file containing the videos. Paths can either by a local \n",
        "                              folder or a GDrive mounted path.\n",
        "        @param label_file     The file containing the space-delimited video name to label mapping\n",
        "        @param output_folder  The local output path where the preprocessed files will be stored for \n",
        "                              further preprocessing can be done\n",
        "        @param output_file    If not none, the output_folder will be zipped up and stored at this location\n",
        "        @param is_zip         If set to True, the `video_folder` will be unzipped prior to accessing\n",
        "        @param height         Height of the extracted video frames\n",
        "        @param width          Width of the extracted video frames\n",
        "        @param sample_every   The frames to skip.\n",
        "        @param max_workers    The number of workers to use to parallelize work.\n",
        "        \"\"\"\n",
        "        self.is_zip = is_zip\n",
        "        self.video_folder = video_folder\n",
        "        self.label_file = label_file\n",
        "        self.output_folder = output_folder\n",
        "        self.output_file = output_file\n",
        "        print(f\"Video Preprocessor created with is_zip = {is_zip}, video_folder = {video_folder} , label_file = {label_file} , output_folder = {output_folder}, output_file = {output_file}\")\n",
        "        \n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.sample_every = sample_every\n",
        "        self.max_workers = max_workers\n",
        "        print(f\"Frames will be created with height = {height} , width = {width} , sample_every = {sample_every}\")\n",
        "\n",
        "\n",
        "    def preprocess(self):\n",
        "        if self.is_zip:\n",
        "            # Unzips files to a temp directory\n",
        "            tmp_output_folder = self.output_folder.rstrip('/') + \"_tmp\"\n",
        "            print(f\"Unzipping files to temp dir {tmp_output_folder}...\")\n",
        "            Path(f\"{tmp_output_folder}\").mkdir(parents=True, exist_ok=True)\n",
        "            with zipfile.ZipFile(self.video_folder, 'r') as zip_ref:\n",
        "                zip_ref.extractall(tmp_output_folder)\n",
        "            print(\"Finished unzipping files\")\n",
        "        else:\n",
        "            tmp_output_folder = self.video_folder\n",
        "            print(\"Skipping unzipping files as input is a folder\")\n",
        "        \n",
        "        # Create the category subfolders in the output folder\n",
        "        # Path Structure:\n",
        "        #   output/\n",
        "        #     1/\n",
        "        #     2/\n",
        "        video_to_label = {}\n",
        "        unique_labels = set()\n",
        "        with open(self.label_file, \"r\") as f:\n",
        "            i = 0\n",
        "            for line in f:\n",
        "                if i == 0:\n",
        "                    i += 1\n",
        "                    continue\n",
        "                line_arr = line.split(\" \")\n",
        "                video_to_label[line_arr[0] + \".mp4\"] = line_arr[1].strip()\n",
        "                if line_arr[1].strip() not in unique_labels:\n",
        "                    unique_labels.add(line_arr[1].strip())\n",
        "                    Path(f\"{self.output_folder}/{line_arr[1].strip()}\").mkdir(parents=True, exist_ok=True)\n",
        "                i += 1\n",
        "\n",
        "        # Process each video by extracting the frames in a multi-threaded fashion\n",
        "        futures = []\n",
        "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
        "            videos = next(os.walk(tmp_output_folder))[2]\n",
        "            print(f\"Found {len(videos)} videos\")\n",
        "            video_num = 1\n",
        "\n",
        "            for video_name in videos:\n",
        "                future = executor.submit(self.process_video, tmp_output_folder, video_name, video_num, len(videos), video_to_label)\n",
        "                futures.append(future)\n",
        "                video_num += 1\n",
        "\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "        print(\"***** Submitted all tasks *****\")\n",
        "        for future in futures:\n",
        "            future.result()\n",
        "        print(\"***** Completed *****\")\n",
        "\n",
        "        if self.output_file is not None:\n",
        "            print(f\"Starting to zip files to {self.output_file}\")\n",
        "            def zipdir(path, ziph):\n",
        "                for root, dirs, files in os.walk(path):\n",
        "                    folder = root[len(path):]\n",
        "                    for file in files:\n",
        "                        ziph.write(join(root, file), join(folder, file))\n",
        "\n",
        "            zipf = zipfile.ZipFile(self.output_file, 'w', zipfile.ZIP_DEFLATED)\n",
        "            zipdir(self.output_folder, zipf)\n",
        "            zipf.close()\n",
        "            print(f\"Done zipping files to {self.output_file}\")\n",
        "        \n",
        "        print(\"Done!\")\n",
        "\n",
        "    def process_video(self, tmp_output_folder, video_name, video_num, total_videos, video_to_label):\n",
        "        \"\"\"\n",
        "        Processes a video by extracting the frames\n",
        "        Writes out each frame, where each frame is an image resized to the the specified dimensions\n",
        "        \"\"\"\n",
        "        vidcap = cv2.VideoCapture(join(tmp_output_folder, video_name))\n",
        "        label = video_to_label[video_name]\n",
        "        print(f\"Processing video {video_num}/{total_videos} with name {video_name} and class {label} \\n\")\n",
        "\n",
        "        input_length = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        frame_width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        frame_height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "        success, image = vidcap.read()\n",
        "        count = 0\n",
        "        frame = 0\n",
        "        while success:\n",
        "            if count % self.sample_every == 0:\n",
        "                height, width = image.shape[:2]\n",
        "                image = cv2.resize(image, (self.width, self.height), interpolation = cv2.INTER_CUBIC)\n",
        "                cv2.imwrite(f\"{self.output_folder}/{label}/frame_{video_name}_{frame}.jpg\", image)\n",
        "                frame += 1\n",
        "            success, image = vidcap.read()\n",
        "            count += 1\n",
        "        video_num += 1\n",
        "        vidcap.release()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_OFm_yJYA22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f2188b2-91f8-447b-c2c0-ce82ba8f3614"
      },
      "source": [
        "video_preprocessor = VideoPreprocessor(\n",
        "    video_folder=\"drive/My Drive/cs231n-project/datasets/emotiw/train-tiny.zip\", \n",
        "    label_file=\"drive/My Drive/cs231n-project/datasets/emotiw/Train_labels.txt\", \n",
        "    output_folder=\"train-tiny-local\", \n",
        "    output_file=\"drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-local.zip\"\n",
        ")\n",
        "video_preprocessor.preprocess()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Video Preprocessor created with is_zip = True, video_folder = drive/My Drive/cs231n-project/datasets/emotiw/train-tiny.zip , label_file = drive/My Drive/cs231n-project/datasets/emotiw/Train_labels.txt , output_folder = train-tiny-local, output_file = drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-local.zip\n",
            "Frames will be created with height = 320 , width = 480 , sample_every = 10\n",
            "Unzipping files to temp dir train-tiny-local_tmp...\n",
            "Finished unzipping files\n",
            "Found 50 videos\n",
            "Processing video 1/50 with name 324_96.mp4 and class 3 \n",
            "\n",
            "Processing video 4/50 with name 204_13.mp4 and class 3 \n",
            "Processing video 2/50 with name 303_41.mp4 and class 3 \n",
            "\n",
            "\n",
            "Processing video 6/50 with name 300_56.mp4 and class 3 \n",
            "\n",
            "Processing video 8/50 with name 97_22.mp4 and class 3 \n",
            "\n",
            "Processing video 12/50 with name 108_13.mp4 and class 3 \n",
            "\n",
            "Processing video 14/50 with name 112_5.mp4 and class 2 \n",
            "\n",
            "Processing video 10/50 with name 133_2.mp4 and class 1 \n",
            "\n",
            "Processing video 16/50 with name 16_14.mp4 and class 1 \n",
            "\n",
            "Processing video 18/50 with name 101_30.mp4 and class 1 \n",
            "\n",
            "Processing video 20/50 with name 7_6.mp4 and class 1 \n",
            "\n",
            "Processing video 22/50 with name 217_15.mp4 and class 1 \n",
            "\n",
            "Processing video 3/50 with name 34_9.mp4 and class 2 \n",
            "Processing video 5/50 with name 2_2.mp4 and class 3 \n",
            "\n",
            "\n",
            "Processing video 25/50 with name 286_4.mp4 and class 2 \n",
            "\n",
            "Processing video 26/50 with name 140_1.mp4 and class 1 \n",
            "\n",
            "Processing video 28/50 with name 64_5.mp4 and class 1 \n",
            "\n",
            "Processing video 29/50 with name 3_17.mp4 and class 3 \n",
            "\n",
            "Processing video 15/50 with name 69_30.mp4 and class 2 \n",
            "\n",
            "Processing video 30/50 with name 61_15.mp4 and class 1 \n",
            "\n",
            "Processing video 21/50 with name 321_15.mp4 and class 3 \n",
            "\n",
            "Processing video 24/50 with name 188_15.mp4 and class 3 \n",
            "\n",
            "Processing video 32/50 with name 324_34.mp4 and class 2 \n",
            "\n",
            "Processing video 11/50 with name 276_3.mp4 and class 2 \n",
            "\n",
            "Processing video 9/50 with name 277_3.mp4 and class 2 \n",
            "\n",
            "Processing video 17/50 with name 334_21.mp4 and class 3 \n",
            "\n",
            "Processing video 19/50 with name 122_1.mp4 and class 1 \n",
            "\n",
            "Processing video 13/50 with name 188_22.mp4 and class 3 \n",
            "Processing video 23/50 with name 276_8.mp4 and class 1 \n",
            "Processing video 31/50 with name 328_13.mp4 and class 3 \n",
            "\n",
            "\n",
            "\n",
            "Processing video 7/50 with name 33_20.mp4 and class 1 \n",
            "\n",
            "Processing video 27/50 with name 119_8.mp4 and class 3 \n",
            "\n",
            "Processing video 33/50 with name 281_2.mp4 and class 2 \n",
            "\n",
            "Processing video 34/50 with name 68_9.mp4 and class 1 \n",
            "\n",
            "Processing video 35/50 with name 217_3.mp4 and class 1 \n",
            "\n",
            "Processing video 36/50 with name 101_12.mp4 and class 3 \n",
            "\n",
            "Processing video 37/50 with name 324_56.mp4 and class 3 \n",
            "\n",
            "Processing video 38/50 with name 321_31.mp4 and class 1 \n",
            "\n",
            "Processing video 39/50 with name 197_12.mp4 and class 1 \n",
            "\n",
            "Processing video 40/50 with name 80_1.mp4 and class 1 \n",
            "\n",
            "Processing video 42/50 with name 41_18.mp4 and class 1 \n",
            "\n",
            "Processing video 43/50 with name 198_5.mp4 and class 3 \n",
            "\n",
            "Processing video 41/50 with name 220_6.mp4 and class 3 \n",
            "\n",
            "Processing video 45/50 with name 280_12.mp4 and class 1 \n",
            "\n",
            "Processing video 44/50 with name 52_1.mp4 and class 2 \n",
            "\n",
            "Processing video 46/50 with name 3_29.mp4 and class 3 \n",
            "\n",
            "Processing video 47/50 with name 43_12.mp4 and class 1 \n",
            "\n",
            "Processing video 48/50 with name 258_2.mp4 and class 2 \n",
            "\n",
            "Processing video 49/50 with name 312_1.mp4 and class 2 \n",
            "\n",
            "Processing video 50/50 with name 148_4.mp4 and class 3 \n",
            "\n",
            "***** Submitted all tasks *****\n",
            "***** Completed *****\n",
            "Starting to zip files to drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-local.zip\n",
            "Done zipping files to drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-local.zip\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ3jWsaB49Tj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "1ede2a97-ba17-44fc-9b2e-3a9b8d0da66e"
      },
      "source": [
        "!pip install face_recognition"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 41kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.18.4)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566172 sha256=b390a13e5824c6e7568babbe9c2f2c7809afc357698b622c130927e96f469dae\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qKhN_Kc1XOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import cv2\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from pathlib import Path\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "import face_recognition\n",
        "import pickle\n",
        "\n",
        "class FacePreprocessor:\n",
        "    \"\"\"\n",
        "    Extract the faces from the videos.\n",
        "    Faces are stored in a flat directory structure (no categorical hierarchy)\n",
        "    \n",
        "    Processes a video by extracting the faces from each frame and creating a \n",
        "    list of list of faces which is then saved as a pickled object.\n",
        "\n",
        "    NOTE: Faces are not guaranteed to be the same across frames.\n",
        "          eg. 'face 1' in frame 1 may not be the same as 'face 1' in frame 2\n",
        "\n",
        "    Pickle Object Format:\n",
        "        [\n",
        "            [\n",
        "                [frame 1, face 1],\n",
        "                [frame 1, face 2],\n",
        "                [frame 1, face 3]\n",
        "            ],\n",
        "            [\n",
        "                [frame 2, face 1],\n",
        "                [frame 2, face 2]\n",
        "            ],\n",
        "            ...\n",
        "        ]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, video_folder, output_folder, output_file=None, is_zip=True, height=320, width=480, sample_every=10, max_workers=32):\n",
        "        \"\"\"\n",
        "        @param video_folder          The folder where the list of videos frames are stored. If \n",
        "                                     `is_zip` is set to True, this should be a single zip \n",
        "                                     file containing the video frames. Paths can either by a local \n",
        "                                     folder or a GDrive mounted path.\n",
        "        @param output_folder         The local output path where the preprocessed files will be stored for \n",
        "                                     further preprocessing can be done\n",
        "        @param output_file           If not none, the output_folder will be zipped up and stored at this location\n",
        "        @param is_zip                If set to True, the `video_folder` will be unzipped prior to accessing\n",
        "        @param height         Height of the extracted video frames\n",
        "        @param width          Width of the extracted video frames\n",
        "        @param sample_every   The frames to skip.\n",
        "        @param max_workers    The number of workers to use to parallelize work.\n",
        "        \"\"\"\n",
        "        self.is_zip = is_zip\n",
        "        self.video_folder = video_folder\n",
        "        self.output_folder = output_folder\n",
        "        self.output_file = output_file\n",
        "        print(f\"Video Preprocessor created with is_zip = {is_zip}, video_folder = {video_folder} , output_folder = {output_folder}, output_file = {output_file}\")\n",
        "\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.sample_every = sample_every\n",
        "        self.max_workers = max_workers\n",
        "        print(f\"Frames will be created with height = {height} , width = {width} , sample_every = {sample_every}\")\n",
        "\n",
        "    def preprocess(self):\n",
        "        if self.is_zip:\n",
        "            # Unzips files to a temp directory\n",
        "            tmp_output_folder = self.output_folder.rstrip('/') + \"_tmp\"\n",
        "            print(f\"Unzipping files to temp dir {tmp_output_folder}...\")\n",
        "            Path(f\"{tmp_output_folder}\").mkdir(parents=True, exist_ok=True)\n",
        "            with zipfile.ZipFile(self.video_folder, 'r') as zip_ref:\n",
        "                zip_ref.extractall(tmp_output_folder)\n",
        "            print(\"Finished unzipping files\")\n",
        "        else:\n",
        "            tmp_output_folder = self.video_folder\n",
        "            print(\"Skipping unzipping files as input is a folder\")\n",
        "\n",
        "        # Create output folder\n",
        "        Path(f\"{self.output_folder}/faces-pickle/\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Process each video by extracting the frames in a multi-threaded fashion\n",
        "        futures = []\n",
        "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
        "            videos = next(os.walk(tmp_output_folder))[2]\n",
        "            print(f\"Found {len(videos)} videos\")\n",
        "            video_num = 1\n",
        "\n",
        "            for video_name in videos:\n",
        "                future = executor.submit(self.process_video, tmp_output_folder, video_name, video_num, len(videos))\n",
        "                futures.append(future)\n",
        "                video_num += 1\n",
        "\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "        print(\"***** Submitted all tasks *****\")\n",
        "        with open(f\"{self.output_folder}/summary.txt\", 'w') as f:\n",
        "            f.write(f\"video_name,face_image_name,frame_number,face_number,total_frames,fps,video_width,video_height,top,right,bottom,left\\n\")\n",
        "            for future in futures:\n",
        "                out_arr = future.result()\n",
        "                for out in out_arr:\n",
        "                    f.write(out)\n",
        "        print(\"***** Completed *****\")\n",
        "\n",
        "\n",
        "        if self.output_file is not None:\n",
        "            print(f\"Starting to zip files to {self.output_file}\")\n",
        "            def zipdir(path, ziph):\n",
        "                for root, dirs, files in os.walk(path):\n",
        "                    folder = root[len(path):]\n",
        "                    for file in files:\n",
        "                        ziph.write(join(root, file), join(folder, file))\n",
        "\n",
        "            zipf = zipfile.ZipFile(self.output_file, 'w', zipfile.ZIP_DEFLATED)\n",
        "            zipdir(self.output_folder, zipf)\n",
        "            zipf.close()\n",
        "            print(f\"Done zipping files to {self.output_file}\")\n",
        "        \n",
        "        print(\"Done!\")\n",
        "\n",
        "    def process_video(self, tmp_output_folder, video_name, video_num, total_videos):\n",
        "        \"\"\"\n",
        "        Processes a video by extracting the faces\n",
        "        \"\"\"\n",
        "        vidcap = cv2.VideoCapture(join(tmp_output_folder, video_name))\n",
        "        print(f\"Processing video {video_num}/{total_videos} with name {video_name} \\n\")\n",
        "\n",
        "        input_length = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        frame_width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        frame_height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "        metadata = []\n",
        "        faces_all_frames = []\n",
        "        success, image = vidcap.read()\n",
        "        count = 0\n",
        "        frame = 0\n",
        "        while success:\n",
        "            if count % self.sample_every == 0:\n",
        "                height, width = image.shape[:2]\n",
        "                image = cv2.resize(image, (self.width, self.height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "                # Convert from BGR color (OpenCV) to RGB color (face_recognition)\n",
        "                rgb_image = image[:, :, ::-1]\n",
        "\n",
        "                # Find all the faces in the current frame of video\n",
        "                face_locations = face_recognition.face_locations(rgb_image)\n",
        "                faces = []\n",
        "                face_num = 0\n",
        "                # Display the results\n",
        "                for top, right, bottom, left in face_locations:\n",
        "                    # Draw a box around the face\n",
        "                    faces.append(image[top:bottom, left:right, :].copy())\n",
        "                    metadata.append(f\"{video_name},frame-{count}.face-{face_num}.jpg,{count},{face_num},{input_length},{fps},{frame_width},{frame_height},{top},{right},{bottom},{left}\\n\")\n",
        "                    face_num += 1\n",
        "                faces_all_frames.append(faces)\n",
        "\n",
        "                frame += 1\n",
        "            success, image = vidcap.read()\n",
        "            count += 1\n",
        "        video_num += 1\n",
        "        vidcap.release()\n",
        "\n",
        "        with open(f\"{self.output_folder}/faces-pickle/{video_name}.pkl\", \"wb\") as f_out:\n",
        "            pickle.dump(faces_all_frames, f_out)\n",
        "        return metadata\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERm_6Uli6PzN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d5c80d25-792f-43b1-ebe5-4aae50678d77"
      },
      "source": [
        "face_preprocessor = FacePreprocessor(\n",
        "    video_folder=\"drive/My Drive/cs231n-project/datasets/emotiw/train-tiny.zip\",\n",
        "    output_folder=\"train-tiny-faces\", \n",
        "    output_file=\"drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-faces.zip\"\n",
        ")\n",
        "face_preprocessor.preprocess()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Video Preprocessor created with is_zip = True, video_folder = drive/My Drive/cs231n-project/datasets/emotiw/train-tiny.zip , output_folder = train-tiny-faces, output_file = drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-faces.zip\n",
            "Frames will be created with height = 320 , width = 480 , sample_every = 10\n",
            "Unzipping files to temp dir train-tiny-faces_tmp...\n",
            "Finished unzipping files\n",
            "Found 50 videos\n",
            "Processing video 1/50 with name 324_96.mp4 \n",
            "\n",
            "Processing video 14/50 with name 112_5.mp4 \n",
            "\n",
            "Processing video 5/50 with name 2_2.mp4 \n",
            "Processing video 3/50 with name 34_9.mp4 \n",
            "\n",
            "\n",
            "Processing video 13/50 with name 188_22.mp4 \n",
            "\n",
            "Processing video 11/50 with name 276_3.mp4 \n",
            "\n",
            "Processing video 16/50 with name 16_14.mp4 \n",
            "\n",
            "Processing video 7/50 with name 33_20.mp4 \n",
            "\n",
            "Processing video 4/50 with name 204_13.mp4 \n",
            "\n",
            "Processing video 15/50 with name 69_30.mp4 \n",
            "Processing video 8/50 with name 97_22.mp4 \n",
            "Processing video 17/50 with name 334_21.mp4 \n",
            "Processing video 9/50 with name 277_3.mp4 \n",
            "\n",
            "Processing video 6/50 with name 300_56.mp4 \n",
            "\n",
            "Processing video 18/50 with name 101_30.mp4 \n",
            "\n",
            "Processing video 2/50 with name 303_41.mp4 \n",
            "\n",
            "Processing video 12/50 with name 108_13.mp4 \n",
            "\n",
            "Processing video 10/50 with name 133_2.mp4 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing video 20/50 with name 7_6.mp4 \n",
            "\n",
            "Processing video 19/50 with name 122_1.mp4 \n",
            "\n",
            "Processing video 22/50 with name 217_15.mp4 \n",
            "Processing video 21/50 with name 321_15.mp4 \n",
            "\n",
            "\n",
            "Processing video 23/50 with name 276_8.mp4 \n",
            "\n",
            "Processing video 24/50 with name 188_15.mp4 \n",
            "\n",
            "Processing video 25/50 with name 286_4.mp4 \n",
            "\n",
            "Processing video 26/50 with name 140_1.mp4 \n",
            "\n",
            "Processing video 27/50 with name 119_8.mp4 \n",
            "\n",
            "Processing video 28/50 with name 64_5.mp4 \n",
            "\n",
            "Processing video 29/50 with name 3_17.mp4 \n",
            "\n",
            "Processing video 30/50 with name 61_15.mp4 \n",
            "\n",
            "Processing video 31/50 with name 328_13.mp4 \n",
            "\n",
            "Processing video 32/50 with name 324_34.mp4 \n",
            "\n",
            "Processing video 33/50 with name 281_2.mp4 \n",
            "\n",
            "Processing video 34/50 with name 68_9.mp4 \n",
            "\n",
            "Processing video 35/50 with name 217_3.mp4 \n",
            "\n",
            "Processing video 36/50 with name 101_12.mp4 \n",
            "\n",
            "Processing video 37/50 with name 324_56.mp4 \n",
            "\n",
            "Processing video 38/50 with name 321_31.mp4 \n",
            "\n",
            "Processing video 39/50 with name 197_12.mp4 \n",
            "\n",
            "Processing video 40/50 with name 80_1.mp4 \n",
            "\n",
            "Processing video 41/50 with name 220_6.mp4 \n",
            "\n",
            "Processing video 42/50 with name 41_18.mp4 \n",
            "\n",
            "Processing video 43/50 with name 198_5.mp4 \n",
            "\n",
            "Processing video 44/50 with name 52_1.mp4 \n",
            "\n",
            "Processing video 45/50 with name 280_12.mp4 \n",
            "\n",
            "Processing video 46/50 with name 3_29.mp4 \n",
            "\n",
            "Processing video 48/50 with name 258_2.mp4 \n",
            "\n",
            "Processing video 47/50 with name 43_12.mp4 \n",
            "\n",
            "Processing video 49/50 with name 312_1.mp4 \n",
            "\n",
            "Processing video 50/50 with name 148_4.mp4 \n",
            "\n",
            "***** Submitted all tasks *****\n",
            "***** Completed *****\n",
            "Starting to zip files to drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-faces.zip\n",
            "Done zipping files to drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-faces.zip\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQJc7zHP8mTI",
        "colab_type": "text"
      },
      "source": [
        "### Pose Extraction\n",
        "\n",
        "Poses must be extracted from the frames so VideoProcessor must be run before this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIVa1CKI6gJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp drive/'My Drive'/cs231n-project/openpose/openpose.tar.gz ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pa8pkZJ8RCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xzf openpose.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcI8NL5r8gq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f86d8d43-b51a-492a-c3b6-00d1010408d4"
      },
      "source": [
        "!ls openpose"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3rdparty      build  CMakeLists.txt  examples  LICENSE\tpython\t   scripts\n",
            "appveyor.yml  cmake  doc\t     include   models\tREADME.md  src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_eYdeiG8bCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "p = subprocess.run([\"build/examples/openpose/openpose.bin\", \"--image_dir\", \"/content/train_frames/3\", \"--write_json\", \"/content/train_frames_keypoints/3\", \"--display\", \"0\", \"--render_pose\", \"0\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, encoding='utf-8')\n",
        "print(p.stdout)\n",
        "print(p.stderr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0Gz6HIT8x1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import cv2\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from pathlib import Path\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "import pickle\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "class PosePreprocessor:\n",
        "    \"\"\"\n",
        "    Extract the poses from the video frames.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, video_frame_folder, output_folder, output_file=None, is_zip=True):\n",
        "        \"\"\"\n",
        "        @param video_frame_folder    The folder where the list of videos frames are stored. If \n",
        "                                     `is_zip` is set to True, this should be a single zip \n",
        "                                     file containing the video frames. Paths can either by a local \n",
        "                                     folder or a GDrive mounted path.\n",
        "        @param output_folder         The local output path where the preprocessed files will be stored for \n",
        "                                     further preprocessing can be done\n",
        "        @param output_file           If not none, the output_folder will be zipped up and stored at this location\n",
        "        @param is_zip                If set to True, the `video_frame_folder` will be unzipped prior to accessing\n",
        "        \"\"\"\n",
        "        self.is_zip = is_zip\n",
        "        self.video_frame_folder = video_frame_folder\n",
        "        self.output_folder = output_folder\n",
        "        self.output_file = output_file\n",
        "        print(f\"Pose Preprocessor created with is_zip = {is_zip}, video_frame_folder = {video_frame_folder} , output_folder = {output_folder}, output_file = {output_file}\")\n",
        "\n",
        "    def preprocess(self):\n",
        "        if self.is_zip:\n",
        "            # Unzips files to a temp directory\n",
        "            tmp_output_folder = self.output_folder.rstrip('/') + \"_tmp\"\n",
        "            print(f\"Unzipping files to temp dir {tmp_output_folder}...\")\n",
        "            Path(f\"{tmp_output_folder}\").mkdir(parents=True, exist_ok=True)\n",
        "            with zipfile.ZipFile(self.video_frame_folder, 'r') as zip_ref:\n",
        "                zip_ref.extractall(tmp_output_folder)\n",
        "            print(\"Finished unzipping files\")\n",
        "        else:\n",
        "            tmp_output_folder = self.video_frame_folder\n",
        "            print(\"Skipping unzipping files as input is a folder\")\n",
        "\n",
        "        # Create output folder for the keypoints\n",
        "        Path(f\"{self.output_folder}\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Subfolders represent the different categories \n",
        "        # (we will mimic this for the final output)\n",
        "        subfolders = next(os.walk(tmp_output_folder))[1]\n",
        "        for subfolder in subfolders:\n",
        "            print(f\"Starting pose extraction for {join(tmp_output_folder, subfolder)}\")\n",
        "            p = subprocess.run([\"build/examples/openpose/openpose.bin\", \"--image_dir\", \"../\" + join(tmp_output_folder, subfolder), \"--write_json\", \"../\" + join(self.output_folder, subfolder), \"--display\", \"0\", \"--render_pose\", \"0\"], cwd=\"openpose\", stdout=subprocess.PIPE, stderr=subprocess.PIPE, encoding='utf-8')\n",
        "            print(p.stdout)\n",
        "            print(p.stderr)\n",
        "\n",
        "        if self.output_file is not None:\n",
        "            print(f\"Starting to zip files to {self.output_file}\")\n",
        "            def zipdir(path, ziph):\n",
        "                for root, dirs, files in os.walk(path):\n",
        "                    for file in files:\n",
        "                        ziph.write(join(root, file))\n",
        "\n",
        "            zipf = zipfile.ZipFile(self.output_file, 'w', zipfile.ZIP_DEFLATED)\n",
        "            zipdir(self.output_folder, zipf)\n",
        "            zipf.close()\n",
        "            print(f\"Done zipping files to {self.output_file}\")\n",
        "        \n",
        "        print(\"Done!\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_2x6JSVAB6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21a71fd9-4f95-4443-e87a-cc0948b35fa8"
      },
      "source": [
        "!apt-get -qq install -y libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler libgflags-dev libgoogle-glog-dev liblmdb-dev opencl-headers ocl-icd-opencl-dev libviennacl-dev"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package libgflags2.2.\n",
            "(Reading database ... 144433 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libgflags2.2_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags2.2 (2.2.1-1) ...\n",
            "Selecting previously unselected package libgflags-dev.\n",
            "Preparing to unpack .../01-libgflags-dev_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags-dev (2.2.1-1) ...\n",
            "Selecting previously unselected package libgoogle-glog0v5.\n",
            "Preparing to unpack .../02-libgoogle-glog0v5_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Selecting previously unselected package libgoogle-glog-dev.\n",
            "Preparing to unpack .../03-libgoogle-glog-dev_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog-dev (0.3.5-1) ...\n",
            "Selecting previously unselected package libhdf5-serial-dev.\n",
            "Preparing to unpack .../04-libhdf5-serial-dev_1.10.0-patch1+docs-4_all.deb ...\n",
            "Unpacking libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Selecting previously unselected package libleveldb1v5:amd64.\n",
            "Preparing to unpack .../05-libleveldb1v5_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb1v5:amd64 (1.20-2) ...\n",
            "Selecting previously unselected package libleveldb-dev:amd64.\n",
            "Preparing to unpack .../06-libleveldb-dev_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb-dev:amd64 (1.20-2) ...\n",
            "Selecting previously unselected package liblmdb0:amd64.\n",
            "Preparing to unpack .../07-liblmdb0_0.9.21-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package liblmdb-dev:amd64.\n",
            "Preparing to unpack .../08-liblmdb-dev_0.9.21-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblmdb-dev:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libprotobuf-lite10:amd64.\n",
            "Preparing to unpack .../09-libprotobuf-lite10_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package lmdb-doc.\n",
            "Preparing to unpack .../10-lmdb-doc_0.9.21-1ubuntu0.1_all.deb ...\n",
            "Unpacking lmdb-doc (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libprotobuf-dev:amd64.\n",
            "Preparing to unpack .../11-libprotobuf-dev_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package libsnappy-dev:amd64.\n",
            "Preparing to unpack .../12-libsnappy-dev_1.1.7-1_amd64.deb ...\n",
            "Unpacking libsnappy-dev:amd64 (1.1.7-1) ...\n",
            "Selecting previously unselected package libviennacl-dev.\n",
            "Preparing to unpack .../13-libviennacl-dev_1.7.1+dfsg1-2ubuntu1_all.deb ...\n",
            "Unpacking libviennacl-dev (1.7.1+dfsg1-2ubuntu1) ...\n",
            "Selecting previously unselected package opencl-clhpp-headers.\n",
            "Preparing to unpack .../14-opencl-clhpp-headers_2.0.10+git12-g5dd8bb9-1_all.deb ...\n",
            "Unpacking opencl-clhpp-headers (2.0.10+git12-g5dd8bb9-1) ...\n",
            "Selecting previously unselected package opencl-headers.\n",
            "Preparing to unpack .../15-opencl-headers_2.2~2018.02.21-gb5c3680-1_all.deb ...\n",
            "Unpacking opencl-headers (2.2~2018.02.21-gb5c3680-1) ...\n",
            "Setting up libviennacl-dev (1.7.1+dfsg1-2ubuntu1) ...\n",
            "Setting up libgflags2.2 (2.2.1-1) ...\n",
            "Setting up libgflags-dev (2.2.1-1) ...\n",
            "Setting up liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Setting up opencl-clhpp-headers (2.0.10+git12-g5dd8bb9-1) ...\n",
            "Setting up libleveldb1v5:amd64 (1.20-2) ...\n",
            "Setting up libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Setting up libsnappy-dev:amd64 (1.1.7-1) ...\n",
            "Setting up libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Setting up liblmdb-dev:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Setting up lmdb-doc (0.9.21-1ubuntu0.1) ...\n",
            "Setting up libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up opencl-headers (2.2~2018.02.21-gb5c3680-1) ...\n",
            "Setting up libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libleveldb-dev:amd64 (1.20-2) ...\n",
            "Setting up libgoogle-glog-dev (0.3.5-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_TR0Jlc94w3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "e10279b4-7d63-4568-9085-ccf49d4b7792"
      },
      "source": [
        "pose_preprocessor = PosePreprocessor(\n",
        "    video_frame_folder=\"drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-local.zip\",\n",
        "    output_folder=\"train-tiny-pose\", \n",
        "    output_file=\"drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-pose.zip\"\n",
        ")\n",
        "pose_preprocessor.preprocess()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pose Preprocessor created with is_zip = True, video_frame_folder = drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-local.zip , output_folder = train-tiny-pose, output_file = drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-pose.zip\n",
            "Unzipping files to temp dir train-tiny-pose_tmp...\n",
            "Finished unzipping files\n",
            "Starting pose extraction for train-tiny-pose_tmp/2\n",
            "Starting OpenPose demo...\n",
            "Configuring OpenPose...\n",
            "Starting thread(s)...\n",
            "Auto-detecting all available GPUs... Detected 1 GPU(s), using 1 of them starting at GPU 0.\n",
            "OpenPose demo successfully finished. Total time: 16.510883 seconds.\n",
            "\n",
            "\n",
            "Starting pose extraction for train-tiny-pose_tmp/3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkfCvxLGBU3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}