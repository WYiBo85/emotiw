{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video_preprocessor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAfS_VQphFOI",
        "colab_type": "text"
      },
      "source": [
        "### Video Pre-processor\n",
        "\n",
        "Consumes the videos from a file and produces files that can be used by downstream models and/or downstream preprocessors. \n",
        "\n",
        "This is the first step in the video preprocessing pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNI9YJehDOYd",
        "colab_type": "code",
        "outputId": "ca4268fc-c185-4d06-f5de-8ed8152c1156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igkQYjwH6B_j",
        "colab_type": "text"
      },
      "source": [
        "### Create a tiny video folder for testing and debugging purposes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnO_riN1_gDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp 'drive/My Drive/cs231n-project/datasets/emotiw/val_frames.tar.gz' .\n",
        "!tar -xzf val_frames.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7xLmtUxAOKK",
        "colab_type": "code",
        "outputId": "d967068b-5d85-4ada-ee33-647764f7c0aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t  openpose.tar.gz  val_frames\t      val-tiny-pose_tmp\n",
            "openpose  sample_data\t   val_frames.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4J-pyLN_0zu",
        "colab_type": "code",
        "outputId": "c8bf1905-03d8-4cdd-cde8-1643341a6edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "videos = next(os.walk(\"drive/My Drive/cs231n-project/datasets/emotiw/val\"))[2]\n",
        "print(len(videos))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppRlFxZ2A454",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir test-tiny"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTcuFeW1ApQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from shutil import copyfile\n",
        "\n",
        "i = len(videos) - 1\n",
        "j = 0\n",
        "while j < 50:\n",
        "    copyfile(os.path.join(\"drive/My Drive/cs231n-project/datasets/emotiw/val\", videos[i]), os.path.join(\"test-tiny\", videos[i]))\n",
        "    j += 1\n",
        "    i -= 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHQ5NA_UBR8h",
        "colab_type": "code",
        "outputId": "2a2a1240-1215-402e-df91-0e1789ebca3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!ls test-tiny"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100_1.mp4  44_29.mp4  5_2.mp4\t 53_3.mp4   54_13.mp4  81_13.mp4  86_42.mp4\n",
            "11_12.mp4  44_9.mp4   53_12.mp4  53_47.mp4  54_8.mp4   81_4.mp4   86_6.mp4\n",
            "11_1.mp4   45_1.mp4   53_14.mp4  53_48.mp4  55_19.mp4  83_1.mp4\n",
            "31_2.mp4   45_5.mp4   53_15.mp4  53_49.mp4  55_2.mp4   86_11.mp4\n",
            "31_3.mp4   45_6.mp4   53_33.mp4  53_7.mp4   55_7.mp4   86_19.mp4\n",
            "31_5.mp4   5_11.mp4   53_35.mp4  53_8.mp4   55_8.mp4   86_20.mp4\n",
            "44_17.mp4  5_16.mp4   53_36.mp4  53_9.mp4   70_24.mp4  86_26.mp4\n",
            "44_26.mp4  5_1.mp4    53_39.mp4  54_10.mp4  77_3.mp4   86_40.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP1aKrDuBluC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -j test-tiny.zip test-tiny/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-ECv6EZCcgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp test-tiny.zip \"drive/My Drive/cs231n-project/datasets/emotiw\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5teG4O-X6Hhm",
        "colab_type": "text"
      },
      "source": [
        "### Video preprocessing to extract frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxhjkzmem8dK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import cv2\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from pathlib import Path\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "\n",
        "class VideoPreprocessor:\n",
        "    \"\"\"\n",
        "    Preprocesses raw videos into frames so that further downstream extraction and\n",
        "    preprocessing can occur\n",
        "\n",
        "    Example usage:\n",
        "\n",
        "    video_preprocessor = VideoPreprocessor(\n",
        "        video_folder=\"drive/My Drive/cs231n-project/datasets/emotiw/train-tiny.zip\", \n",
        "        label_file=\"drive/My Drive/cs231n-project/datasets/emotiw/Train_labels.txt\", \n",
        "        output_folder=\"train-tiny-local\", \n",
        "        output_file=\"drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-local.zip\"\n",
        "    )\n",
        "    video_preprocessor.preprocess()\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, video_folder, output_folder, output_file=None, label_file=None, is_zip=True, height=320, width=480, sample_every=10, max_workers=32):\n",
        "        \"\"\"\n",
        "        @param video_folder   The folder where the list of videos are stored. If \n",
        "                              `is_zip` is set to True, this should be a single zip \n",
        "                              file containing the videos. Paths can either by a local \n",
        "                              folder or a GDrive mounted path.\n",
        "        @param label_file     The file containing the space-delimited video name to label mapping. If None,\n",
        "                              we assume that we are in 'test' mode and that there are no categories\n",
        "        @param output_folder  The local output path where the preprocessed files will be stored for \n",
        "                              further preprocessing can be done\n",
        "        @param output_file    If not none, the output_folder will be zipped up and stored at this location\n",
        "        @param is_zip         If set to True, the `video_folder` will be unzipped prior to accessing\n",
        "        @param height         Height of the extracted video frames\n",
        "        @param width          Width of the extracted video frames\n",
        "        @param sample_every   The frames to skip.\n",
        "        @param max_workers    The number of workers to use to parallelize work.\n",
        "        \"\"\"\n",
        "        self.is_zip = is_zip\n",
        "        self.video_folder = video_folder\n",
        "        self.label_file = label_file\n",
        "        self.output_folder = output_folder\n",
        "        self.output_file = output_file\n",
        "        print(f\"Video Preprocessor created with is_zip = {is_zip}, video_folder = {video_folder} , label_file = {label_file} , output_folder = {output_folder}, output_file = {output_file}\")\n",
        "        \n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.sample_every = sample_every\n",
        "        self.max_workers = max_workers\n",
        "        print(f\"Frames will be created with height = {height} , width = {width} , sample_every = {sample_every}\")\n",
        "\n",
        "\n",
        "    def preprocess(self):\n",
        "        if self.is_zip:\n",
        "            # Unzips files to a temp directory\n",
        "            tmp_output_folder = self.output_folder.rstrip('/') + \"_tmp\"\n",
        "            print(f\"Unzipping files to temp dir {tmp_output_folder}...\")\n",
        "            Path(f\"{tmp_output_folder}\").mkdir(parents=True, exist_ok=True)\n",
        "            with zipfile.ZipFile(self.video_folder, 'r') as zip_ref:\n",
        "                zip_ref.extractall(tmp_output_folder)\n",
        "            print(\"Finished unzipping files\")\n",
        "        else:\n",
        "            tmp_output_folder = self.video_folder\n",
        "            print(\"Skipping unzipping files as input is a folder\")\n",
        "        \n",
        "        if self.label_file is not None:\n",
        "            # Create the category subfolders in the output folder\n",
        "            # Path Structure:\n",
        "            #   output/\n",
        "            #     1/\n",
        "            #     2/\n",
        "            video_to_label = {}\n",
        "            unique_labels = set()\n",
        "            with open(self.label_file, \"r\") as f:\n",
        "                i = 0\n",
        "                for line in f:\n",
        "                    if i == 0:\n",
        "                        i += 1\n",
        "                        continue\n",
        "                    line_arr = line.split(\" \")\n",
        "                    video_to_label[line_arr[0] + \".mp4\"] = line_arr[1].strip()\n",
        "                    if line_arr[1].strip() not in unique_labels:\n",
        "                        unique_labels.add(line_arr[1].strip())\n",
        "                        Path(f\"{self.output_folder}/{line_arr[1].strip()}\").mkdir(parents=True, exist_ok=True)\n",
        "                    i += 1\n",
        "        else:\n",
        "            video_to_label = None\n",
        "            Path(f\"{self.output_folder}\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Process each video by extracting the frames in a multi-threaded fashion\n",
        "        futures = []\n",
        "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
        "            videos = next(os.walk(tmp_output_folder))[2]\n",
        "            videos = sorted(videos)\n",
        "\n",
        "            print(f\"Found {len(videos)} videos\")\n",
        "            video_num = 1\n",
        "\n",
        "            for video_name in videos:\n",
        "                future = executor.submit(self.process_video, tmp_output_folder, video_name, video_num, len(videos), video_to_label)\n",
        "                futures.append(future)\n",
        "                video_num += 1\n",
        "\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "        print(\"***** Submitted all tasks *****\")\n",
        "        for future in futures:\n",
        "            future.result()\n",
        "        print(\"***** Completed *****\")\n",
        "\n",
        "        if self.output_file is not None:\n",
        "            print(f\"Starting to zip files to {self.output_file}\")\n",
        "            def zipdir(path, ziph):\n",
        "                for root, dirs, files in os.walk(path):\n",
        "                    folder = root[len(path):]\n",
        "                    for file in files:\n",
        "                        ziph.write(join(root, file), join(folder, file))\n",
        "\n",
        "            zipf = zipfile.ZipFile(self.output_file, 'w', zipfile.ZIP_DEFLATED)\n",
        "            zipdir(self.output_folder, zipf)\n",
        "            zipf.close()\n",
        "            print(f\"Done zipping files to {self.output_file}\")\n",
        "        \n",
        "        print(\"Done!\")\n",
        "\n",
        "    def process_video(self, tmp_output_folder, video_name, video_num, total_videos, video_to_label):\n",
        "        \"\"\"\n",
        "        Processes a video by extracting the frames\n",
        "        Writes out each frame, where each frame is an image resized to the the specified dimensions\n",
        "        \"\"\"\n",
        "        vidcap = cv2.VideoCapture(join(tmp_output_folder, video_name))\n",
        "        if video_to_label is not None:\n",
        "            label = video_to_label[video_name]\n",
        "            print(f\"Processing video {video_num}/{total_videos} with name {video_name} and class {label} \\n\")\n",
        "        else:\n",
        "            label = None\n",
        "            print(f\"Processing video {video_num}/{total_videos} with name {video_name} (test-mode) \\n\")\n",
        "\n",
        "        input_length = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        frame_width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        frame_height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "        success, image = vidcap.read()\n",
        "        count = 0\n",
        "        frame = 0\n",
        "        while success:\n",
        "            if count % self.sample_every == 0:\n",
        "                height, width = image.shape[:2]\n",
        "                image = cv2.resize(image, (self.width, self.height), interpolation = cv2.INTER_CUBIC)\n",
        "                if video_to_label is not None:\n",
        "                    cv2.imwrite(f\"{self.output_folder}/{label}/frame_{video_name}_{frame}.jpg\", image)\n",
        "                else:\n",
        "                    cv2.imwrite(f\"{self.output_folder}/frame_{video_name}_{frame}.jpg\", image)\n",
        "\n",
        "                frame += 1\n",
        "            success, image = vidcap.read()\n",
        "            count += 1\n",
        "        video_num += 1\n",
        "        vidcap.release()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_OFm_yJYA22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HOME_DIR = \"drive/My Drive/Machine-Learning-Projects/\"\n",
        "video_preprocessor = VideoPreprocessor(\n",
        "    video_folder= HOME_DIR + \"cs231n-project/datasets/emotiw/train-tiny.zip\", \n",
        "    label_file= HOME_DIR + \"cs231n-project/datasets/emotiw/Train_labels.txt\", \n",
        "    output_folder=\"train-tiny-local\", \n",
        "    output_file= HOME_DIR + \"cs231n-project/datasets/emotiw/train-tiny-local.zip\"\n",
        ")\n",
        "video_preprocessor.preprocess()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb7Prj6K-dL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HOME_DIR = \"drive/My Drive/\"\n",
        "video_preprocessor = VideoPreprocessor(\n",
        "    video_folder= HOME_DIR + \"cs231n-project/datasets/emotiw/val-tiny.zip\", \n",
        "    label_file= HOME_DIR + \"cs231n-project/datasets/emotiw/Val_labels.txt\", \n",
        "    output_folder=\"val-tiny-local\", \n",
        "    output_file= HOME_DIR + \"cs231n-project/datasets/emotiw/val-tiny-local.zip\"\n",
        ")\n",
        "video_preprocessor.preprocess()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-FgAGorDXXB",
        "colab_type": "code",
        "outputId": "48aa5b87-df38-42da-83cc-f7bf885c23ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "HOME_DIR = \"drive/My Drive/\"\n",
        "video_preprocessor = VideoPreprocessor(\n",
        "    video_folder= HOME_DIR + \"cs231n-project/datasets/emotiw/test-tiny.zip\", \n",
        "    output_folder=\"test-tiny-local\", \n",
        "    output_file= HOME_DIR + \"cs231n-project/datasets/emotiw/test-tiny-local.zip\"\n",
        ")\n",
        "video_preprocessor.preprocess()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Video Preprocessor created with is_zip = True, video_folder = drive/My Drive/cs231n-project/datasets/emotiw/test-tiny.zip , label_file = None , output_folder = test-tiny-local, output_file = drive/My Drive/cs231n-project/datasets/emotiw/test-tiny-local.zip\n",
            "Frames will be created with height = 320 , width = 480 , sample_every = 10\n",
            "Unzipping files to temp dir test-tiny-local_tmp...\n",
            "Finished unzipping files\n",
            "Found 50 videos\n",
            "Processing video 1/50 with name 100_1.mp4 (test-mode) \n",
            "\n",
            "Processing video 2/50 with name 11_1.mp4 (test-mode) \n",
            "\n",
            "Processing video 4/50 with name 31_2.mp4 (test-mode) \n",
            "\n",
            "Processing video 6/50 with name 31_5.mp4 (test-mode) \n",
            "\n",
            "Processing video 8/50 with name 44_26.mp4 (test-mode) \n",
            "\n",
            "Processing video 9/50 with name 44_29.mp4 (test-mode) \n",
            "\n",
            "Processing video 11/50 with name 45_1.mp4 (test-mode) \n",
            "\n",
            "Processing video 12/50 with name 45_5.mp4 (test-mode) \n",
            "\n",
            "Processing video 15/50 with name 53_14.mp4 (test-mode) \n",
            "Processing video 14/50 with name 53_12.mp4 (test-mode) \n",
            "\n",
            "\n",
            "Processing video 17/50 with name 53_3.mp4 (test-mode) \n",
            "\n",
            "Processing video 19/50 with name 53_35.mp4 (test-mode) \n",
            "\n",
            "Processing video 21/50 with name 53_39.mp4 (test-mode) \n",
            "\n",
            "Processing video 22/50 with name 53_47.mp4 (test-mode) \n",
            "Processing video 24/50 with name 53_49.mp4 (test-mode) \n",
            "\n",
            "\n",
            "Processing video 25/50 with name 53_7.mp4 (test-mode) \n",
            "\n",
            "Processing video 27/50 with name 53_9.mp4 (test-mode) \n",
            "\n",
            "Processing video 29/50 with name 54_13.mp4 (test-mode) \n",
            "\n",
            "Processing video 13/50 with name 45_6.mp4 (test-mode) \n",
            "\n",
            "Processing video 7/50 with name 44_17.mp4 (test-mode) \n",
            "\n",
            "Processing video 20/50 with name 53_36.mp4 (test-mode) \n",
            "\n",
            "Processing video 3/50 with name 11_12.mp4 (test-mode) \n",
            "\n",
            "Processing video 23/50 with name 53_48.mp4 (test-mode) \n",
            "\n",
            "Processing video 26/50 with name 53_8.mp4 (test-mode) \n",
            "\n",
            "Processing video 5/50 with name 31_3.mp4 (test-mode) \n",
            "\n",
            "Processing video 16/50 with name 53_15.mp4 (test-mode) \n",
            "\n",
            "Processing video 31/50 with name 55_19.mp4 (test-mode) \n",
            "\n",
            "Processing video 30/50 with name 54_8.mp4 (test-mode) \n",
            "\n",
            "Processing video 10/50 with name 44_9.mp4 (test-mode) \n",
            "\n",
            "Processing video 28/50 with name 54_10.mp4 (test-mode) \n",
            "\n",
            "Processing video 32/50 with name 55_2.mp4 (test-mode) \n",
            "\n",
            "Processing video 18/50 with name 53_33.mp4 (test-mode) \n",
            "\n",
            "Processing video 33/50 with name 55_7.mp4 (test-mode) \n",
            "\n",
            "Processing video 34/50 with name 55_8.mp4 (test-mode) \n",
            "\n",
            "Processing video 36/50 with name 5_11.mp4 (test-mode) \n",
            "\n",
            "Processing video 35/50 with name 5_1.mp4 (test-mode) \n",
            "\n",
            "Processing video 37/50 with name 5_16.mp4 (test-mode) \n",
            "\n",
            "Processing video 38/50 with name 5_2.mp4 (test-mode) \n",
            "\n",
            "Processing video 39/50 with name 70_24.mp4 (test-mode) \n",
            "\n",
            "Processing video 41/50 with name 81_13.mp4 (test-mode) \n",
            "\n",
            "Processing video 43/50 with name 83_1.mp4 (test-mode) \n",
            "\n",
            "Processing video 42/50 with name 81_4.mp4 (test-mode) \n",
            "\n",
            "Processing video 45/50 with name 86_19.mp4 (test-mode) \n",
            "\n",
            "Processing video 47/50 with name 86_26.mp4 (test-mode) \n",
            "\n",
            "Processing video 48/50 with name 86_40.mp4 (test-mode) \n",
            "\n",
            "Processing video 49/50 with name 86_42.mp4 (test-mode) \n",
            "\n",
            "Processing video 46/50 with name 86_20.mp4 (test-mode) \n",
            "\n",
            "Processing video 44/50 with name 86_11.mp4 (test-mode) \n",
            "\n",
            "Processing video 40/50 with name 77_3.mp4 (test-mode) \n",
            "\n",
            "Processing video 50/50 with name 86_6.mp4 (test-mode) \n",
            "\n",
            "***** Submitted all tasks *****\n",
            "***** Completed *****\n",
            "Starting to zip files to drive/My Drive/cs231n-project/datasets/emotiw/test-tiny-local.zip\n",
            "Done zipping files to drive/My Drive/cs231n-project/datasets/emotiw/test-tiny-local.zip\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ3jWsaB49Tj",
        "colab_type": "code",
        "outputId": "1ede2a97-ba17-44fc-9b2e-3a9b8d0da66e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "!pip install face_recognition"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 41kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.18.4)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566172 sha256=b390a13e5824c6e7568babbe9c2f2c7809afc357698b622c130927e96f469dae\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qKhN_Kc1XOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import cv2\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from pathlib import Path\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "import face_recognition\n",
        "import pickle\n",
        "\n",
        "class FacePreprocessor:\n",
        "    \"\"\"\n",
        "    Extract the faces from the videos.\n",
        "    Faces are stored in a flat directory structure (no categorical hierarchy)\n",
        "    \n",
        "    Processes a video by extracting the faces from each frame and creating a \n",
        "    list of list of faces which is then saved as a pickled object.\n",
        "\n",
        "    NOTE: Faces are not guaranteed to be the same across frames.\n",
        "          eg. 'face 1' in frame 1 may not be the same as 'face 1' in frame 2\n",
        "\n",
        "    Pickle Object Format:\n",
        "        [\n",
        "            [\n",
        "                [frame 1, face 1],\n",
        "                [frame 1, face 2],\n",
        "                [frame 1, face 3]\n",
        "            ],\n",
        "            [\n",
        "                [frame 2, face 1],\n",
        "                [frame 2, face 2]\n",
        "            ],\n",
        "            ...\n",
        "        ]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, video_folder, output_folder, output_file=None, is_zip=True, height=320, width=480, sample_every=10, max_workers=32):\n",
        "        \"\"\"\n",
        "        @param video_folder          The folder where the list of videos frames are stored. If \n",
        "                                     `is_zip` is set to True, this should be a single zip \n",
        "                                     file containing the video frames. Paths can either by a local \n",
        "                                     folder or a GDrive mounted path.\n",
        "        @param output_folder         The local output path where the preprocessed files will be stored for \n",
        "                                     further preprocessing can be done\n",
        "        @param output_file           If not none, the output_folder will be zipped up and stored at this location\n",
        "        @param is_zip                If set to True, the `video_folder` will be unzipped prior to accessing\n",
        "        @param height         Height of the extracted video frames\n",
        "        @param width          Width of the extracted video frames\n",
        "        @param sample_every   The frames to skip.\n",
        "        @param max_workers    The number of workers to use to parallelize work.\n",
        "        \"\"\"\n",
        "        self.is_zip = is_zip\n",
        "        self.video_folder = video_folder\n",
        "        self.output_folder = output_folder\n",
        "        self.output_file = output_file\n",
        "        print(f\"Video Preprocessor created with is_zip = {is_zip}, video_folder = {video_folder} , output_folder = {output_folder}, output_file = {output_file}\")\n",
        "\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.sample_every = sample_every\n",
        "        self.max_workers = max_workers\n",
        "        print(f\"Frames will be created with height = {height} , width = {width} , sample_every = {sample_every}\")\n",
        "\n",
        "    def preprocess(self):\n",
        "        tmp_output_folder = \"\"\n",
        "        if self.is_zip:\n",
        "            # Unzips files to a temp directory\n",
        "            tmp_output_folder = self.output_folder.rstrip('/') + \"_tmp\"\n",
        "            print(f\"Unzipping files to temp dir {tmp_output_folder}...\")\n",
        "            Path(f\"{tmp_output_folder}\").mkdir(parents=True, exist_ok=True)\n",
        "            with zipfile.ZipFile(self.video_folder, 'r') as zip_ref:\n",
        "                zip_ref.extractall(tmp_output_folder)\n",
        "            print(\"Finished unzipping files\")\n",
        "        else:\n",
        "            tmp_output_folder = self.video_folder\n",
        "            print(\"Skipping unzipping files as input is a folder\")\n",
        "\n",
        "        # Create output folder\n",
        "        Path(f\"{self.output_folder}/faces-pickle/\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Process each video by extracting the frames in a multi-threaded fashion\n",
        "        futures = []\n",
        "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
        "            videos = next(os.walk(tmp_output_folder))[2]\n",
        "            print(f\"Found {len(videos)} videos\")\n",
        "            video_num = 1\n",
        "\n",
        "            for video_name in videos:\n",
        "                future = executor.submit(self.process_video, self.process_audio m tmp_output_folder, video_name, video_num, len(videos))\n",
        "                futures.append(future)\n",
        "                video_num += 1\n",
        "\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "        print(\"***** Submitted all tasks *****\")\n",
        "        with open(f\"{self.output_folder}/summary.txt\", 'w') as f:\n",
        "            f.write(f\"video_name,face_image_name,frame_number,face_number,total_frames,fps,video_width,video_height,top,right,bottom,left\\n\")\n",
        "            for future in futures:\n",
        "                out_arr = future.result()\n",
        "                for out in out_arr:\n",
        "                    f.write(out)\n",
        "        print(\"***** Completed *****\")\n",
        "\n",
        "\n",
        "        if self.output_file is not None:\n",
        "            print(f\"Starting to zip files to {self.output_file}\")\n",
        "            def zipdir(path, ziph):\n",
        "                for root, dirs, files in os.walk(path):\n",
        "                    folder = root[len(path):]\n",
        "                    for file in files:\n",
        "                        ziph.write(join(root, file), join(folder, file))\n",
        "\n",
        "            zipf = zipfile.ZipFile(self.output_file, 'w', zipfile.ZIP_DEFLATED)\n",
        "            zipdir(self.output_folder, zipf)\n",
        "            zipf.close()\n",
        "            print(f\"Done zipping files to {self.output_file}\")\n",
        "        \n",
        "        print(\"Done!\")\n",
        "\n",
        "\n",
        "    def process_video(self, tmp_output_folder, video_name, video_num, total_videos):\n",
        "        \"\"\"\n",
        "        Processes a video by extracting the faces\n",
        "        \"\"\"\n",
        "        vidcap = cv2.VideoCapture(join(tmp_output_folder, video_name))\n",
        "        print(f\"Processing video {video_num}/{total_videos} with name {video_name} \\n\")\n",
        "\n",
        "        input_length = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        frame_width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        frame_height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "        metadata = []\n",
        "        faces_all_frames = []\n",
        "        success, image = vidcap.read()\n",
        "        count = 0\n",
        "        frame = 0\n",
        "        while success:\n",
        "            if count % self.sample_every == 0:\n",
        "                height, width = image.shape[:2]\n",
        "                image = cv2.resize(image, (self.width, self.height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "                # Convert from BGR color (OpenCV) to RGB color (face_recognition)\n",
        "                rgb_image = image[:, :, ::-1]\n",
        "\n",
        "                # Find all the faces in the current frame of video\n",
        "                face_locations = face_recognition.face_locations(rgb_image)\n",
        "                faces = []\n",
        "                face_num = 0\n",
        "                # Display the results\n",
        "                for top, right, bottom, left in face_locations:\n",
        "                    # Draw a box around the face\n",
        "                    faces.append(image[top:bottom, left:right, :].copy())\n",
        "                    metadata.append(f\"{video_name},frame-{count}.face-{face_num}.jpg,{count},{face_num},{input_length},{fps},{frame_width},{frame_height},{top},{right},{bottom},{left}\\n\")\n",
        "                    face_num += 1\n",
        "                faces_all_frames.append(faces)\n",
        "\n",
        "                frame += 1\n",
        "            success, image = vidcap.read()\n",
        "            count += 1\n",
        "        video_num += 1\n",
        "        vidcap.release()\n",
        "\n",
        "        with open(f\"{self.output_folder}/faces-pickle/{video_name}.pkl\", \"wb\") as f_out:\n",
        "            pickle.dump(faces_all_frames, f_out)\n",
        "        return metadata\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERm_6Uli6PzN",
        "colab_type": "code",
        "outputId": "d5c80d25-792f-43b1-ebe5-4aae50678d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "face_preprocessor = FacePreprocessor(\n",
        "    video_folder=\"drive/My Drive/cs231n-project/datasets/emotiw/train-tiny.zip\",\n",
        "    output_folder=\"train-tiny-faces\", \n",
        "    output_file=\"drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-faces.zip\"\n",
        ")\n",
        "face_preprocessor.preprocess()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Video Preprocessor created with is_zip = True, video_folder = drive/My Drive/cs231n-project/datasets/emotiw/train-tiny.zip , output_folder = train-tiny-faces, output_file = drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-faces.zip\n",
            "Frames will be created with height = 320 , width = 480 , sample_every = 10\n",
            "Unzipping files to temp dir train-tiny-faces_tmp...\n",
            "Finished unzipping files\n",
            "Found 50 videos\n",
            "Processing video 1/50 with name 324_96.mp4 \n",
            "\n",
            "Processing video 14/50 with name 112_5.mp4 \n",
            "\n",
            "Processing video 5/50 with name 2_2.mp4 \n",
            "Processing video 3/50 with name 34_9.mp4 \n",
            "\n",
            "\n",
            "Processing video 13/50 with name 188_22.mp4 \n",
            "\n",
            "Processing video 11/50 with name 276_3.mp4 \n",
            "\n",
            "Processing video 16/50 with name 16_14.mp4 \n",
            "\n",
            "Processing video 7/50 with name 33_20.mp4 \n",
            "\n",
            "Processing video 4/50 with name 204_13.mp4 \n",
            "\n",
            "Processing video 15/50 with name 69_30.mp4 \n",
            "Processing video 8/50 with name 97_22.mp4 \n",
            "Processing video 17/50 with name 334_21.mp4 \n",
            "Processing video 9/50 with name 277_3.mp4 \n",
            "\n",
            "Processing video 6/50 with name 300_56.mp4 \n",
            "\n",
            "Processing video 18/50 with name 101_30.mp4 \n",
            "\n",
            "Processing video 2/50 with name 303_41.mp4 \n",
            "\n",
            "Processing video 12/50 with name 108_13.mp4 \n",
            "\n",
            "Processing video 10/50 with name 133_2.mp4 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing video 20/50 with name 7_6.mp4 \n",
            "\n",
            "Processing video 19/50 with name 122_1.mp4 \n",
            "\n",
            "Processing video 22/50 with name 217_15.mp4 \n",
            "Processing video 21/50 with name 321_15.mp4 \n",
            "\n",
            "\n",
            "Processing video 23/50 with name 276_8.mp4 \n",
            "\n",
            "Processing video 24/50 with name 188_15.mp4 \n",
            "\n",
            "Processing video 25/50 with name 286_4.mp4 \n",
            "\n",
            "Processing video 26/50 with name 140_1.mp4 \n",
            "\n",
            "Processing video 27/50 with name 119_8.mp4 \n",
            "\n",
            "Processing video 28/50 with name 64_5.mp4 \n",
            "\n",
            "Processing video 29/50 with name 3_17.mp4 \n",
            "\n",
            "Processing video 30/50 with name 61_15.mp4 \n",
            "\n",
            "Processing video 31/50 with name 328_13.mp4 \n",
            "\n",
            "Processing video 32/50 with name 324_34.mp4 \n",
            "\n",
            "Processing video 33/50 with name 281_2.mp4 \n",
            "\n",
            "Processing video 34/50 with name 68_9.mp4 \n",
            "\n",
            "Processing video 35/50 with name 217_3.mp4 \n",
            "\n",
            "Processing video 36/50 with name 101_12.mp4 \n",
            "\n",
            "Processing video 37/50 with name 324_56.mp4 \n",
            "\n",
            "Processing video 38/50 with name 321_31.mp4 \n",
            "\n",
            "Processing video 39/50 with name 197_12.mp4 \n",
            "\n",
            "Processing video 40/50 with name 80_1.mp4 \n",
            "\n",
            "Processing video 41/50 with name 220_6.mp4 \n",
            "\n",
            "Processing video 42/50 with name 41_18.mp4 \n",
            "\n",
            "Processing video 43/50 with name 198_5.mp4 \n",
            "\n",
            "Processing video 44/50 with name 52_1.mp4 \n",
            "\n",
            "Processing video 45/50 with name 280_12.mp4 \n",
            "\n",
            "Processing video 46/50 with name 3_29.mp4 \n",
            "\n",
            "Processing video 48/50 with name 258_2.mp4 \n",
            "\n",
            "Processing video 47/50 with name 43_12.mp4 \n",
            "\n",
            "Processing video 49/50 with name 312_1.mp4 \n",
            "\n",
            "Processing video 50/50 with name 148_4.mp4 \n",
            "\n",
            "***** Submitted all tasks *****\n",
            "***** Completed *****\n",
            "Starting to zip files to drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-faces.zip\n",
            "Done zipping files to drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-faces.zip\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQJc7zHP8mTI",
        "colab_type": "text"
      },
      "source": [
        "### Pose Extraction\n",
        "\n",
        "Poses must be extracted from the frames so VideoProcessor must be run before this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIVa1CKI6gJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp drive/'My Drive'/cs231n-project/openpose/openpose.tar.gz ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pa8pkZJ8RCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xzf openpose.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcI8NL5r8gq8",
        "colab_type": "code",
        "outputId": "87b9921f-8f74-45ec-8e46-c5830c2609fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls openpose"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3rdparty      build  CMakeLists.txt  examples  LICENSE\tpython\t   scripts\n",
            "appveyor.yml  cmake  doc\t     include   models\tREADME.md  src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_2x6JSVAB6C",
        "colab_type": "code",
        "outputId": "31b6f223-a416-4e06-c594-a0988ad2f042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt-get -qq install -y libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler libgflags-dev libgoogle-glog-dev liblmdb-dev opencl-headers ocl-icd-opencl-dev libviennacl-dev"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package libgflags2.2.\n",
            "(Reading database ... 144433 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libgflags2.2_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags2.2 (2.2.1-1) ...\n",
            "Selecting previously unselected package libgflags-dev.\n",
            "Preparing to unpack .../01-libgflags-dev_2.2.1-1_amd64.deb ...\n",
            "Unpacking libgflags-dev (2.2.1-1) ...\n",
            "Selecting previously unselected package libgoogle-glog0v5.\n",
            "Preparing to unpack .../02-libgoogle-glog0v5_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Selecting previously unselected package libgoogle-glog-dev.\n",
            "Preparing to unpack .../03-libgoogle-glog-dev_0.3.5-1_amd64.deb ...\n",
            "Unpacking libgoogle-glog-dev (0.3.5-1) ...\n",
            "Selecting previously unselected package libhdf5-serial-dev.\n",
            "Preparing to unpack .../04-libhdf5-serial-dev_1.10.0-patch1+docs-4_all.deb ...\n",
            "Unpacking libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Selecting previously unselected package libleveldb1v5:amd64.\n",
            "Preparing to unpack .../05-libleveldb1v5_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb1v5:amd64 (1.20-2) ...\n",
            "Selecting previously unselected package libleveldb-dev:amd64.\n",
            "Preparing to unpack .../06-libleveldb-dev_1.20-2_amd64.deb ...\n",
            "Unpacking libleveldb-dev:amd64 (1.20-2) ...\n",
            "Selecting previously unselected package liblmdb0:amd64.\n",
            "Preparing to unpack .../07-liblmdb0_0.9.21-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package liblmdb-dev:amd64.\n",
            "Preparing to unpack .../08-liblmdb-dev_0.9.21-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking liblmdb-dev:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libprotobuf-lite10:amd64.\n",
            "Preparing to unpack .../09-libprotobuf-lite10_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package lmdb-doc.\n",
            "Preparing to unpack .../10-lmdb-doc_0.9.21-1ubuntu0.1_all.deb ...\n",
            "Unpacking lmdb-doc (0.9.21-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libprotobuf-dev:amd64.\n",
            "Preparing to unpack .../11-libprotobuf-dev_3.0.0-9.1ubuntu1_amd64.deb ...\n",
            "Unpacking libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Selecting previously unselected package libsnappy-dev:amd64.\n",
            "Preparing to unpack .../12-libsnappy-dev_1.1.7-1_amd64.deb ...\n",
            "Unpacking libsnappy-dev:amd64 (1.1.7-1) ...\n",
            "Selecting previously unselected package libviennacl-dev.\n",
            "Preparing to unpack .../13-libviennacl-dev_1.7.1+dfsg1-2ubuntu1_all.deb ...\n",
            "Unpacking libviennacl-dev (1.7.1+dfsg1-2ubuntu1) ...\n",
            "Selecting previously unselected package opencl-clhpp-headers.\n",
            "Preparing to unpack .../14-opencl-clhpp-headers_2.0.10+git12-g5dd8bb9-1_all.deb ...\n",
            "Unpacking opencl-clhpp-headers (2.0.10+git12-g5dd8bb9-1) ...\n",
            "Selecting previously unselected package opencl-headers.\n",
            "Preparing to unpack .../15-opencl-headers_2.2~2018.02.21-gb5c3680-1_all.deb ...\n",
            "Unpacking opencl-headers (2.2~2018.02.21-gb5c3680-1) ...\n",
            "Setting up libviennacl-dev (1.7.1+dfsg1-2ubuntu1) ...\n",
            "Setting up libgflags2.2 (2.2.1-1) ...\n",
            "Setting up libgflags-dev (2.2.1-1) ...\n",
            "Setting up liblmdb0:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Setting up opencl-clhpp-headers (2.0.10+git12-g5dd8bb9-1) ...\n",
            "Setting up libleveldb1v5:amd64 (1.20-2) ...\n",
            "Setting up libhdf5-serial-dev (1.10.0-patch1+docs-4) ...\n",
            "Setting up libsnappy-dev:amd64 (1.1.7-1) ...\n",
            "Setting up libgoogle-glog0v5 (0.3.5-1) ...\n",
            "Setting up liblmdb-dev:amd64 (0.9.21-1ubuntu0.1) ...\n",
            "Setting up lmdb-doc (0.9.21-1ubuntu0.1) ...\n",
            "Setting up libprotobuf-lite10:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up opencl-headers (2.2~2018.02.21-gb5c3680-1) ...\n",
            "Setting up libprotobuf-dev:amd64 (3.0.0-9.1ubuntu1) ...\n",
            "Setting up libleveldb-dev:amd64 (1.20-2) ...\n",
            "Setting up libgoogle-glog-dev (0.3.5-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0Gz6HIT8x1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import cv2\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from pathlib import Path\n",
        "import os\n",
        "from os.path import isfile, join\n",
        "import pickle\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "class PosePreprocessor:\n",
        "    \"\"\"\n",
        "    Extract the poses from the video frames.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, video_frame_folder, output_folder, output_file=None, is_zip=True, is_test=False):\n",
        "        \"\"\"\n",
        "        @param video_frame_folder    The folder where the list of videos frames are stored. If \n",
        "                                     `is_zip` is set to True, this should be a single zip \n",
        "                                     file containing the video frames. Paths can either by a local \n",
        "                                     folder or a GDrive mounted path.\n",
        "        @param output_folder         The local output path where the preprocessed files will be stored for \n",
        "                                     further preprocessing can be done\n",
        "        @param output_file           If not none, the output_folder will be zipped up and stored at this location\n",
        "        @param is_zip                If set to True, the `video_frame_folder` will be unzipped prior to accessing\n",
        "        @param is_test               If set to True, the `video_frame_folder` is assumed to have no categorical \n",
        "                                     classification folder hierarchy\n",
        "        \"\"\"\n",
        "        self.is_zip = is_zip\n",
        "        self.is_test = is_test\n",
        "        self.video_frame_folder = video_frame_folder\n",
        "        self.output_folder = output_folder\n",
        "        self.output_file = output_file\n",
        "        print(f\"Pose Preprocessor created with is_zip = {is_zip}, is_test = {is_test}, video_frame_folder = {video_frame_folder} , output_folder = {output_folder}, output_file = {output_file}\")\n",
        "\n",
        "    def preprocess(self):\n",
        "        tmp_output_folder = \"\"\n",
        "        if self.is_zip:\n",
        "            # Unzips files to a temp directory\n",
        "            tmp_output_folder = self.output_folder.rstrip('/') + \"_tmp\"\n",
        "            print(f\"Unzipping files to temp dir {tmp_output_folder}...\")\n",
        "            Path(f\"{tmp_output_folder}\").mkdir(parents=True, exist_ok=True)\n",
        "            with zipfile.ZipFile(self.video_frame_folder, 'r') as zip_ref:\n",
        "                zip_ref.extractall(tmp_output_folder)\n",
        "            print(\"Finished unzipping files\")\n",
        "        else:\n",
        "            tmp_output_folder = self.video_frame_folder\n",
        "            print(\"Skipping unzipping files as input is a folder\")\n",
        "\n",
        "        # Create output folder for the keypoints\n",
        "        Path(f\"{self.output_folder}\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        if self.is_test:\n",
        "            print(f\"Starting pose extraction for {tmp_output_folder}\")\n",
        "            p = subprocess.run([\"build/examples/openpose/openpose.bin\", \"--image_dir\", \"../\" + tmp_output_folder, \"--write_json\", \"../\" + self.output_folder, \"--display\", \"0\", \"--render_pose\", \"0\"], cwd=\"openpose\", stdout=subprocess.PIPE, stderr=subprocess.PIPE, encoding='utf-8')\n",
        "            print(p.stdout)\n",
        "            print(p.stderr)\n",
        "        else:\n",
        "            # Subfolders represent the different categories \n",
        "            # (we will mimic this for the final output)\n",
        "            subfolders = next(os.walk(tmp_output_folder))[1]\n",
        "            for subfolder in subfolders:\n",
        "                print(f\"Starting pose extraction for {join(tmp_output_folder, subfolder)}\")\n",
        "                p = subprocess.run([\"build/examples/openpose/openpose.bin\", \"--image_dir\", \"../\" + join(tmp_output_folder, subfolder), \"--write_json\", \"../\" + join(self.output_folder, subfolder), \"--display\", \"0\", \"--render_pose\", \"0\"], cwd=\"openpose\", stdout=subprocess.PIPE, stderr=subprocess.PIPE, encoding='utf-8')\n",
        "                print(p.stdout)\n",
        "                print(p.stderr)\n",
        "\n",
        "        if self.output_file is not None:\n",
        "            print(f\"Starting to zip files to {self.output_file}\")\n",
        "            def zipdir(path, ziph):\n",
        "                for root, dirs, files in os.walk(path):\n",
        "                    folder = root[len(path):]\n",
        "                    for file in files:\n",
        "                        ziph.write(join(root, file), join(folder, file))\n",
        "\n",
        "            zipf = zipfile.ZipFile(self.output_file, 'w', zipfile.ZIP_DEFLATED)\n",
        "            zipdir(self.output_folder, zipf)\n",
        "            zipf.close()\n",
        "            print(f\"Done zipping files to {self.output_file}\")\n",
        "        \n",
        "        print(\"Done!\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_TR0Jlc94w3",
        "colab_type": "code",
        "outputId": "f8f8787f-c1af-412a-c56f-e38fa1f38caf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "pose_preprocessor = PosePreprocessor(\n",
        "    video_frame_folder=\"drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-local.zip\",\n",
        "    output_folder=\"train-tiny-pose\", \n",
        "    output_file=\"drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-pose.zip\"\n",
        ")\n",
        "pose_preprocessor.preprocess()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pose Preprocessor created with is_zip = True, is_test = False, video_frame_folder = drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-local.zip , output_folder = train-tiny-pose, output_file = drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-pose.zip\n",
            "Unzipping files to temp dir train-tiny-pose_tmp...\n",
            "Finished unzipping files\n",
            "Starting pose extraction for train-tiny-pose_tmp/1\n",
            "Starting OpenPose demo...\n",
            "Configuring OpenPose...\n",
            "Starting thread(s)...\n",
            "Auto-detecting all available GPUs... Detected 1 GPU(s), using 1 of them starting at GPU 0.\n",
            "OpenPose demo successfully finished. Total time: 14.118342 seconds.\n",
            "\n",
            "\n",
            "Starting pose extraction for train-tiny-pose_tmp/3\n",
            "Starting OpenPose demo...\n",
            "Configuring OpenPose...\n",
            "Starting thread(s)...\n",
            "Auto-detecting all available GPUs... Detected 1 GPU(s), using 1 of them starting at GPU 0.\n",
            "OpenPose demo successfully finished. Total time: 14.530537 seconds.\n",
            "\n",
            "\n",
            "Starting pose extraction for train-tiny-pose_tmp/2\n",
            "Starting OpenPose demo...\n",
            "Configuring OpenPose...\n",
            "Starting thread(s)...\n",
            "Auto-detecting all available GPUs... Detected 1 GPU(s), using 1 of them starting at GPU 0.\n",
            "OpenPose demo successfully finished. Total time: 9.088124 seconds.\n",
            "\n",
            "\n",
            "Starting to zip files to drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-pose.zip\n",
            "Done zipping files to drive/My Drive/cs231n-project/datasets/emotiw/train-tiny-pose.zip\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLzsKvpq-HZa",
        "colab_type": "code",
        "outputId": "5a3f3eec-9f30-4d53-ebba-4e612cb1f301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "pose_preprocessor = PosePreprocessor(\n",
        "    video_frame_folder=\"drive/My Drive/cs231n-project/datasets/emotiw/val-tiny-local.zip\",\n",
        "    output_folder=\"val-tiny-pose\", \n",
        "    output_file=\"drive/My Drive/cs231n-project/datasets/emotiw/val-tiny-pose.zip\"\n",
        ")\n",
        "pose_preprocessor.preprocess()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pose Preprocessor created with is_zip = True, is_test = False, video_frame_folder = drive/My Drive/cs231n-project/datasets/emotiw/val-tiny-local.zip , output_folder = val-tiny-pose, output_file = drive/My Drive/cs231n-project/datasets/emotiw/val-tiny-pose.zip\n",
            "Unzipping files to temp dir val-tiny-pose_tmp...\n",
            "Finished unzipping files\n",
            "Starting pose extraction for val-tiny-pose_tmp/1\n",
            "Starting OpenPose demo...\n",
            "Configuring OpenPose...\n",
            "Starting thread(s)...\n",
            "Auto-detecting all available GPUs... Detected 1 GPU(s), using 1 of them starting at GPU 0.\n",
            "OpenPose demo successfully finished. Total time: 15.779708 seconds.\n",
            "\n",
            "\n",
            "Starting pose extraction for val-tiny-pose_tmp/3\n",
            "Starting OpenPose demo...\n",
            "Configuring OpenPose...\n",
            "Starting thread(s)...\n",
            "Auto-detecting all available GPUs... Detected 1 GPU(s), using 1 of them starting at GPU 0.\n",
            "OpenPose demo successfully finished. Total time: 8.034669 seconds.\n",
            "\n",
            "\n",
            "Starting pose extraction for val-tiny-pose_tmp/2\n",
            "Starting OpenPose demo...\n",
            "Configuring OpenPose...\n",
            "Starting thread(s)...\n",
            "Auto-detecting all available GPUs... Detected 1 GPU(s), using 1 of them starting at GPU 0.\n",
            "OpenPose demo successfully finished. Total time: 12.068611 seconds.\n",
            "\n",
            "\n",
            "Starting to zip files to drive/My Drive/cs231n-project/datasets/emotiw/val-tiny-pose.zip\n",
            "Done zipping files to drive/My Drive/cs231n-project/datasets/emotiw/val-tiny-pose.zip\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6Ldkmq9EAn6",
        "colab_type": "code",
        "outputId": "2099a026-0ca6-44fc-de6d-321f84939886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "pose_preprocessor = PosePreprocessor(\n",
        "    video_frame_folder=\"drive/My Drive/cs231n-project/datasets/emotiw/test-tiny-local.zip\",\n",
        "    output_folder=\"test-tiny-pose\", \n",
        "    output_file=\"drive/My Drive/cs231n-project/datasets/emotiw/test-tiny-pose.zip\",\n",
        "    is_test=True\n",
        ")\n",
        "pose_preprocessor.preprocess()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pose Preprocessor created with is_zip = True, is_test = True, video_frame_folder = drive/My Drive/cs231n-project/datasets/emotiw/test-tiny-local.zip , output_folder = test-tiny-pose, output_file = drive/My Drive/cs231n-project/datasets/emotiw/test-tiny-pose.zip\n",
            "Unzipping files to temp dir test-tiny-pose_tmp...\n",
            "Finished unzipping files\n",
            "Starting pose extraction for test-tiny-pose_tmp\n",
            "Starting OpenPose demo...\n",
            "Configuring OpenPose...\n",
            "Starting thread(s)...\n",
            "Auto-detecting all available GPUs... Detected 1 GPU(s), using 1 of them starting at GPU 0.\n",
            "OpenPose demo successfully finished. Total time: 34.017663 seconds.\n",
            "\n",
            "\n",
            "Starting to zip files to drive/My Drive/cs231n-project/datasets/emotiw/test-tiny-pose.zip\n",
            "Done zipping files to drive/My Drive/cs231n-project/datasets/emotiw/test-tiny-pose.zip\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbmAqNRTzYyg",
        "colab_type": "text"
      },
      "source": [
        "## Audio Preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkfCvxLGBU3x",
        "colab_type": "code",
        "outputId": "ab506545-34cf-4077-ae87-5bc964cc4353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import zipfile\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from pathlib import Path\n",
        "import os\n",
        "%tensorflow_version 1\n",
        "import tensorflow as tf\n",
        "from os.path import isfile, join\n",
        "import pickle\n",
        "import glob\n",
        "import subprocess\n",
        "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_audio\n",
        "import numpy as np\n",
        "subprocess.check_output(\"pip install openl3\" , shell=True)\n",
        "subprocess.check_output(\"pip install pydub\", shell=True)\n",
        "import openl3\n",
        "import soundfile as sf\n",
        "class AudioPreprocessor:\n",
        "    \"\"\"\n",
        "    Extract the audio from the videos.\n",
        "    Faces are stored in a flat directory structure (no categorical hierarchy)\n",
        "    \n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, video_folder, output_folder, output_file=None, label_path = None , is_zip=True, sample_every=10 , hop_size=0.5, max_len=5):\n",
        "        \"\"\"\n",
        "        @param video_folder          The folder where the list of videos frames are stored. If \n",
        "                                     `is_zip` is set to True, this should be a single zip \n",
        "                                     file containing the video frames. Paths can either by a local \n",
        "                                     folder or a GDrive mounted path.\n",
        "        @param output_folder         The local output path where the preprocessed files will be stored for \n",
        "                                     further preprocessing can be done\n",
        "        @param output_file           If not none, the output_folder will be zipped up and stored at this location\n",
        "        @param label_path            The path of the .txt file containing the class labels matched to the sample name.\n",
        "        @param is_zip                If set to True, the `video_folder` will be unzipped prior to accessing\n",
        "        - hop_size: The frame collection rate \n",
        "        @param sample_every the frames to skip.\n",
        "\n",
        "        \"\"\"\n",
        "        self.is_zip = is_zip\n",
        "        self.video_folder = video_folder\n",
        "        self.output_folder = output_folder\n",
        "        self.output_file = output_file\n",
        "        self.hop_size = hop_size\n",
        "        self.max_len = max_len\n",
        "        self.label_path = label_path\n",
        "        print(f\"Video Preprocessor created with is_zip = {is_zip}, video_folder = {video_folder} , output_folder = {output_folder}, output_file = {output_file}\")\n",
        "\n",
        "        self.sample_every = sample_every\n",
        "        print(f\"Frames will be created with hop_size = {hop_size}\")\n",
        "\n",
        "\n",
        "    def preprocess(self, batch_size=16):\n",
        "      \"\"\"\n",
        "      Outputs: Writes to disk the openl3 embedding pickle object for each sample. \n",
        "      Optionally, it will output the entire matched X and Y numpy pickle objects if label path is provided\n",
        "      - \n",
        "      \"\"\"\n",
        "\n",
        "\n",
        "      tmp_output_folder = \"\"\n",
        "      if self.is_zip:\n",
        "      # Unzips files to a temp directory\n",
        "        tmp_output_folder = self.output_folder.rstrip('/') + \"_tmp\"\n",
        "        print(f\"Unzipping files to temp dir {tmp_output_folder}...\")\n",
        "        Path(f\"{tmp_output_folder}\").mkdir(parents=True, exist_ok=True)\n",
        "        with zipfile.ZipFile(self.video_folder, 'r') as zip_ref:\n",
        "            zip_ref.extractall(tmp_output_folder)\n",
        "        print(\"Finished unzipping files\")\n",
        "      else:\n",
        "        tmp_output_folder = self.video_folder\n",
        "        print(\"Skipping unzipping files as input is a folder\")\n",
        "\n",
        "      Path(f\"{self.output_folder}/audio-pickle/\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "      # Strip the audio from video and store as .wav file\n",
        "      video_files = sorted(glob.glob(tmp_output_folder + '/*.mp4'))\n",
        "      video_files_split = np.array_split(np.asarray(video_files),len(video_files)//batch_size)\n",
        "\n",
        "      target_labels = []\n",
        "\n",
        "      if self.label_path is not None:   \n",
        "        targets = []\n",
        "        target_labels = np.genfromtxt(self.label_path , delimiter = ' ' , dtype='str')\n",
        "\n",
        "      sr = 0\n",
        "      all_x = []\n",
        "\n",
        "      maxlen = int(self.max_len // self.hop_size + 1)\n",
        "\n",
        "      for i in range (0 , len(video_files_split)):\n",
        "\n",
        "\n",
        "        audio_reads = []\n",
        "\n",
        "\n",
        "        for f in video_files_split[i]: \n",
        "          newname = os.path.basename(f)\n",
        "          output_wav_file = newname + 'extracted_audio.wav'\n",
        "          ffmpeg_extract_audio(f ,  \"/tmp/\" + output_wav_file)\n",
        "          if self.label_path is not None:        \n",
        "            target_index = np.where(target_labels[: , 0] == newname[:-4])[0]\n",
        "            target_index = int(target_index)\n",
        "            target = int(target_labels[: , 1][target_index]) - 1\n",
        "            targets.append(target)\n",
        "          audio_read, sr = sf.read(\"/tmp/\" + output_wav_file)\n",
        "          audio_reads.append(audio_read)\n",
        "          print(f\"Reading file {output_wav_file} ...\")\n",
        "       \n",
        "          \n",
        "        X_arr, ts_list = openl3.get_audio_embedding(audio_reads, sr, batch_size=15 ,  hop_size=self.hop_size)\n",
        "\n",
        "        X = tf.keras.preprocessing.sequence.pad_sequences(X_arr, maxlen=maxlen)\n",
        "        X = np.asarray(X , dtype='float32')\n",
        "\n",
        "        if i == 0:\n",
        "          all_x = X\n",
        "          all_x = np.asarray(all_x , dtype='float32')\n",
        "        else: \n",
        "          all_x = np.concatenate((all_x ,  X ), axis=0)\n",
        "\n",
        "        print(all_x.shape)\n",
        "\n",
        "      for f in video_files:\n",
        "        file_name = os.path.basename(f)\n",
        "        with open(f\"{self.output_folder}/audio-pickle/{file_name}-openl3.pkl\", \"wb\") as f_out:\n",
        "          pickle.dump(all_x[i], f_out)\n",
        "\n",
        "\n",
        "      if self.label_path is not None:\n",
        "        with open(f\"{self.output_folder}/audio-pickle-all-X-openl3.pkl\", \"wb\") as f_out:\n",
        "          pickle.dump(all_x , f_out)\n",
        "\n",
        "        targets = np.asarray(targets)\n",
        "        with open(f\"{self.output_folder}/audio-pickle-all-Y-openl3.pkl\", \"wb\") as f_out:\n",
        "          pickle.dump(targets , f_out)\n",
        "\n",
        "      if self.output_file is not None:\n",
        "            print(f\"Starting to zip files to {self.output_file}\")\n",
        "            def zipdir(path, ziph):\n",
        "                for root, dirs, files in os.walk(path):\n",
        "                    folder = root[len(path):]\n",
        "                    for file in files:\n",
        "                        ziph.write(join(root, file), join(folder, file))\n",
        "\n",
        "            zipf = zipfile.ZipFile(self.output_file, 'w', zipfile.ZIP_DEFLATED)\n",
        "            zipdir(self.output_folder, zipf)\n",
        "            zipf.close()\n",
        "            print(f\"Done zipping files to {self.output_file}\")\n",
        "        \n",
        "      print(\"Done!\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gUTaZaELjp1",
        "colab_type": "code",
        "outputId": "f1016c0f-bdc6-4ad6-de23-d94fdcecb153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "HOME_DIR = \"drive/My Drive/Machine-Learning-Projects/\"\n",
        "audio_preprocessor = AudioPreprocessor(\n",
        "    output_folder=\"train-tiny-audio\", \n",
        "    output_file= HOME_DIR + \"cs231n-project/datasets/emotiw/train-tiny-audio.zip\" ,\n",
        "    video_folder= HOME_DIR + \"cs231n-project/datasets/emotiw/train-tiny.zip\",\n",
        "    label_path = HOME_DIR + \"cs231n-project/datasets/emotiw/Train_labels.txt\"\n",
        ")\n",
        "\n",
        "X = audio_preprocessor.preprocess()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Video Preprocessor created with is_zip = True, video_folder = drive/My Drive/Machine-Learning-Projects/cs231n-project/datasets/emotiw/train-tiny.zip , output_folder = train-tiny-audio, output_file = drive/My Drive/Machine-Learning-Projects/cs231n-project/datasets/emotiw/train-tiny-audio.zip\n",
            "Frames will be created with hop_size = 0.5\n",
            "Unzipping files to temp dir train-tiny-audio_tmp...\n",
            "Finished unzipping files\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/101_12.mp4 -ab 3000k -ar 44100 /tmp/101_12.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 101_12.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/101_30.mp4 -ab 3000k -ar 44100 /tmp/101_30.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 101_30.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/108_13.mp4 -ab 3000k -ar 44100 /tmp/108_13.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 108_13.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/112_5.mp4 -ab 3000k -ar 44100 /tmp/112_5.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 112_5.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/119_8.mp4 -ab 3000k -ar 44100 /tmp/119_8.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 119_8.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/122_1.mp4 -ab 3000k -ar 44100 /tmp/122_1.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 122_1.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/133_2.mp4 -ab 3000k -ar 44100 /tmp/133_2.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 133_2.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/140_1.mp4 -ab 3000k -ar 44100 /tmp/140_1.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 140_1.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/148_4.mp4 -ab 3000k -ar 44100 /tmp/148_4.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 148_4.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/16_14.mp4 -ab 3000k -ar 44100 /tmp/16_14.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 16_14.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/188_15.mp4 -ab 3000k -ar 44100 /tmp/188_15.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 188_15.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/188_22.mp4 -ab 3000k -ar 44100 /tmp/188_22.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 188_22.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/197_12.mp4 -ab 3000k -ar 44100 /tmp/197_12.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 197_12.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/198_5.mp4 -ab 3000k -ar 44100 /tmp/198_5.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 198_5.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/204_13.mp4 -ab 3000k -ar 44100 /tmp/204_13.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 204_13.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/217_15.mp4 -ab 3000k -ar 44100 /tmp/217_15.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 217_15.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/217_3.mp4 -ab 3000k -ar 44100 /tmp/217_3.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 217_3.mp4extracted_audio.wav ...\n",
            "187/187 [==============================] - 1s 5ms/step\n",
            "(17, 11, 6144)\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/220_6.mp4 -ab 3000k -ar 44100 /tmp/220_6.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 220_6.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/258_2.mp4 -ab 3000k -ar 44100 /tmp/258_2.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 258_2.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/276_3.mp4 -ab 3000k -ar 44100 /tmp/276_3.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 276_3.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/276_8.mp4 -ab 3000k -ar 44100 /tmp/276_8.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 276_8.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/277_3.mp4 -ab 3000k -ar 44100 /tmp/277_3.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 277_3.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/280_12.mp4 -ab 3000k -ar 44100 /tmp/280_12.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 280_12.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/281_2.mp4 -ab 3000k -ar 44100 /tmp/281_2.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 281_2.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/286_4.mp4 -ab 3000k -ar 44100 /tmp/286_4.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 286_4.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/2_2.mp4 -ab 3000k -ar 44100 /tmp/2_2.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 2_2.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/300_56.mp4 -ab 3000k -ar 44100 /tmp/300_56.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 300_56.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/303_41.mp4 -ab 3000k -ar 44100 /tmp/303_41.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 303_41.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/312_1.mp4 -ab 3000k -ar 44100 /tmp/312_1.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 312_1.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/321_15.mp4 -ab 3000k -ar 44100 /tmp/321_15.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 321_15.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/321_31.mp4 -ab 3000k -ar 44100 /tmp/321_31.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 321_31.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/324_34.mp4 -ab 3000k -ar 44100 /tmp/324_34.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 324_34.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/324_56.mp4 -ab 3000k -ar 44100 /tmp/324_56.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 324_56.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/324_96.mp4 -ab 3000k -ar 44100 /tmp/324_96.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 324_96.mp4extracted_audio.wav ...\n",
            "187/187 [==============================] - 1s 5ms/step\n",
            "(34, 11, 6144)\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/328_13.mp4 -ab 3000k -ar 44100 /tmp/328_13.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 328_13.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/334_21.mp4 -ab 3000k -ar 44100 /tmp/334_21.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 334_21.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/33_20.mp4 -ab 3000k -ar 44100 /tmp/33_20.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 33_20.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/34_9.mp4 -ab 3000k -ar 44100 /tmp/34_9.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 34_9.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/3_17.mp4 -ab 3000k -ar 44100 /tmp/3_17.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 3_17.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/3_29.mp4 -ab 3000k -ar 44100 /tmp/3_29.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 3_29.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/41_18.mp4 -ab 3000k -ar 44100 /tmp/41_18.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 41_18.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/43_12.mp4 -ab 3000k -ar 44100 /tmp/43_12.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 43_12.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/52_1.mp4 -ab 3000k -ar 44100 /tmp/52_1.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 52_1.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/61_15.mp4 -ab 3000k -ar 44100 /tmp/61_15.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 61_15.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/64_5.mp4 -ab 3000k -ar 44100 /tmp/64_5.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 64_5.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/68_9.mp4 -ab 3000k -ar 44100 /tmp/68_9.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 68_9.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/69_30.mp4 -ab 3000k -ar 44100 /tmp/69_30.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 69_30.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/7_6.mp4 -ab 3000k -ar 44100 /tmp/7_6.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 7_6.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/80_1.mp4 -ab 3000k -ar 44100 /tmp/80_1.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 80_1.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i train-tiny-audio_tmp/97_22.mp4 -ab 3000k -ar 44100 /tmp/97_22.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 97_22.mp4extracted_audio.wav ...\n",
            "176/176 [==============================] - 1s 5ms/step\n",
            "(50, 11, 6144)\n",
            "Starting to zip files to drive/My Drive/Machine-Learning-Projects/cs231n-project/datasets/emotiw/train-tiny-audio.zip\n",
            "Done zipping files to drive/My Drive/Machine-Learning-Projects/cs231n-project/datasets/emotiw/train-tiny-audio.zip\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3nvPZGOeut5",
        "colab_type": "code",
        "outputId": "12b84528-eeae-4e71-e7c4-e45474111bca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "HOME_DIR = \"drive/My Drive/Machine-Learning-Projects/\"\n",
        "audio_preprocessor = AudioPreprocessor(\n",
        "    video_folder =  HOME_DIR + \"cs231n-project/datasets/emotiw/val-tiny.zip\",\n",
        "    output_file= HOME_DIR + \"cs231n-project/datasets/emotiw/val-tiny-audio.zip\" ,\n",
        "    output_folder=\"val-tiny-audio\",\n",
        "    label_path = HOME_DIR + \"cs231n-project/datasets/emotiw/Val_labels.txt\" )\n",
        "audio_preprocessor.preprocess()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Video Preprocessor created with is_zip = True, video_folder = drive/My Drive/Machine-Learning-Projects/cs231n-project/datasets/emotiw/val-tiny.zip , output_folder = val-tiny-audio, output_file = drive/My Drive/Machine-Learning-Projects/cs231n-project/datasets/emotiw/val-tiny-audio.zip\n",
            "Frames will be created with hop_size = 0.5\n",
            "Unzipping files to temp dir val-tiny-audio_tmp...\n",
            "Finished unzipping files\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/115_10.mp4 -ab 3000k -ar 44100 /tmp/115_10.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 115_10.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/115_8.mp4 -ab 3000k -ar 44100 /tmp/115_8.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 115_8.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/115_9.mp4 -ab 3000k -ar 44100 /tmp/115_9.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 115_9.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/11_10.mp4 -ab 3000k -ar 44100 /tmp/11_10.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 11_10.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/11_16.mp4 -ab 3000k -ar 44100 /tmp/11_16.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 11_16.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/131_6.mp4 -ab 3000k -ar 44100 /tmp/131_6.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 131_6.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/145_4.mp4 -ab 3000k -ar 44100 /tmp/145_4.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 145_4.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/157_10.mp4 -ab 3000k -ar 44100 /tmp/157_10.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 157_10.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/179_5.mp4 -ab 3000k -ar 44100 /tmp/179_5.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 179_5.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/181_2.mp4 -ab 3000k -ar 44100 /tmp/181_2.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 181_2.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/181_5.mp4 -ab 3000k -ar 44100 /tmp/181_5.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 181_5.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/181_8.mp4 -ab 3000k -ar 44100 /tmp/181_8.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 181_8.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/268_1.mp4 -ab 3000k -ar 44100 /tmp/268_1.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 268_1.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/274_2.mp4 -ab 3000k -ar 44100 /tmp/274_2.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 274_2.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/27_13.mp4 -ab 3000k -ar 44100 /tmp/27_13.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 27_13.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/27_17.mp4 -ab 3000k -ar 44100 /tmp/27_17.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 27_17.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/284_11.mp4 -ab 3000k -ar 44100 /tmp/284_11.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 284_11.mp4extracted_audio.wav ...\n",
            "187/187 [==============================] - 1s 6ms/step\n",
            "(17, 11, 6144)\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/284_9.mp4 -ab 3000k -ar 44100 /tmp/284_9.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 284_9.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/289_17.mp4 -ab 3000k -ar 44100 /tmp/289_17.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 289_17.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/289_2.mp4 -ab 3000k -ar 44100 /tmp/289_2.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 289_2.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/289_34.mp4 -ab 3000k -ar 44100 /tmp/289_34.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 289_34.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/289_42.mp4 -ab 3000k -ar 44100 /tmp/289_42.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 289_42.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/294_20.mp4 -ab 3000k -ar 44100 /tmp/294_20.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 294_20.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/294_26.mp4 -ab 3000k -ar 44100 /tmp/294_26.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 294_26.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/294_30.mp4 -ab 3000k -ar 44100 /tmp/294_30.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 294_30.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/294_39.mp4 -ab 3000k -ar 44100 /tmp/294_39.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 294_39.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/294_9.mp4 -ab 3000k -ar 44100 /tmp/294_9.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 294_9.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/298_21.mp4 -ab 3000k -ar 44100 /tmp/298_21.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 298_21.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/298_29.mp4 -ab 3000k -ar 44100 /tmp/298_29.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 298_29.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/298_31.mp4 -ab 3000k -ar 44100 /tmp/298_31.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 298_31.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/298_9.mp4 -ab 3000k -ar 44100 /tmp/298_9.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 298_9.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/306_8.mp4 -ab 3000k -ar 44100 /tmp/306_8.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 306_8.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/320_1.mp4 -ab 3000k -ar 44100 /tmp/320_1.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 320_1.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/320_2.mp4 -ab 3000k -ar 44100 /tmp/320_2.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 320_2.mp4extracted_audio.wav ...\n",
            "187/187 [==============================] - 1s 6ms/step\n",
            "(34, 11, 6144)\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/320_8.mp4 -ab 3000k -ar 44100 /tmp/320_8.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 320_8.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/325_37.mp4 -ab 3000k -ar 44100 /tmp/325_37.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 325_37.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/44_14.mp4 -ab 3000k -ar 44100 /tmp/44_14.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 44_14.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/44_2.mp4 -ab 3000k -ar 44100 /tmp/44_2.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 44_2.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/53_12.mp4 -ab 3000k -ar 44100 /tmp/53_12.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 53_12.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/53_31.mp4 -ab 3000k -ar 44100 /tmp/53_31.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 53_31.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/53_7.mp4 -ab 3000k -ar 44100 /tmp/53_7.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 53_7.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/5_17.mp4 -ab 3000k -ar 44100 /tmp/5_17.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 5_17.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/70_3.mp4 -ab 3000k -ar 44100 /tmp/70_3.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 70_3.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/77_4.mp4 -ab 3000k -ar 44100 /tmp/77_4.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 77_4.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/81_21.mp4 -ab 3000k -ar 44100 /tmp/81_21.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 81_21.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/86_16.mp4 -ab 3000k -ar 44100 /tmp/86_16.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 86_16.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/86_2.mp4 -ab 3000k -ar 44100 /tmp/86_2.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 86_2.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/86_39.mp4 -ab 3000k -ar 44100 /tmp/86_39.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 86_39.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/86_4.mp4 -ab 3000k -ar 44100 /tmp/86_4.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 86_4.mp4extracted_audio.wav ...\n",
            "\n",
            "[MoviePy] Running:\n",
            ">>> /usr/bin/ffmpeg -y -i val-tiny-audio_tmp/86_48.mp4 -ab 3000k -ar 44100 /tmp/86_48.mp4extracted_audio.wav\n",
            "... command successful.\n",
            "Reading file 86_48.mp4extracted_audio.wav ...\n",
            "176/176 [==============================] - 1s 6ms/step\n",
            "(50, 11, 6144)\n",
            "Starting to zip files to drive/My Drive/Machine-Learning-Projects/cs231n-project/datasets/emotiw/val-tiny-audio.zip\n",
            "Done zipping files to drive/My Drive/Machine-Learning-Projects/cs231n-project/datasets/emotiw/val-tiny-audio.zip\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5j1Vnl-e0HR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HOME_DIR = \"drive/My Drive/Machine-Learning-Projects/\"\n",
        "TEST_LABELS_PATH = \"\"\n",
        "\n",
        "audio_preprocessor = AudioPreprocessor(\n",
        "    output_folder=\"test-tiny-audio\", \n",
        "    output_file= HOME_DIR + \"cs231n-project/datasets/emotiw/test-tiny-audio.zip\" ,\n",
        "    video_folder= HOME_DIR + \"cs231n-project/datasets/emotiw/test-tiny.zip\",\n",
        "    label_path = TEST_LABELS_PATH\n",
        ")\n",
        "\n",
        "X = audio_preprocessor.preprocess()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}