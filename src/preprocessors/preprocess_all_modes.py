# -*- coding: utf-8 -*-
"""preprocess-all-modes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R-fl6VLDuneQMMovEAemB3odW4VNkuCJ

## Video Sentiment Analysis in the Wild
### Ensembling Notebook | CS231n

This notebook preprocesses input videos to extract faces, frames, poses, and audio before running pre-trained models for each modality to predict group sentiment (positive, negative, or neutral).
"""

"""#### Pre-Processing

Here, we will instantiate each of the preprocessors and process all of the input video files.

NOTE: Change the input parameters as needed.

WARNING: This may take several hours to complete, depending on the number of files.

In general, pre-processing will extract the following:
- Video frames
- Pose keypoints
- Faces from each video frame
- Audio waveform and audio features
"""

from src.preprocessors.scene_preprocessor import ScenePreprocessor
from src.preprocessors.face_preprocessor import FacePreprocessor
from src.preprocessors.fer_preprocessor import FerPreprocessor
from src.preprocessors.pose_preprocessor import PosePreprocessor
from src.preprocessors.audio_preprocessor import AudioPreprocessor


def preprocess(video_folder, local_base_path, label_file=None):
    """
    The preprocess the raw videos into different modalities

    @param video_folder: The folder containing the video files.
                         Example: "train-tiny.zip"
    @param local_base_path: The folder prefix used in the local folders generated.
                            Example: "train-tiny"
    @param label_file: The file containing the videos.
                       If set to None, assumed to be "test-mode"
    """
    video_preprocessor = ScenePreprocessor(
        video_folder=video_folder,
        label_file=label_file,
        output_folder=f"{local_base_path}-frames",
        output_file=f"{local_base_path}-frames.zip"
    )

    face_preprocessor = FacePreprocessor(
        video_folder=video_folder,
        output_folder=f"{local_base_path}-faces",
        output_file=f"{local_base_path}-faces.zip"
    )

    fer_preprocessor = FerPreprocessor(
        faces_folder=f"{local_base_path}-faces",
        output_folder=f"{local_base_path}-fer",
        output_file=f"{local_base_path}-fer.zip",
        model_path="fer2013_mini_XCEPTION.119-0.65.hdf5"
    )

    pose_preprocessor = PosePreprocessor(
        video_frame_folder=f"{local_base_path}-frames",
        output_folder=f"{local_base_path}-pose",
        output_file=f"{local_base_path}-pose.zip",
        is_test=label_file is None
    )

    audio_preprocessor = AudioPreprocessor(
        video_folder=video_folder,
        label_path=label_file,
        output_folder=f"{local_base_path}-audio",
        output_file=f"{local_base_path}-audio.zip"
    )

    #preprocessors_list = [fer_preprocessor]
    preprocessors_list = [video_preprocessor, face_preprocessor, pose_preprocessor, audio_preprocessor]

    for preprocessor in preprocessors_list:
        preprocessor.preprocess()

    print("Done all pre-processing. Folders created: ")
    print(f"   {local_base_path}-frames")
    print(f"   {local_base_path}-faces")
    print(f"   {local_base_path}-fer")
    print(f"   {local_base_path}-pose")
    print(f"   {local_base_path}-audio")
